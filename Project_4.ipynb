{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3bbab66-745f-40fb-b981-c03a0e211055",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.4-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69d07b-2d67-4e71-9eec-04bc62e3864e",
   "metadata": {},
   "source": [
    "# Import the dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "074d77b3-1a7a-439b-8cad-7cd667ae74f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62267299-22bd-4060-81d1-91867e724db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import Data\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abf296-e64c-4dcd-92b9-3dc2cf99fcc8",
   "metadata": {},
   "source": [
    "### Load and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c41ad6-d0c9-4933-b4f9-d7241f9f54b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Submission DataFrame:\n",
      "        ID resname  resid  x_1  y_1  z_1  x_2  y_2  z_2  x_3  y_3  z_3  x_4  \\\n",
      "0  R1107_1       G      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1  R1107_2       G      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2  R1107_3       G      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3  R1107_4       G      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4  R1107_5       G      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   y_4  z_4  x_5  y_5  z_5  \n",
      "0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "Test Sequences DataFrame:\n",
      "  target_id                                           sequence  \\\n",
      "0     R1107  GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...   \n",
      "1     R1108  GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUU...   \n",
      "2     R1116  CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGG...   \n",
      "3   R1117v2                     UUGGGUUCCCUCACCCCAAUCAUAAAAAGG   \n",
      "4     R1126  GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUU...   \n",
      "\n",
      "  temporal_cutoff                                        description  \\\n",
      "0      2022-05-28  CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...   \n",
      "1      2022-05-27  CPEB3 ribozyme\\nChimpanzee\\nChimpanzee CPEB3 H...   \n",
      "2      2022-06-04  Cloverleaf RNA\\nPoliovirus\\nCrystal Structure ...   \n",
      "3      2022-06-03  PreQ1 class I type III riboswitch\\nK. pneumoni...   \n",
      "4      2022-06-11  Traptamer\\nSynthetic\\nAdditional Information: ...   \n",
      "\n",
      "                                       all_sequences  \n",
      "0  >7QR4_1|Chain A|U1 small nuclear ribonucleopro...  \n",
      "1  >7QR3_1|Chains A, B|U1 small nuclear ribonucle...  \n",
      "2  >8S95_1|Chain A[auth C]|Lysine tRNA scaffold,P...  \n",
      "3  >8FZA_1|Chains A, B|PreQ1 Riboswitch (30-MER)|...  \n",
      "4  >8TVZ_1|Chain A[auth C]|RNA (363-MER)|syntheti...  \n",
      "\n",
      "Train Labels DataFrame:\n",
      "         ID resname  resid     x_1        y_1     z_1\n",
      "0  1SCL_A_1       G      1  13.760 -25.974001   0.102\n",
      "1  1SCL_A_2       G      2   9.310 -29.638000   2.669\n",
      "2  1SCL_A_3       G      3   5.529 -27.813000   5.878\n",
      "3  1SCL_A_4       U      4   2.678 -24.900999   9.793\n",
      "4  1SCL_A_5       G      5   1.827 -20.136000  11.793\n",
      "\n",
      "Train Sequences DataFrame:\n",
      "  target_id                            sequence temporal_cutoff  \\\n",
      "0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n",
      "1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n",
      "2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n",
      "3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n",
      "4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n",
      "\n",
      "                                         description  \\\n",
      "0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n",
      "1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n",
      "2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n",
      "3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n",
      "4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n",
      "\n",
      "                                       all_sequences  \n",
      "0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  \n",
      "1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...  \n",
      "2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...  \n",
      "3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...  \n",
      "4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...  \n",
      "\n",
      "Validation Labels DataFrame:\n",
      "        ID resname  resid    x_1        y_1        z_1           x_2  \\\n",
      "0  R1107_1       G      1 -5.499   8.520000   8.605000 -1.000000e+18   \n",
      "1  R1107_2       G      2 -5.826  10.453000  14.010000 -1.000000e+18   \n",
      "2  R1107_3       G      3 -5.849  14.768000  17.584999 -1.000000e+18   \n",
      "3  R1107_4       G      4 -5.784  19.985001  18.666000 -1.000000e+18   \n",
      "4  R1107_5       G      5 -5.755  25.533001  17.132999 -1.000000e+18   \n",
      "\n",
      "            y_2           z_2           x_3  ...          z_37          x_38  \\\n",
      "0 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n",
      "1 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n",
      "2 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n",
      "3 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n",
      "4 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n",
      "\n",
      "           y_38          z_38          x_39          y_39          z_39  \\\n",
      "0 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
      "1 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
      "2 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
      "3 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
      "4 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
      "\n",
      "           x_40          y_40          z_40  \n",
      "0 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n",
      "1 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n",
      "2 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n",
      "3 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n",
      "4 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n",
      "\n",
      "[5 rows x 123 columns]\n",
      "\n",
      "Validation Sequences DataFrame:\n",
      "  target_id                                           sequence  \\\n",
      "0     R1107  GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...   \n",
      "1     R1108  GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUU...   \n",
      "2     R1116  CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGG...   \n",
      "3   R1117v2                     UUGGGUUCCCUCACCCCAAUCAUAAAAAGG   \n",
      "4     R1126  GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUU...   \n",
      "\n",
      "  temporal_cutoff                                        description  \\\n",
      "0      2022-05-28  CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...   \n",
      "1      2022-05-27  CPEB3 ribozyme\\nChimpanzee\\nChimpanzee CPEB3 H...   \n",
      "2      2022-06-04  Cloverleaf RNA\\nPoliovirus\\nCrystal Structure ...   \n",
      "3      2022-06-03  PreQ1 class I type III riboswitch\\nK. pneumoni...   \n",
      "4      2022-06-11  Traptamer\\nSynthetic\\nAdditional Information: ...   \n",
      "\n",
      "                                       all_sequences  \n",
      "0  >7QR4_1|Chain A|U1 small nuclear ribonucleopro...  \n",
      "1  >7QR3_1|Chains A, B|U1 small nuclear ribonucle...  \n",
      "2  >8S95_1|Chain A[auth C]|Lysine tRNA scaffold,P...  \n",
      "3  >8FZA_1|Chains A, B|PreQ1 Riboswitch (30-MER)|...  \n",
      "4  >8TVZ_1|Chain A[auth C]|RNA (363-MER)|syntheti...  \n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "sample_submission = Path(\"Resources/sample_submission.csv\")\n",
    "test_sequences = Path(\"Resources/test_sequences.csv\")\n",
    "train_labels = Path(\"Resources/train_labels.csv\")\n",
    "train_sequences = Path(\"Resources/train_sequences.csv\")\n",
    "validation_labels = Path(\"Resources/validation_labels.csv\")\n",
    "validation_sequences_path = Path(\"Resources/validation_sequences.csv\")  # Rename variable\n",
    "\n",
    "# Read CSV files into DataFrames\n",
    "sample_submission_df = pd.read_csv(sample_submission)\n",
    "test_sequences_df = pd.read_csv(test_sequences)\n",
    "train_labels_df = pd.read_csv(train_labels)\n",
    "train_sequences_df = pd.read_csv(train_sequences)\n",
    "validation_labels_df = pd.read_csv(validation_labels)\n",
    "validation_sequences_df = pd.read_csv(validation_sequences_path)  # Use renamed variable\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Sample Submission DataFrame:\")\n",
    "print(sample_submission_df.head())\n",
    "\n",
    "print(\"\\nTest Sequences DataFrame:\")\n",
    "print(test_sequences_df.head())\n",
    "\n",
    "print(\"\\nTrain Labels DataFrame:\")\n",
    "print(train_labels_df.head())\n",
    "\n",
    "print(\"\\nTrain Sequences DataFrame:\")\n",
    "print(train_sequences_df.head())\n",
    "\n",
    "print(\"\\nValidation Labels DataFrame:\")\n",
    "print(validation_labels_df.head())\n",
    "\n",
    "print(\"\\nValidation Sequences DataFrame:\")\n",
    "print(validation_sequences_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7da76a-286e-441c-82be-77dad2a05bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x4000 with 272 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize pairwise relationships\n",
    "sns.pairplot(sample_submission_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb1b2d9-328e-4278-9284-89e1e9898274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select only numeric columns for correlation analysis\n",
    "numeric_data = sample_submission_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Generate the heatmap\n",
    "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33593d2-249e-46e7-b3f4-ad956b952c6e",
   "metadata": {},
   "source": [
    "Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8c2f3d-9aaf-483d-bafa-e368572f5cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>target_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>temporal_cutoff</th>\n",
       "      <th>description</th>\n",
       "      <th>all_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SCL_A_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>13.760</td>\n",
       "      <td>-25.974001</td>\n",
       "      <td>0.102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1SCL_A_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>9.310</td>\n",
       "      <td>-29.638000</td>\n",
       "      <td>2.669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1SCL_A_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>5.529</td>\n",
       "      <td>-27.813000</td>\n",
       "      <td>5.878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1SCL_A_4</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>2.678</td>\n",
       "      <td>-24.900999</td>\n",
       "      <td>9.793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1SCL_A_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>1.827</td>\n",
       "      <td>-20.136000</td>\n",
       "      <td>11.793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID resname  resid     x_1        y_1     z_1 target_id sequence  \\\n",
       "0  1SCL_A_1       G      1  13.760 -25.974001   0.102       NaN      NaN   \n",
       "1  1SCL_A_2       G      2   9.310 -29.638000   2.669       NaN      NaN   \n",
       "2  1SCL_A_3       G      3   5.529 -27.813000   5.878       NaN      NaN   \n",
       "3  1SCL_A_4       U      4   2.678 -24.900999   9.793       NaN      NaN   \n",
       "4  1SCL_A_5       G      5   1.827 -20.136000  11.793       NaN      NaN   \n",
       "\n",
       "  temporal_cutoff description all_sequences  \n",
       "0             NaN         NaN           NaN  \n",
       "1             NaN         NaN           NaN  \n",
       "2             NaN         NaN           NaN  \n",
       "3             NaN         NaN           NaN  \n",
       "4             NaN         NaN           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge sequence and structural data based on target_id\n",
    "merged_df = pd.merge(train_labels_df, train_sequences_df, left_on='ID', right_on='target_id', how='left')\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ebc19-054a-46fd-9604-f08285847f36",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447cb29-0a30-4e15-8379-b20fd3f8e52c",
   "metadata": {},
   "source": [
    "Failed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3709a9f-1237-43c8-8f9d-7ccaeae1fb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/816950566.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merged_df.fillna('', inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/816950566.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Normalize coordinate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Display the first few rows of the processed DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \"\"\"\n\u001b[1;32m    874\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \"\"\"\n\u001b[1;32m    911\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    913\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    994\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m                 raise ValueError(\n\u001b[1;32m   1000\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "merged_df.fillna('', inplace=True)\n",
    "\n",
    "# Clean and preprocess the sequences\n",
    "merged_df['sequence'] = merged_df['sequence'].str.strip().str.replace('\\n', '')\n",
    "\n",
    "# Normalize coordinate data\n",
    "scaler = StandardScaler()\n",
    "merged_df[['x_1', 'y_1', 'z_1']] = scaler.fit_transform(merged_df[['x_1', 'y_1', 'z_1']])\n",
    "\n",
    "# Display the first few rows of the processed DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93dfe238-12c0-4b23-aeeb-a622b054d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x_1    y_1    z_1\n",
      "0        True   True   True\n",
      "1        True   True   True\n",
      "2        True   True   True\n",
      "3        True   True   True\n",
      "4        True   True   True\n",
      "...       ...    ...    ...\n",
      "137090  False  False  False\n",
      "137091  False  False  False\n",
      "137092  False  False  False\n",
      "137093  False  False  False\n",
      "137094  False  False  False\n",
      "\n",
      "[137095 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/1376466223.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  print(merged_df[['x_1', 'y_1', 'z_1']].applymap(lambda x: isinstance(x, (int, float))))\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric values in the coordinate columns\n",
    "print(merged_df[['x_1', 'y_1', 'z_1']].applymap(lambda x: isinstance(x, (int, float))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1515e-55b4-4393-946c-ce76237ce8e6",
   "metadata": {},
   "source": [
    "# After the above code failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d968c16-2445-4080-8b86-7c4d13732434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID resname  resid       x_1       y_1       z_1 target_id sequence  \\\n",
      "0  1SCL_A_1       G      1 -0.462849 -0.979448 -0.844099                      \n",
      "1  1SCL_A_2       G      2 -0.493735 -1.012068 -0.822103                      \n",
      "2  1SCL_A_3       G      3 -0.519977 -0.995820 -0.794606                      \n",
      "3  1SCL_A_4       U      4 -0.539765 -0.969895 -0.761060                      \n",
      "4  1SCL_A_5       G      5 -0.545671 -0.927473 -0.743922                      \n",
      "\n",
      "  temporal_cutoff description all_sequences  \n",
      "0                                            \n",
      "1                                            \n",
      "2                                            \n",
      "3                                            \n",
      "4                                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/3663280842.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['x_1'].fillna(merged_df['x_1'].mean(), inplace=True)\n",
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/3663280842.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['y_1'].fillna(merged_df['y_1'].mean(), inplace=True)\n",
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/3663280842.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['z_1'].fillna(merged_df['z_1'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace non-numeric values with NaN\n",
    "merged_df[['x_1', 'y_1', 'z_1']] = merged_df[['x_1', 'y_1', 'z_1']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values with the mean of their respective columns\n",
    "merged_df['x_1'].fillna(merged_df['x_1'].mean(), inplace=True)\n",
    "merged_df['y_1'].fillna(merged_df['y_1'].mean(), inplace=True)\n",
    "merged_df['z_1'].fillna(merged_df['z_1'].mean(), inplace=True)\n",
    "\n",
    "# Normalize coordinate data\n",
    "scaler = StandardScaler()\n",
    "merged_df[['x_1', 'y_1', 'z_1']] = scaler.fit_transform(merged_df[['x_1', 'y_1', 'z_1']])\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7905e-164c-495e-9c42-febb4078a589",
   "metadata": {},
   "source": [
    "# creating targets with the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7643cc9-c78c-4839-a2d6-0874ef348869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.6285e-01, -9.7945e-01, -8.4410e-01],\n",
      "        [-4.9374e-01, -1.0121e+00, -8.2210e-01],\n",
      "        [-5.1998e-01, -9.9582e-01, -7.9461e-01],\n",
      "        ...,\n",
      "        [-9.8632e-17,  0.0000e+00,  1.2177e-16],\n",
      "        [-9.8632e-17,  0.0000e+00,  1.2177e-16],\n",
      "        [-9.8632e-17,  0.0000e+00,  1.2177e-16]])\n"
     ]
    }
   ],
   "source": [
    "# Dummy example: Creating targets with the same shape as input data\n",
    "data = {}  # Initialize a dictionary to hold data (assuming a PyTorch-Geometric Data object later)\n",
    "data['y'] = torch.tensor(merged_df[['x_1', 'y_1', 'z_1']].values, dtype=torch.float)\n",
    "\n",
    "# Display the tensor to verify\n",
    "print(data['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430ac6b-efed-48bd-96da-f70e1a58d3e6",
   "metadata": {},
   "source": [
    "# Define a GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dc44735-0eaf-424f-a4fb-b8a8a97adace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/100, Training Loss: 1.0453894138336182, Validation Loss: 0.9962837100028992\n",
      "Epoch 2/100, Training Loss: 1.0299867391586304, Validation Loss: 0.9817377924919128\n",
      "Epoch 3/100, Training Loss: 1.011953592300415, Validation Loss: 0.9674208760261536\n",
      "Epoch 4/100, Training Loss: 1.0011566877365112, Validation Loss: 0.9533292055130005\n",
      "Epoch 5/100, Training Loss: 0.9853573441505432, Validation Loss: 0.9394527673721313\n",
      "Epoch 6/100, Training Loss: 0.9734222292900085, Validation Loss: 0.925784170627594\n",
      "Epoch 7/100, Training Loss: 0.9606046676635742, Validation Loss: 0.9123210906982422\n",
      "Epoch 8/100, Training Loss: 0.9460705518722534, Validation Loss: 0.8990572690963745\n",
      "Epoch 9/100, Training Loss: 0.9345507025718689, Validation Loss: 0.8859871625900269\n",
      "Epoch 10/100, Training Loss: 0.9207971692085266, Validation Loss: 0.8731099367141724\n",
      "Epoch 11/100, Training Loss: 0.9061523079872131, Validation Loss: 0.8604149222373962\n",
      "Epoch 12/100, Training Loss: 0.8973925113677979, Validation Loss: 0.8478927612304688\n",
      "Epoch 13/100, Training Loss: 0.8836411237716675, Validation Loss: 0.8355306386947632\n",
      "Epoch 14/100, Training Loss: 0.8738391995429993, Validation Loss: 0.8233230113983154\n",
      "Epoch 15/100, Training Loss: 0.858993649482727, Validation Loss: 0.8112560510635376\n",
      "Epoch 16/100, Training Loss: 0.8482785820960999, Validation Loss: 0.7993310689926147\n",
      "Epoch 17/100, Training Loss: 0.8377357125282288, Validation Loss: 0.7875387668609619\n",
      "Epoch 18/100, Training Loss: 0.8263183832168579, Validation Loss: 0.7758868932723999\n",
      "Epoch 19/100, Training Loss: 0.8128019571304321, Validation Loss: 0.7643734216690063\n",
      "Epoch 20/100, Training Loss: 0.8054577708244324, Validation Loss: 0.752997875213623\n",
      "Epoch 21/100, Training Loss: 0.7921810150146484, Validation Loss: 0.7417574524879456\n",
      "Epoch 22/100, Training Loss: 0.7803662419319153, Validation Loss: 0.7306506633758545\n",
      "Epoch 23/100, Training Loss: 0.7678421139717102, Validation Loss: 0.719670295715332\n",
      "Epoch 24/100, Training Loss: 0.7591629028320312, Validation Loss: 0.7088142037391663\n",
      "Epoch 25/100, Training Loss: 0.7477893829345703, Validation Loss: 0.6980798244476318\n",
      "Epoch 26/100, Training Loss: 0.7399997711181641, Validation Loss: 0.6874709725379944\n",
      "Epoch 27/100, Training Loss: 0.7266001105308533, Validation Loss: 0.676978588104248\n",
      "Epoch 28/100, Training Loss: 0.7188549637794495, Validation Loss: 0.6666035652160645\n",
      "Epoch 29/100, Training Loss: 0.7080255150794983, Validation Loss: 0.6563364863395691\n",
      "Epoch 30/100, Training Loss: 0.7001479864120483, Validation Loss: 0.6461670398712158\n",
      "Epoch 31/100, Training Loss: 0.6902400851249695, Validation Loss: 0.6361027956008911\n",
      "Epoch 32/100, Training Loss: 0.682393491268158, Validation Loss: 0.6261279582977295\n",
      "Epoch 33/100, Training Loss: 0.6701131463050842, Validation Loss: 0.6162288784980774\n",
      "Epoch 34/100, Training Loss: 0.6605409979820251, Validation Loss: 0.6064016819000244\n",
      "Epoch 35/100, Training Loss: 0.6527353525161743, Validation Loss: 0.5966389775276184\n",
      "Epoch 36/100, Training Loss: 0.6414333581924438, Validation Loss: 0.5869392156600952\n",
      "Epoch 37/100, Training Loss: 0.6346431970596313, Validation Loss: 0.5772932767868042\n",
      "Epoch 38/100, Training Loss: 0.6284500360488892, Validation Loss: 0.567693829536438\n",
      "Epoch 39/100, Training Loss: 0.6143867373466492, Validation Loss: 0.5581283569335938\n",
      "Epoch 40/100, Training Loss: 0.6045578718185425, Validation Loss: 0.5485800504684448\n",
      "Epoch 41/100, Training Loss: 0.5973440408706665, Validation Loss: 0.5390464067459106\n",
      "Epoch 42/100, Training Loss: 0.5899456143379211, Validation Loss: 0.5295160412788391\n",
      "Epoch 43/100, Training Loss: 0.5782443881034851, Validation Loss: 0.5199800133705139\n",
      "Epoch 44/100, Training Loss: 0.5714336633682251, Validation Loss: 0.5104310512542725\n",
      "Epoch 45/100, Training Loss: 0.5612728595733643, Validation Loss: 0.500857949256897\n",
      "Epoch 46/100, Training Loss: 0.5521640777587891, Validation Loss: 0.4912542402744293\n",
      "Epoch 47/100, Training Loss: 0.544727623462677, Validation Loss: 0.4816250205039978\n",
      "Epoch 48/100, Training Loss: 0.537067711353302, Validation Loss: 0.4719686806201935\n",
      "Epoch 49/100, Training Loss: 0.5280027389526367, Validation Loss: 0.46227654814720154\n",
      "Epoch 50/100, Training Loss: 0.5191555023193359, Validation Loss: 0.4525381624698639\n",
      "Epoch 51/100, Training Loss: 0.5097153186798096, Validation Loss: 0.44276171922683716\n",
      "Epoch 52/100, Training Loss: 0.5022408366203308, Validation Loss: 0.4329482316970825\n",
      "Epoch 53/100, Training Loss: 0.49228623509407043, Validation Loss: 0.4231065511703491\n",
      "Epoch 54/100, Training Loss: 0.4877634644508362, Validation Loss: 0.41325512528419495\n",
      "Epoch 55/100, Training Loss: 0.478773832321167, Validation Loss: 0.4034116864204407\n",
      "Epoch 56/100, Training Loss: 0.47077202796936035, Validation Loss: 0.39359161257743835\n",
      "Epoch 57/100, Training Loss: 0.4587077498435974, Validation Loss: 0.3838061988353729\n",
      "Epoch 58/100, Training Loss: 0.45286306738853455, Validation Loss: 0.3740711808204651\n",
      "Epoch 59/100, Training Loss: 0.4458412230014801, Validation Loss: 0.3643985688686371\n",
      "Epoch 60/100, Training Loss: 0.4366653263568878, Validation Loss: 0.35479915142059326\n",
      "Epoch 61/100, Training Loss: 0.42958182096481323, Validation Loss: 0.34529465436935425\n",
      "Epoch 62/100, Training Loss: 0.42228928208351135, Validation Loss: 0.3358963131904602\n",
      "Epoch 63/100, Training Loss: 0.4129412770271301, Validation Loss: 0.32661429047584534\n",
      "Epoch 64/100, Training Loss: 0.4063222110271454, Validation Loss: 0.3174605667591095\n",
      "Epoch 65/100, Training Loss: 0.4007158577442169, Validation Loss: 0.30844274163246155\n",
      "Epoch 66/100, Training Loss: 0.39320099353790283, Validation Loss: 0.2995750308036804\n",
      "Epoch 67/100, Training Loss: 0.38172921538352966, Validation Loss: 0.29086288809776306\n",
      "Epoch 68/100, Training Loss: 0.37973999977111816, Validation Loss: 0.28232261538505554\n",
      "Epoch 69/100, Training Loss: 0.37085893750190735, Validation Loss: 0.2739590108394623\n",
      "Epoch 70/100, Training Loss: 0.36661297082901, Validation Loss: 0.2657869756221771\n",
      "Epoch 71/100, Training Loss: 0.35863301157951355, Validation Loss: 0.25780928134918213\n",
      "Epoch 72/100, Training Loss: 0.35056158900260925, Validation Loss: 0.2500323951244354\n",
      "Epoch 73/100, Training Loss: 0.345854789018631, Validation Loss: 0.24246369302272797\n",
      "Epoch 74/100, Training Loss: 0.3411809504032135, Validation Loss: 0.23510129749774933\n",
      "Epoch 75/100, Training Loss: 0.33218884468078613, Validation Loss: 0.22795657813549042\n",
      "Epoch 76/100, Training Loss: 0.32773855328559875, Validation Loss: 0.22102554142475128\n",
      "Epoch 77/100, Training Loss: 0.3197092115879059, Validation Loss: 0.21431438624858856\n",
      "Epoch 78/100, Training Loss: 0.31547653675079346, Validation Loss: 0.2078232765197754\n",
      "Epoch 79/100, Training Loss: 0.310021311044693, Validation Loss: 0.20155450701713562\n",
      "Epoch 80/100, Training Loss: 0.3072918951511383, Validation Loss: 0.1955070197582245\n",
      "Epoch 81/100, Training Loss: 0.3040783405303955, Validation Loss: 0.18967832624912262\n",
      "Epoch 82/100, Training Loss: 0.2994014322757721, Validation Loss: 0.1840699017047882\n",
      "Epoch 83/100, Training Loss: 0.29307660460472107, Validation Loss: 0.17867805063724518\n",
      "Epoch 84/100, Training Loss: 0.2903507947921753, Validation Loss: 0.17350153625011444\n",
      "Epoch 85/100, Training Loss: 0.28383663296699524, Validation Loss: 0.16853554546833038\n",
      "Epoch 86/100, Training Loss: 0.28042078018188477, Validation Loss: 0.1637715846300125\n",
      "Epoch 87/100, Training Loss: 0.2762787640094757, Validation Loss: 0.1592075228691101\n",
      "Epoch 88/100, Training Loss: 0.27148717641830444, Validation Loss: 0.15484246611595154\n",
      "Epoch 89/100, Training Loss: 0.26876071095466614, Validation Loss: 0.15066774189472198\n",
      "Epoch 90/100, Training Loss: 0.2643696665763855, Validation Loss: 0.14668221771717072\n",
      "Epoch 91/100, Training Loss: 0.2646417021751404, Validation Loss: 0.14287914335727692\n",
      "Epoch 92/100, Training Loss: 0.2617568075656891, Validation Loss: 0.1392514705657959\n",
      "Epoch 93/100, Training Loss: 0.2567930221557617, Validation Loss: 0.13579584658145905\n",
      "Epoch 94/100, Training Loss: 0.253076434135437, Validation Loss: 0.13250714540481567\n",
      "Epoch 95/100, Training Loss: 0.24914617836475372, Validation Loss: 0.12937970459461212\n",
      "Epoch 96/100, Training Loss: 0.2492697834968567, Validation Loss: 0.12640823423862457\n",
      "Epoch 97/100, Training Loss: 0.24507395923137665, Validation Loss: 0.1235843375325203\n",
      "Epoch 98/100, Training Loss: 0.24242433905601501, Validation Loss: 0.1209007054567337\n",
      "Epoch 99/100, Training Loss: 0.2399616688489914, Validation Loss: 0.11834921687841415\n",
      "Epoch 100/100, Training Loss: 0.23952922224998474, Validation Loss: 0.11592505872249603\n",
      "R² Score: 0.8862, MAE: 0.2297\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.005}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_4826/1957935757.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.5760490894317627, Validation Loss: 1.3889212608337402\n",
      "Epoch 2/100, Training Loss: 1.4565647840499878, Validation Loss: 1.28983736038208\n",
      "Epoch 3/100, Training Loss: 1.348681092262268, Validation Loss: 1.2008270025253296\n",
      "Epoch 4/100, Training Loss: 1.2555184364318848, Validation Loss: 1.1204980611801147\n",
      "Epoch 5/100, Training Loss: 1.1712498664855957, Validation Loss: 1.047957181930542\n",
      "Epoch 6/100, Training Loss: 1.0952948331832886, Validation Loss: 0.982769787311554\n",
      "Epoch 7/100, Training Loss: 1.0293368101119995, Validation Loss: 0.9243015050888062\n",
      "Epoch 8/100, Training Loss: 0.9702360033988953, Validation Loss: 0.8725637793540955\n",
      "Epoch 9/100, Training Loss: 0.9194204807281494, Validation Loss: 0.8280090093612671\n",
      "Epoch 10/100, Training Loss: 0.8736321330070496, Validation Loss: 0.7892374396324158\n",
      "Epoch 11/100, Training Loss: 0.8306469321250916, Validation Loss: 0.7537121176719666\n",
      "Epoch 12/100, Training Loss: 0.7906252145767212, Validation Loss: 0.7200372815132141\n",
      "Epoch 13/100, Training Loss: 0.7577726244926453, Validation Loss: 0.6876054406166077\n",
      "Epoch 14/100, Training Loss: 0.7246466875076294, Validation Loss: 0.6559858322143555\n",
      "Epoch 15/100, Training Loss: 0.6905386447906494, Validation Loss: 0.6249938607215881\n",
      "Epoch 16/100, Training Loss: 0.6607003808021545, Validation Loss: 0.5946537852287292\n",
      "Epoch 17/100, Training Loss: 0.6329734325408936, Validation Loss: 0.5647974014282227\n",
      "Epoch 18/100, Training Loss: 0.6042293310165405, Validation Loss: 0.5352281928062439\n",
      "Epoch 19/100, Training Loss: 0.575097918510437, Validation Loss: 0.5057164430618286\n",
      "Epoch 20/100, Training Loss: 0.5491521954536438, Validation Loss: 0.4761911928653717\n",
      "Epoch 21/100, Training Loss: 0.5209460258483887, Validation Loss: 0.446621298789978\n",
      "Epoch 22/100, Training Loss: 0.4941762685775757, Validation Loss: 0.4171191453933716\n",
      "Epoch 23/100, Training Loss: 0.4685758352279663, Validation Loss: 0.3879505395889282\n",
      "Epoch 24/100, Training Loss: 0.4415970742702484, Validation Loss: 0.35937488079071045\n",
      "Epoch 25/100, Training Loss: 0.41815584897994995, Validation Loss: 0.3316505253314972\n",
      "Epoch 26/100, Training Loss: 0.3944874703884125, Validation Loss: 0.3051002621650696\n",
      "Epoch 27/100, Training Loss: 0.37345534563064575, Validation Loss: 0.2800329625606537\n",
      "Epoch 28/100, Training Loss: 0.3478377163410187, Validation Loss: 0.2567415237426758\n",
      "Epoch 29/100, Training Loss: 0.3290797472000122, Validation Loss: 0.23546795547008514\n",
      "Epoch 30/100, Training Loss: 0.3130194842815399, Validation Loss: 0.21631059050559998\n",
      "Epoch 31/100, Training Loss: 0.29410475492477417, Validation Loss: 0.19928893446922302\n",
      "Epoch 32/100, Training Loss: 0.2826741933822632, Validation Loss: 0.18443503975868225\n",
      "Epoch 33/100, Training Loss: 0.2701229155063629, Validation Loss: 0.17161263525485992\n",
      "Epoch 34/100, Training Loss: 0.26347318291664124, Validation Loss: 0.1605531871318817\n",
      "Epoch 35/100, Training Loss: 0.2541874647140503, Validation Loss: 0.15090312063694\n",
      "Epoch 36/100, Training Loss: 0.24512644112110138, Validation Loss: 0.14226968586444855\n",
      "Epoch 37/100, Training Loss: 0.23810464143753052, Validation Loss: 0.1344284564256668\n",
      "Epoch 38/100, Training Loss: 0.23197777569293976, Validation Loss: 0.12725502252578735\n",
      "Epoch 39/100, Training Loss: 0.22723525762557983, Validation Loss: 0.12070171535015106\n",
      "Epoch 40/100, Training Loss: 0.22081957757472992, Validation Loss: 0.11478661745786667\n",
      "Epoch 41/100, Training Loss: 0.21427567303180695, Validation Loss: 0.10956531018018723\n",
      "Epoch 42/100, Training Loss: 0.21098262071609497, Validation Loss: 0.10516046732664108\n",
      "Epoch 43/100, Training Loss: 0.206959068775177, Validation Loss: 0.10157787054777145\n",
      "Epoch 44/100, Training Loss: 0.20071500539779663, Validation Loss: 0.09879255294799805\n",
      "Epoch 45/100, Training Loss: 0.19773662090301514, Validation Loss: 0.09678064286708832\n",
      "Epoch 46/100, Training Loss: 0.195822075009346, Validation Loss: 0.09539466351270676\n",
      "Epoch 47/100, Training Loss: 0.1934538036584854, Validation Loss: 0.09448260813951492\n",
      "Epoch 48/100, Training Loss: 0.19296540319919586, Validation Loss: 0.09386967122554779\n",
      "Epoch 49/100, Training Loss: 0.19022560119628906, Validation Loss: 0.093416228890419\n",
      "Epoch 50/100, Training Loss: 0.1871892362833023, Validation Loss: 0.09305312484502792\n",
      "Epoch 51/100, Training Loss: 0.1836456060409546, Validation Loss: 0.09263822436332703\n",
      "Epoch 52/100, Training Loss: 0.180399551987648, Validation Loss: 0.09209572523832321\n",
      "Epoch 53/100, Training Loss: 0.17808569967746735, Validation Loss: 0.09135350584983826\n",
      "Epoch 54/100, Training Loss: 0.17429853975772858, Validation Loss: 0.09040995687246323\n",
      "Epoch 55/100, Training Loss: 0.17046377062797546, Validation Loss: 0.08924347162246704\n",
      "Epoch 56/100, Training Loss: 0.16945219039916992, Validation Loss: 0.08794333040714264\n",
      "Epoch 57/100, Training Loss: 0.1659071296453476, Validation Loss: 0.08652884513139725\n",
      "Epoch 58/100, Training Loss: 0.16434727609157562, Validation Loss: 0.0850735530257225\n",
      "Epoch 59/100, Training Loss: 0.16154755651950836, Validation Loss: 0.0837225466966629\n",
      "Epoch 60/100, Training Loss: 0.15878470242023468, Validation Loss: 0.08258919417858124\n",
      "Epoch 61/100, Training Loss: 0.15736208856105804, Validation Loss: 0.0817929282784462\n",
      "Epoch 62/100, Training Loss: 0.15552985668182373, Validation Loss: 0.08129439502954483\n",
      "Epoch 63/100, Training Loss: 0.15247435867786407, Validation Loss: 0.08105938881635666\n",
      "Epoch 64/100, Training Loss: 0.1537953019142151, Validation Loss: 0.08084361255168915\n",
      "Epoch 65/100, Training Loss: 0.15187758207321167, Validation Loss: 0.08055941015481949\n",
      "Epoch 66/100, Training Loss: 0.14869998395442963, Validation Loss: 0.08022838830947876\n",
      "Epoch 67/100, Training Loss: 0.14864487946033478, Validation Loss: 0.07976096868515015\n",
      "Epoch 68/100, Training Loss: 0.148157000541687, Validation Loss: 0.07916870713233948\n",
      "Epoch 69/100, Training Loss: 0.14665886759757996, Validation Loss: 0.07847756892442703\n",
      "Epoch 70/100, Training Loss: 0.1440824568271637, Validation Loss: 0.07773745805025101\n",
      "Epoch 71/100, Training Loss: 0.14185331761837006, Validation Loss: 0.07698529958724976\n",
      "Epoch 72/100, Training Loss: 0.1400420218706131, Validation Loss: 0.07624004781246185\n",
      "Epoch 73/100, Training Loss: 0.13918673992156982, Validation Loss: 0.07555907964706421\n",
      "Epoch 74/100, Training Loss: 0.13742408156394958, Validation Loss: 0.07494296878576279\n",
      "Epoch 75/100, Training Loss: 0.13858018815517426, Validation Loss: 0.07433875650167465\n",
      "Epoch 76/100, Training Loss: 0.13643336296081543, Validation Loss: 0.0737197995185852\n",
      "Epoch 77/100, Training Loss: 0.1334887146949768, Validation Loss: 0.07307981699705124\n",
      "Epoch 78/100, Training Loss: 0.1328553557395935, Validation Loss: 0.07248033583164215\n",
      "Epoch 79/100, Training Loss: 0.1317804455757141, Validation Loss: 0.07187018543481827\n",
      "Epoch 80/100, Training Loss: 0.13026975095272064, Validation Loss: 0.07125882804393768\n",
      "Epoch 81/100, Training Loss: 0.13002923130989075, Validation Loss: 0.07058275490999222\n",
      "Epoch 82/100, Training Loss: 0.13005594909191132, Validation Loss: 0.06986016780138016\n",
      "Epoch 83/100, Training Loss: 0.12867453694343567, Validation Loss: 0.06920871138572693\n",
      "Epoch 84/100, Training Loss: 0.1261652410030365, Validation Loss: 0.06852691620588303\n",
      "Epoch 85/100, Training Loss: 0.12534575164318085, Validation Loss: 0.06791099905967712\n",
      "Epoch 86/100, Training Loss: 0.1265878677368164, Validation Loss: 0.06726376712322235\n",
      "Epoch 87/100, Training Loss: 0.12551811337471008, Validation Loss: 0.06661732494831085\n",
      "Epoch 88/100, Training Loss: 0.12461132556200027, Validation Loss: 0.0660334900021553\n",
      "Epoch 89/100, Training Loss: 0.12161366641521454, Validation Loss: 0.06556428223848343\n",
      "Epoch 90/100, Training Loss: 0.12110824137926102, Validation Loss: 0.06518333405256271\n",
      "Epoch 91/100, Training Loss: 0.1218453049659729, Validation Loss: 0.06489910185337067\n",
      "Epoch 92/100, Training Loss: 0.12142208963632584, Validation Loss: 0.06464005261659622\n",
      "Epoch 93/100, Training Loss: 0.1191602274775505, Validation Loss: 0.064432792365551\n",
      "Epoch 94/100, Training Loss: 0.12039171904325485, Validation Loss: 0.06428590416908264\n",
      "Epoch 95/100, Training Loss: 0.11686351895332336, Validation Loss: 0.06426048278808594\n",
      "Epoch 96/100, Training Loss: 0.11915194243192673, Validation Loss: 0.06420284509658813\n",
      "Epoch 97/100, Training Loss: 0.11661691963672638, Validation Loss: 0.06411565095186234\n",
      "Epoch 98/100, Training Loss: 0.11744660139083862, Validation Loss: 0.06402264535427094\n",
      "Epoch 99/100, Training Loss: 0.11564648151397705, Validation Loss: 0.06396394968032837\n",
      "Epoch 100/100, Training Loss: 0.11445872485637665, Validation Loss: 0.06394517421722412\n",
      "R² Score: 0.9376, MAE: 0.1653\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Training Loss: 1.0961191654205322, Validation Loss: 0.9432532787322998\n",
      "Epoch 2/100, Training Loss: 0.9579197764396667, Validation Loss: 0.821090042591095\n",
      "Epoch 3/100, Training Loss: 0.8490495085716248, Validation Loss: 0.7222097516059875\n",
      "Epoch 4/100, Training Loss: 0.7578338384628296, Validation Loss: 0.6395044922828674\n",
      "Epoch 5/100, Training Loss: 0.6855453252792358, Validation Loss: 0.5671883821487427\n",
      "Epoch 6/100, Training Loss: 0.6213288903236389, Validation Loss: 0.5027735829353333\n",
      "Epoch 7/100, Training Loss: 0.5655320882797241, Validation Loss: 0.4443846046924591\n",
      "Epoch 8/100, Training Loss: 0.5194100737571716, Validation Loss: 0.3902840316295624\n",
      "Epoch 9/100, Training Loss: 0.47303688526153564, Validation Loss: 0.3392004370689392\n",
      "Epoch 10/100, Training Loss: 0.42982107400894165, Validation Loss: 0.29017728567123413\n",
      "Epoch 11/100, Training Loss: 0.38882020115852356, Validation Loss: 0.24347113072872162\n",
      "Epoch 12/100, Training Loss: 0.345603346824646, Validation Loss: 0.20073392987251282\n",
      "Epoch 13/100, Training Loss: 0.30037251114845276, Validation Loss: 0.1645793914794922\n",
      "Epoch 14/100, Training Loss: 0.268871545791626, Validation Loss: 0.1376240849494934\n",
      "Epoch 15/100, Training Loss: 0.24298861622810364, Validation Loss: 0.12139610201120377\n",
      "Epoch 16/100, Training Loss: 0.23030750453472137, Validation Loss: 0.11516309529542923\n",
      "Epoch 17/100, Training Loss: 0.22770117223262787, Validation Loss: 0.11533617228269577\n",
      "Epoch 18/100, Training Loss: 0.2319277971982956, Validation Loss: 0.11672251671552658\n",
      "Epoch 19/100, Training Loss: 0.23858077824115753, Validation Loss: 0.11504175513982773\n",
      "Epoch 20/100, Training Loss: 0.2377166450023651, Validation Loss: 0.10866287350654602\n",
      "Epoch 21/100, Training Loss: 0.2325003743171692, Validation Loss: 0.09862121939659119\n",
      "Epoch 22/100, Training Loss: 0.22273339331150055, Validation Loss: 0.08747158944606781\n",
      "Epoch 23/100, Training Loss: 0.2092180848121643, Validation Loss: 0.07773435860872269\n",
      "Epoch 24/100, Training Loss: 0.1975127011537552, Validation Loss: 0.07084726542234421\n",
      "Epoch 25/100, Training Loss: 0.1873110830783844, Validation Loss: 0.06710734218358994\n",
      "Epoch 26/100, Training Loss: 0.1787690669298172, Validation Loss: 0.06596535444259644\n",
      "Epoch 27/100, Training Loss: 0.1699218899011612, Validation Loss: 0.06668173521757126\n",
      "Epoch 28/100, Training Loss: 0.1677623987197876, Validation Loss: 0.0684848353266716\n",
      "Epoch 29/100, Training Loss: 0.16042020916938782, Validation Loss: 0.07073182612657547\n",
      "Epoch 30/100, Training Loss: 0.1571500152349472, Validation Loss: 0.07277687638998032\n",
      "Epoch 31/100, Training Loss: 0.1546369343996048, Validation Loss: 0.07405194640159607\n",
      "Epoch 32/100, Training Loss: 0.14886242151260376, Validation Loss: 0.07411174476146698\n",
      "Epoch 33/100, Training Loss: 0.14686912298202515, Validation Loss: 0.07283468544483185\n",
      "Epoch 34/100, Training Loss: 0.14288969337940216, Validation Loss: 0.07025150954723358\n",
      "Epoch 35/100, Training Loss: 0.1394421011209488, Validation Loss: 0.06655460596084595\n",
      "Epoch 36/100, Training Loss: 0.1362074464559555, Validation Loss: 0.06191401183605194\n",
      "Epoch 37/100, Training Loss: 0.13346312940120697, Validation Loss: 0.05680646374821663\n",
      "Epoch 38/100, Training Loss: 0.13054683804512024, Validation Loss: 0.05153420940041542\n",
      "Epoch 39/100, Training Loss: 0.12882983684539795, Validation Loss: 0.04647810757160187\n",
      "Epoch 40/100, Training Loss: 0.12681996822357178, Validation Loss: 0.041862353682518005\n",
      "Epoch 41/100, Training Loss: 0.12410961836576462, Validation Loss: 0.03819909319281578\n",
      "Epoch 42/100, Training Loss: 0.11988942325115204, Validation Loss: 0.03571677207946777\n",
      "Epoch 43/100, Training Loss: 0.11957284063100815, Validation Loss: 0.034363336861133575\n",
      "Epoch 44/100, Training Loss: 0.11899147182703018, Validation Loss: 0.03392358869314194\n",
      "Epoch 45/100, Training Loss: 0.1157177984714508, Validation Loss: 0.034313637763261795\n",
      "Epoch 46/100, Training Loss: 0.11305779218673706, Validation Loss: 0.035123489797115326\n",
      "Epoch 47/100, Training Loss: 0.11256744712591171, Validation Loss: 0.03595058247447014\n",
      "Epoch 48/100, Training Loss: 0.10947470366954803, Validation Loss: 0.036632832139730453\n",
      "Epoch 49/100, Training Loss: 0.10839205235242844, Validation Loss: 0.03711233288049698\n",
      "Epoch 50/100, Training Loss: 0.1070445254445076, Validation Loss: 0.03723887726664543\n",
      "Epoch 51/100, Training Loss: 0.10560820251703262, Validation Loss: 0.036971546709537506\n",
      "Epoch 52/100, Training Loss: 0.10349515080451965, Validation Loss: 0.036357466131448746\n",
      "Epoch 53/100, Training Loss: 0.10279766470193863, Validation Loss: 0.035507913678884506\n",
      "Epoch 54/100, Training Loss: 0.10280121862888336, Validation Loss: 0.03467494994401932\n",
      "Early stopping triggered\n",
      "R² Score: 0.9660, MAE: 0.1349\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/100, Training Loss: 0.971657931804657, Validation Loss: 0.9601296782493591\n",
      "Epoch 2/100, Training Loss: 0.9517869353294373, Validation Loss: 0.940125584602356\n",
      "Epoch 3/100, Training Loss: 0.9325698614120483, Validation Loss: 0.9203504323959351\n",
      "Epoch 4/100, Training Loss: 0.9127143025398254, Validation Loss: 0.9008353352546692\n",
      "Epoch 5/100, Training Loss: 0.8947964906692505, Validation Loss: 0.8816370368003845\n",
      "Epoch 6/100, Training Loss: 0.8755431771278381, Validation Loss: 0.8628087639808655\n",
      "Epoch 7/100, Training Loss: 0.8588025569915771, Validation Loss: 0.844390332698822\n",
      "Epoch 8/100, Training Loss: 0.8409309387207031, Validation Loss: 0.826421320438385\n",
      "Epoch 9/100, Training Loss: 0.8220053911209106, Validation Loss: 0.8087334036827087\n",
      "Epoch 10/100, Training Loss: 0.8056068420410156, Validation Loss: 0.7912078499794006\n",
      "Epoch 11/100, Training Loss: 0.7855969667434692, Validation Loss: 0.7738130688667297\n",
      "Epoch 12/100, Training Loss: 0.7683730721473694, Validation Loss: 0.7565019130706787\n",
      "Epoch 13/100, Training Loss: 0.7525096535682678, Validation Loss: 0.7391887307167053\n",
      "Epoch 14/100, Training Loss: 0.7351775765419006, Validation Loss: 0.7217414379119873\n",
      "Epoch 15/100, Training Loss: 0.719739556312561, Validation Loss: 0.7041869759559631\n",
      "Epoch 16/100, Training Loss: 0.7019141316413879, Validation Loss: 0.6866747140884399\n",
      "Epoch 17/100, Training Loss: 0.6858755946159363, Validation Loss: 0.6692522168159485\n",
      "Epoch 18/100, Training Loss: 0.6705737113952637, Validation Loss: 0.6519333720207214\n",
      "Epoch 19/100, Training Loss: 0.6527066826820374, Validation Loss: 0.6347230672836304\n",
      "Epoch 20/100, Training Loss: 0.639369547367096, Validation Loss: 0.6176257729530334\n",
      "Epoch 21/100, Training Loss: 0.6212745308876038, Validation Loss: 0.6006479859352112\n",
      "Epoch 22/100, Training Loss: 0.6089844703674316, Validation Loss: 0.5837891101837158\n",
      "Epoch 23/100, Training Loss: 0.590085506439209, Validation Loss: 0.5670568943023682\n",
      "Epoch 24/100, Training Loss: 0.573441743850708, Validation Loss: 0.5504435896873474\n",
      "Epoch 25/100, Training Loss: 0.5605214238166809, Validation Loss: 0.5339584946632385\n",
      "Epoch 26/100, Training Loss: 0.5441387891769409, Validation Loss: 0.517600417137146\n",
      "Epoch 27/100, Training Loss: 0.5310555100440979, Validation Loss: 0.5013689994812012\n",
      "Epoch 28/100, Training Loss: 0.5154507160186768, Validation Loss: 0.48528796434402466\n",
      "Epoch 29/100, Training Loss: 0.5004824995994568, Validation Loss: 0.46938568353652954\n",
      "Epoch 30/100, Training Loss: 0.4877829849720001, Validation Loss: 0.45368990302085876\n",
      "Epoch 31/100, Training Loss: 0.47411561012268066, Validation Loss: 0.43821582198143005\n",
      "Epoch 32/100, Training Loss: 0.4604264199733734, Validation Loss: 0.42298242449760437\n",
      "Epoch 33/100, Training Loss: 0.4465652108192444, Validation Loss: 0.40802812576293945\n",
      "Epoch 34/100, Training Loss: 0.43694207072257996, Validation Loss: 0.3933906853199005\n",
      "Epoch 35/100, Training Loss: 0.42103061079978943, Validation Loss: 0.3790907561779022\n",
      "Epoch 36/100, Training Loss: 0.4102611243724823, Validation Loss: 0.3651530146598816\n",
      "Epoch 37/100, Training Loss: 0.39682093262672424, Validation Loss: 0.35159915685653687\n",
      "Epoch 38/100, Training Loss: 0.3873331844806671, Validation Loss: 0.33845099806785583\n",
      "Epoch 39/100, Training Loss: 0.3749462068080902, Validation Loss: 0.32573801279067993\n",
      "Epoch 40/100, Training Loss: 0.3647042512893677, Validation Loss: 0.3134681284427643\n",
      "Epoch 41/100, Training Loss: 0.35452672839164734, Validation Loss: 0.3016469478607178\n",
      "Epoch 42/100, Training Loss: 0.34275999665260315, Validation Loss: 0.2902824580669403\n",
      "Epoch 43/100, Training Loss: 0.3337530493736267, Validation Loss: 0.27938032150268555\n",
      "Epoch 44/100, Training Loss: 0.32412537932395935, Validation Loss: 0.2689416706562042\n",
      "Epoch 45/100, Training Loss: 0.31670042872428894, Validation Loss: 0.2589725852012634\n",
      "Epoch 46/100, Training Loss: 0.30889859795570374, Validation Loss: 0.24946793913841248\n",
      "Epoch 47/100, Training Loss: 0.299643337726593, Validation Loss: 0.2404129058122635\n",
      "Epoch 48/100, Training Loss: 0.29207056760787964, Validation Loss: 0.23179307579994202\n",
      "Epoch 49/100, Training Loss: 0.2845570743083954, Validation Loss: 0.2235962450504303\n",
      "Epoch 50/100, Training Loss: 0.2793554961681366, Validation Loss: 0.21580465137958527\n",
      "Epoch 51/100, Training Loss: 0.2746560275554657, Validation Loss: 0.2084064930677414\n",
      "Epoch 52/100, Training Loss: 0.26572325825691223, Validation Loss: 0.2013833373785019\n",
      "Epoch 53/100, Training Loss: 0.2588995695114136, Validation Loss: 0.19471298158168793\n",
      "Epoch 54/100, Training Loss: 0.2542377710342407, Validation Loss: 0.18837271630764008\n",
      "Epoch 55/100, Training Loss: 0.24993789196014404, Validation Loss: 0.18234385550022125\n",
      "Epoch 56/100, Training Loss: 0.2453804761171341, Validation Loss: 0.17659825086593628\n",
      "Epoch 57/100, Training Loss: 0.24311846494674683, Validation Loss: 0.1711188554763794\n",
      "Epoch 58/100, Training Loss: 0.23773008584976196, Validation Loss: 0.16588135063648224\n",
      "Epoch 59/100, Training Loss: 0.23222167789936066, Validation Loss: 0.160858616232872\n",
      "Epoch 60/100, Training Loss: 0.22817952930927277, Validation Loss: 0.1560356318950653\n",
      "Epoch 61/100, Training Loss: 0.2245739996433258, Validation Loss: 0.15139228105545044\n",
      "Epoch 62/100, Training Loss: 0.22024448215961456, Validation Loss: 0.14690576493740082\n",
      "Epoch 63/100, Training Loss: 0.2157076597213745, Validation Loss: 0.14255669713020325\n",
      "Epoch 64/100, Training Loss: 0.2140168845653534, Validation Loss: 0.13833078742027283\n",
      "Epoch 65/100, Training Loss: 0.2098652571439743, Validation Loss: 0.13421452045440674\n",
      "Epoch 66/100, Training Loss: 0.20638929307460785, Validation Loss: 0.13020606338977814\n",
      "Epoch 67/100, Training Loss: 0.2033804953098297, Validation Loss: 0.1262953132390976\n",
      "Epoch 68/100, Training Loss: 0.1999460607767105, Validation Loss: 0.12247439473867416\n",
      "Epoch 69/100, Training Loss: 0.19660575687885284, Validation Loss: 0.11873845010995865\n",
      "Epoch 70/100, Training Loss: 0.19411586225032806, Validation Loss: 0.11508166790008545\n",
      "Epoch 71/100, Training Loss: 0.18991097807884216, Validation Loss: 0.11149930953979492\n",
      "Epoch 72/100, Training Loss: 0.18798108398914337, Validation Loss: 0.10799134522676468\n",
      "Epoch 73/100, Training Loss: 0.18232452869415283, Validation Loss: 0.10455518215894699\n",
      "Epoch 74/100, Training Loss: 0.18058012425899506, Validation Loss: 0.10119073837995529\n",
      "Epoch 75/100, Training Loss: 0.17610056698322296, Validation Loss: 0.09789564460515976\n",
      "Epoch 76/100, Training Loss: 0.1745317578315735, Validation Loss: 0.09467262029647827\n",
      "Epoch 77/100, Training Loss: 0.17041894793510437, Validation Loss: 0.0915156751871109\n",
      "Epoch 78/100, Training Loss: 0.16788128018379211, Validation Loss: 0.08843085169792175\n",
      "Epoch 79/100, Training Loss: 0.16580629348754883, Validation Loss: 0.08542308211326599\n",
      "Epoch 80/100, Training Loss: 0.1623091995716095, Validation Loss: 0.08249303698539734\n",
      "Epoch 81/100, Training Loss: 0.1576051265001297, Validation Loss: 0.07964082807302475\n",
      "Epoch 82/100, Training Loss: 0.15618059039115906, Validation Loss: 0.07686775922775269\n",
      "Epoch 83/100, Training Loss: 0.15263114869594574, Validation Loss: 0.07417508214712143\n",
      "Epoch 84/100, Training Loss: 0.15108957886695862, Validation Loss: 0.07156277447938919\n",
      "Epoch 85/100, Training Loss: 0.14896532893180847, Validation Loss: 0.06902968883514404\n",
      "Epoch 86/100, Training Loss: 0.14511297643184662, Validation Loss: 0.06657444685697556\n",
      "Epoch 87/100, Training Loss: 0.14433293044567108, Validation Loss: 0.0641971156001091\n",
      "Epoch 88/100, Training Loss: 0.14049336314201355, Validation Loss: 0.061899758875370026\n",
      "Epoch 89/100, Training Loss: 0.14085562527179718, Validation Loss: 0.05968111753463745\n",
      "Epoch 90/100, Training Loss: 0.13591796159744263, Validation Loss: 0.0575428269803524\n",
      "Epoch 91/100, Training Loss: 0.13318738341331482, Validation Loss: 0.05548115447163582\n",
      "Epoch 92/100, Training Loss: 0.13349275290966034, Validation Loss: 0.05349241569638252\n",
      "Epoch 93/100, Training Loss: 0.1308424174785614, Validation Loss: 0.051576048135757446\n",
      "Epoch 94/100, Training Loss: 0.1297904998064041, Validation Loss: 0.049730200320482254\n",
      "Epoch 95/100, Training Loss: 0.1259712427854538, Validation Loss: 0.0479552261531353\n",
      "Epoch 96/100, Training Loss: 0.12414707988500595, Validation Loss: 0.04625250771641731\n",
      "Epoch 97/100, Training Loss: 0.12388163059949875, Validation Loss: 0.0446150079369545\n",
      "Epoch 98/100, Training Loss: 0.12067381292581558, Validation Loss: 0.043044399470090866\n",
      "Epoch 99/100, Training Loss: 0.11953176558017731, Validation Loss: 0.041538022458553314\n",
      "Epoch 100/100, Training Loss: 0.11813133209943771, Validation Loss: 0.04009496420621872\n",
      "R² Score: 0.9608, MAE: 0.1233\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Training Loss: 1.0195839405059814, Validation Loss: 0.9203358888626099\n",
      "Epoch 2/100, Training Loss: 0.9180831909179688, Validation Loss: 0.8286594748497009\n",
      "Epoch 3/100, Training Loss: 0.8335965275764465, Validation Loss: 0.7453022599220276\n",
      "Epoch 4/100, Training Loss: 0.7519218921661377, Validation Loss: 0.6686568856239319\n",
      "Epoch 5/100, Training Loss: 0.6763175129890442, Validation Loss: 0.5953934192657471\n",
      "Epoch 6/100, Training Loss: 0.6031315922737122, Validation Loss: 0.5240234136581421\n",
      "Epoch 7/100, Training Loss: 0.5340884923934937, Validation Loss: 0.4545056223869324\n",
      "Epoch 8/100, Training Loss: 0.47002720832824707, Validation Loss: 0.3880317807197571\n",
      "Epoch 9/100, Training Loss: 0.41022995114326477, Validation Loss: 0.3259481191635132\n",
      "Epoch 10/100, Training Loss: 0.3522774279117584, Validation Loss: 0.2693620026111603\n",
      "Epoch 11/100, Training Loss: 0.2997846007347107, Validation Loss: 0.21919287741184235\n",
      "Epoch 12/100, Training Loss: 0.26048603653907776, Validation Loss: 0.17682163417339325\n",
      "Epoch 13/100, Training Loss: 0.22693899273872375, Validation Loss: 0.14323318004608154\n",
      "Epoch 14/100, Training Loss: 0.20050427317619324, Validation Loss: 0.11862671375274658\n",
      "Epoch 15/100, Training Loss: 0.183748260140419, Validation Loss: 0.10253030806779861\n",
      "Epoch 16/100, Training Loss: 0.17599518597126007, Validation Loss: 0.09374169260263443\n",
      "Epoch 17/100, Training Loss: 0.17420044541358948, Validation Loss: 0.09012870490550995\n",
      "Epoch 18/100, Training Loss: 0.1772831380367279, Validation Loss: 0.08899012207984924\n",
      "Epoch 19/100, Training Loss: 0.17867252230644226, Validation Loss: 0.08764149993658066\n",
      "Epoch 20/100, Training Loss: 0.17856653034687042, Validation Loss: 0.08438633382320404\n",
      "Epoch 21/100, Training Loss: 0.1761344075202942, Validation Loss: 0.07877537608146667\n",
      "Epoch 22/100, Training Loss: 0.16788442432880402, Validation Loss: 0.07140468060970306\n",
      "Epoch 23/100, Training Loss: 0.15690456330776215, Validation Loss: 0.06339199095964432\n",
      "Epoch 24/100, Training Loss: 0.1463368535041809, Validation Loss: 0.05580588057637215\n",
      "Epoch 25/100, Training Loss: 0.13531260192394257, Validation Loss: 0.04942109063267708\n",
      "Epoch 26/100, Training Loss: 0.12348398566246033, Validation Loss: 0.04467276111245155\n",
      "Epoch 27/100, Training Loss: 0.11628513783216476, Validation Loss: 0.041622012853622437\n",
      "Epoch 28/100, Training Loss: 0.10856137424707413, Validation Loss: 0.04007788002490997\n",
      "Epoch 29/100, Training Loss: 0.10458409041166306, Validation Loss: 0.039651110768318176\n",
      "Epoch 30/100, Training Loss: 0.10147720575332642, Validation Loss: 0.039893731474876404\n",
      "Epoch 31/100, Training Loss: 0.10038019716739655, Validation Loss: 0.04026928171515465\n",
      "Epoch 32/100, Training Loss: 0.09825646877288818, Validation Loss: 0.040439166128635406\n",
      "Epoch 33/100, Training Loss: 0.09648807346820831, Validation Loss: 0.040164414793252945\n",
      "Epoch 34/100, Training Loss: 0.09562300890684128, Validation Loss: 0.03926747292280197\n",
      "Epoch 35/100, Training Loss: 0.0937056764960289, Validation Loss: 0.03776376694440842\n",
      "Epoch 36/100, Training Loss: 0.09140446782112122, Validation Loss: 0.03572377562522888\n",
      "Epoch 37/100, Training Loss: 0.09040477126836777, Validation Loss: 0.033290229737758636\n",
      "Epoch 38/100, Training Loss: 0.08609400689601898, Validation Loss: 0.030629822984337807\n",
      "Epoch 39/100, Training Loss: 0.08552622050046921, Validation Loss: 0.027894994243979454\n",
      "Epoch 40/100, Training Loss: 0.08320450037717819, Validation Loss: 0.025276169180870056\n",
      "Epoch 41/100, Training Loss: 0.0812845528125763, Validation Loss: 0.022743171080946922\n",
      "Epoch 42/100, Training Loss: 0.07908599078655243, Validation Loss: 0.020510917529463768\n",
      "Epoch 43/100, Training Loss: 0.077635258436203, Validation Loss: 0.018728509545326233\n",
      "Epoch 44/100, Training Loss: 0.07654512673616409, Validation Loss: 0.017357803881168365\n",
      "Epoch 45/100, Training Loss: 0.07495260238647461, Validation Loss: 0.01635403372347355\n",
      "Epoch 46/100, Training Loss: 0.07454917579889297, Validation Loss: 0.015694430097937584\n",
      "Epoch 47/100, Training Loss: 0.07372714579105377, Validation Loss: 0.015246333554387093\n",
      "Epoch 48/100, Training Loss: 0.07365584373474121, Validation Loss: 0.015059422701597214\n",
      "Epoch 49/100, Training Loss: 0.07181566208600998, Validation Loss: 0.015093304216861725\n",
      "Epoch 50/100, Training Loss: 0.07085750997066498, Validation Loss: 0.015340256504714489\n",
      "Epoch 51/100, Training Loss: 0.06961183249950409, Validation Loss: 0.015734581276774406\n",
      "Epoch 52/100, Training Loss: 0.06869692355394363, Validation Loss: 0.016238771378993988\n",
      "Epoch 53/100, Training Loss: 0.06826043874025345, Validation Loss: 0.016747260466217995\n",
      "Epoch 54/100, Training Loss: 0.06776870042085648, Validation Loss: 0.017211997881531715\n",
      "Epoch 55/100, Training Loss: 0.0667499452829361, Validation Loss: 0.017612284049391747\n",
      "Epoch 56/100, Training Loss: 0.06613797694444656, Validation Loss: 0.017937786877155304\n",
      "Epoch 57/100, Training Loss: 0.06489045172929764, Validation Loss: 0.01813351735472679\n",
      "Epoch 58/100, Training Loss: 0.06456244736909866, Validation Loss: 0.01825663074851036\n",
      "Early stopping triggered\n",
      "R² Score: 0.9821, MAE: 0.1014\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Training Loss: 1.0960034132003784, Validation Loss: 0.8352445363998413\n",
      "Epoch 2/100, Training Loss: 0.858440101146698, Validation Loss: 0.6361178755760193\n",
      "Epoch 3/100, Training Loss: 0.6675474643707275, Validation Loss: 0.4746900498867035\n",
      "Epoch 4/100, Training Loss: 0.5168159604072571, Validation Loss: 0.35952121019363403\n",
      "Epoch 5/100, Training Loss: 0.4131150245666504, Validation Loss: 0.2833661139011383\n",
      "Epoch 6/100, Training Loss: 0.3449280261993408, Validation Loss: 0.22836777567863464\n",
      "Epoch 7/100, Training Loss: 0.2951657772064209, Validation Loss: 0.17746739089488983\n",
      "Epoch 8/100, Training Loss: 0.25044456124305725, Validation Loss: 0.13326646387577057\n",
      "Epoch 9/100, Training Loss: 0.2118765413761139, Validation Loss: 0.10825937241315842\n",
      "Epoch 10/100, Training Loss: 0.1921137422323227, Validation Loss: 0.10342847555875778\n",
      "Epoch 11/100, Training Loss: 0.19476383924484253, Validation Loss: 0.10357644408941269\n",
      "Epoch 12/100, Training Loss: 0.19674116373062134, Validation Loss: 0.0962308719754219\n",
      "Epoch 13/100, Training Loss: 0.1917782723903656, Validation Loss: 0.08014927804470062\n",
      "Epoch 14/100, Training Loss: 0.17636504769325256, Validation Loss: 0.060437481850385666\n",
      "Epoch 15/100, Training Loss: 0.15793481469154358, Validation Loss: 0.04258504882454872\n",
      "Epoch 16/100, Training Loss: 0.14172577857971191, Validation Loss: 0.030125249177217484\n",
      "Epoch 17/100, Training Loss: 0.1259506344795227, Validation Loss: 0.024208789691329002\n",
      "Epoch 18/100, Training Loss: 0.11734195798635483, Validation Loss: 0.024118177592754364\n",
      "Epoch 19/100, Training Loss: 0.11503233015537262, Validation Loss: 0.027999255806207657\n",
      "Epoch 20/100, Training Loss: 0.11538039892911911, Validation Loss: 0.03310800716280937\n",
      "Epoch 21/100, Training Loss: 0.11630198359489441, Validation Loss: 0.036648448556661606\n",
      "Epoch 22/100, Training Loss: 0.11512509733438492, Validation Loss: 0.03767085820436478\n",
      "Epoch 23/100, Training Loss: 0.1116122156381607, Validation Loss: 0.036884911358356476\n",
      "Epoch 24/100, Training Loss: 0.11057284474372864, Validation Loss: 0.035381291061639786\n",
      "Epoch 25/100, Training Loss: 0.10380713641643524, Validation Loss: 0.03382013365626335\n",
      "Epoch 26/100, Training Loss: 0.10209701210260391, Validation Loss: 0.03192825987935066\n",
      "Epoch 27/100, Training Loss: 0.10019094496965408, Validation Loss: 0.028945405036211014\n",
      "Epoch 28/100, Training Loss: 0.09585849940776825, Validation Loss: 0.025155341252684593\n",
      "Early stopping triggered\n",
      "R² Score: 0.9755, MAE: 0.1135\n",
      "Testing parameters: {'dropout_rate': 0.5, 'hidden_dim': 16, 'learning_rate': 0.001}\n",
      "Epoch 1/100, Training Loss: 1.358973741531372, Validation Loss: 1.1890791654586792\n",
      "Epoch 2/100, Training Loss: 1.3425978422164917, Validation Loss: 1.1744511127471924\n",
      "Epoch 3/100, Training Loss: 1.3193895816802979, Validation Loss: 1.1601436138153076\n",
      "Epoch 4/100, Training Loss: 1.2978100776672363, Validation Loss: 1.1461387872695923\n",
      "Epoch 5/100, Training Loss: 1.2855833768844604, Validation Loss: 1.1324026584625244\n",
      "Epoch 6/100, Training Loss: 1.265582799911499, Validation Loss: 1.1189388036727905\n",
      "Epoch 7/100, Training Loss: 1.2477413415908813, Validation Loss: 1.1057626008987427\n",
      "Epoch 8/100, Training Loss: 1.2304612398147583, Validation Loss: 1.092866063117981\n",
      "Epoch 9/100, Training Loss: 1.216929316520691, Validation Loss: 1.0802392959594727\n",
      "Epoch 10/100, Training Loss: 1.1983956098556519, Validation Loss: 1.0678733587265015\n",
      "Epoch 11/100, Training Loss: 1.1815540790557861, Validation Loss: 1.05575430393219\n",
      "Epoch 12/100, Training Loss: 1.1686229705810547, Validation Loss: 1.0438597202301025\n",
      "Epoch 13/100, Training Loss: 1.1553590297698975, Validation Loss: 1.0321903228759766\n",
      "Epoch 14/100, Training Loss: 1.1413334608078003, Validation Loss: 1.0207291841506958\n",
      "Epoch 15/100, Training Loss: 1.1263662576675415, Validation Loss: 1.0094588994979858\n",
      "Epoch 16/100, Training Loss: 1.114004135131836, Validation Loss: 0.9983699321746826\n",
      "Epoch 17/100, Training Loss: 1.0989729166030884, Validation Loss: 0.9874522686004639\n",
      "Epoch 18/100, Training Loss: 1.0886131525039673, Validation Loss: 0.9766911864280701\n",
      "Epoch 19/100, Training Loss: 1.0712238550186157, Validation Loss: 0.966075599193573\n",
      "Epoch 20/100, Training Loss: 1.0604236125946045, Validation Loss: 0.9555960893630981\n",
      "Epoch 21/100, Training Loss: 1.0480974912643433, Validation Loss: 0.9452409744262695\n",
      "Epoch 22/100, Training Loss: 1.0355902910232544, Validation Loss: 0.9350096583366394\n",
      "Epoch 23/100, Training Loss: 1.0245853662490845, Validation Loss: 0.9249156713485718\n",
      "Epoch 24/100, Training Loss: 1.0129129886627197, Validation Loss: 0.9149564504623413\n",
      "Epoch 25/100, Training Loss: 1.0009710788726807, Validation Loss: 0.9050958156585693\n",
      "Epoch 26/100, Training Loss: 0.9932304620742798, Validation Loss: 0.895332932472229\n",
      "Epoch 27/100, Training Loss: 0.9823212027549744, Validation Loss: 0.8856636881828308\n",
      "Epoch 28/100, Training Loss: 0.9740813374519348, Validation Loss: 0.8760652542114258\n",
      "Epoch 29/100, Training Loss: 0.9580504894256592, Validation Loss: 0.8665358424186707\n",
      "Epoch 30/100, Training Loss: 0.9502695798873901, Validation Loss: 0.8570660352706909\n",
      "Epoch 31/100, Training Loss: 0.9431368708610535, Validation Loss: 0.8476564288139343\n",
      "Epoch 32/100, Training Loss: 0.9307454228401184, Validation Loss: 0.8383110761642456\n",
      "Epoch 33/100, Training Loss: 0.9218174815177917, Validation Loss: 0.8290175199508667\n",
      "Epoch 34/100, Training Loss: 0.9117386937141418, Validation Loss: 0.8197818994522095\n",
      "Epoch 35/100, Training Loss: 0.9027920961380005, Validation Loss: 0.8106071949005127\n",
      "Epoch 36/100, Training Loss: 0.8919403553009033, Validation Loss: 0.8014916181564331\n",
      "Epoch 37/100, Training Loss: 0.8837308287620544, Validation Loss: 0.7924268841743469\n",
      "Epoch 38/100, Training Loss: 0.8768362402915955, Validation Loss: 0.7834035754203796\n",
      "Epoch 39/100, Training Loss: 0.8658910989761353, Validation Loss: 0.7744341492652893\n",
      "Epoch 40/100, Training Loss: 0.8571493029594421, Validation Loss: 0.7655238509178162\n",
      "Epoch 41/100, Training Loss: 0.8498261570930481, Validation Loss: 0.7566828727722168\n",
      "Epoch 42/100, Training Loss: 0.8423649668693542, Validation Loss: 0.747910737991333\n",
      "Epoch 43/100, Training Loss: 0.8347903490066528, Validation Loss: 0.7392137050628662\n",
      "Epoch 44/100, Training Loss: 0.8277424573898315, Validation Loss: 0.7305959463119507\n",
      "Epoch 45/100, Training Loss: 0.8170455694198608, Validation Loss: 0.7220600247383118\n",
      "Epoch 46/100, Training Loss: 0.8081708550453186, Validation Loss: 0.7136046290397644\n",
      "Epoch 47/100, Training Loss: 0.8001536726951599, Validation Loss: 0.705234944820404\n",
      "Epoch 48/100, Training Loss: 0.7914861440658569, Validation Loss: 0.6969532370567322\n",
      "Epoch 49/100, Training Loss: 0.785053551197052, Validation Loss: 0.6887553334236145\n",
      "Epoch 50/100, Training Loss: 0.7805665731430054, Validation Loss: 0.6806416511535645\n",
      "Epoch 51/100, Training Loss: 0.7706135511398315, Validation Loss: 0.6726240515708923\n",
      "Epoch 52/100, Training Loss: 0.7655326724052429, Validation Loss: 0.6647018790245056\n",
      "Epoch 53/100, Training Loss: 0.7562524080276489, Validation Loss: 0.6568676233291626\n",
      "Epoch 54/100, Training Loss: 0.7499487400054932, Validation Loss: 0.649120569229126\n",
      "Epoch 55/100, Training Loss: 0.7397643327713013, Validation Loss: 0.6414569020271301\n",
      "Epoch 56/100, Training Loss: 0.7361737489700317, Validation Loss: 0.6338856220245361\n",
      "Epoch 57/100, Training Loss: 0.7263736128807068, Validation Loss: 0.6264073848724365\n",
      "Epoch 58/100, Training Loss: 0.7221548557281494, Validation Loss: 0.6190196871757507\n",
      "Epoch 59/100, Training Loss: 0.7159847021102905, Validation Loss: 0.6117385029792786\n",
      "Epoch 60/100, Training Loss: 0.7093756794929504, Validation Loss: 0.6045559048652649\n",
      "Epoch 61/100, Training Loss: 0.7029092907905579, Validation Loss: 0.5974783301353455\n",
      "Epoch 62/100, Training Loss: 0.6950638294219971, Validation Loss: 0.5905026197433472\n",
      "Epoch 63/100, Training Loss: 0.6895226240158081, Validation Loss: 0.5836264491081238\n",
      "Epoch 64/100, Training Loss: 0.6873793601989746, Validation Loss: 0.5768449306488037\n",
      "Epoch 65/100, Training Loss: 0.6783246397972107, Validation Loss: 0.5701580047607422\n",
      "Epoch 66/100, Training Loss: 0.6732161045074463, Validation Loss: 0.5635667443275452\n",
      "Epoch 67/100, Training Loss: 0.6662411689758301, Validation Loss: 0.5570673942565918\n",
      "Epoch 68/100, Training Loss: 0.6599450707435608, Validation Loss: 0.5506564974784851\n",
      "Epoch 69/100, Training Loss: 0.656686007976532, Validation Loss: 0.5443338751792908\n",
      "Epoch 70/100, Training Loss: 0.647079348564148, Validation Loss: 0.5380932688713074\n",
      "Epoch 71/100, Training Loss: 0.6444012522697449, Validation Loss: 0.5319381952285767\n",
      "Epoch 72/100, Training Loss: 0.6379252076148987, Validation Loss: 0.5258685350418091\n",
      "Epoch 73/100, Training Loss: 0.6319205164909363, Validation Loss: 0.519881546497345\n",
      "Epoch 74/100, Training Loss: 0.6258876919746399, Validation Loss: 0.513973593711853\n",
      "Epoch 75/100, Training Loss: 0.6212049126625061, Validation Loss: 0.5081408023834229\n",
      "Epoch 76/100, Training Loss: 0.6180719137191772, Validation Loss: 0.5023938417434692\n",
      "Epoch 77/100, Training Loss: 0.6119512319564819, Validation Loss: 0.4967268705368042\n",
      "Epoch 78/100, Training Loss: 0.6058441400527954, Validation Loss: 0.4911387264728546\n",
      "Epoch 79/100, Training Loss: 0.6011056900024414, Validation Loss: 0.48562461137771606\n",
      "Epoch 80/100, Training Loss: 0.5954837799072266, Validation Loss: 0.48018643260002136\n",
      "Epoch 81/100, Training Loss: 0.5949962139129639, Validation Loss: 0.47482138872146606\n",
      "Epoch 82/100, Training Loss: 0.5878088474273682, Validation Loss: 0.4695238769054413\n",
      "Epoch 83/100, Training Loss: 0.5840539932250977, Validation Loss: 0.4643000364303589\n",
      "Epoch 84/100, Training Loss: 0.5798565745353699, Validation Loss: 0.4591415524482727\n",
      "Epoch 85/100, Training Loss: 0.574835479259491, Validation Loss: 0.45404762029647827\n",
      "Epoch 86/100, Training Loss: 0.5711637735366821, Validation Loss: 0.4490090310573578\n",
      "Epoch 87/100, Training Loss: 0.5635679960250854, Validation Loss: 0.4440232217311859\n",
      "Epoch 88/100, Training Loss: 0.5603271126747131, Validation Loss: 0.439083456993103\n",
      "Epoch 89/100, Training Loss: 0.5562843680381775, Validation Loss: 0.4341835677623749\n",
      "Epoch 90/100, Training Loss: 0.554049551486969, Validation Loss: 0.4293225109577179\n",
      "Epoch 91/100, Training Loss: 0.547209620475769, Validation Loss: 0.4244859516620636\n",
      "Epoch 92/100, Training Loss: 0.5477628707885742, Validation Loss: 0.4196924865245819\n",
      "Epoch 93/100, Training Loss: 0.5405593514442444, Validation Loss: 0.41492563486099243\n",
      "Epoch 94/100, Training Loss: 0.5367404818534851, Validation Loss: 0.4101855456829071\n",
      "Epoch 95/100, Training Loss: 0.5331857800483704, Validation Loss: 0.40546736121177673\n",
      "Epoch 96/100, Training Loss: 0.5293555855751038, Validation Loss: 0.40077340602874756\n",
      "Epoch 97/100, Training Loss: 0.521974503993988, Validation Loss: 0.39610227942466736\n",
      "Epoch 98/100, Training Loss: 0.520476222038269, Validation Loss: 0.39145874977111816\n",
      "Epoch 99/100, Training Loss: 0.5178170800209045, Validation Loss: 0.38683202862739563\n",
      "Epoch 100/100, Training Loss: 0.516148567199707, Validation Loss: 0.38223084807395935\n",
      "R² Score: 0.6264, MAE: 0.4324\n",
      "Testing parameters: {'dropout_rate': 0.5, 'hidden_dim': 16, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Training Loss: 0.9982408881187439, Validation Loss: 0.914821207523346\n",
      "Epoch 2/100, Training Loss: 0.9468296766281128, Validation Loss: 0.8614156246185303\n",
      "Epoch 3/100, Training Loss: 0.9012815356254578, Validation Loss: 0.8096441626548767\n",
      "Epoch 4/100, Training Loss: 0.8555932641029358, Validation Loss: 0.7603623270988464\n",
      "Epoch 5/100, Training Loss: 0.8104698657989502, Validation Loss: 0.713270902633667\n",
      "Epoch 6/100, Training Loss: 0.7686325907707214, Validation Loss: 0.6677348017692566\n",
      "Epoch 7/100, Training Loss: 0.7321884036064148, Validation Loss: 0.6230978965759277\n",
      "Epoch 8/100, Training Loss: 0.6935180425643921, Validation Loss: 0.5788382291793823\n",
      "Epoch 9/100, Training Loss: 0.6564461588859558, Validation Loss: 0.5350525379180908\n",
      "Epoch 10/100, Training Loss: 0.6249035000801086, Validation Loss: 0.4928424060344696\n",
      "Epoch 11/100, Training Loss: 0.592812716960907, Validation Loss: 0.4528907239437103\n",
      "Epoch 12/100, Training Loss: 0.563139796257019, Validation Loss: 0.4153340756893158\n",
      "Epoch 13/100, Training Loss: 0.5379266142845154, Validation Loss: 0.3802022635936737\n",
      "Epoch 14/100, Training Loss: 0.51112961769104, Validation Loss: 0.34765222668647766\n",
      "Epoch 15/100, Training Loss: 0.4876374900341034, Validation Loss: 0.31769946217536926\n",
      "Epoch 16/100, Training Loss: 0.46889013051986694, Validation Loss: 0.2903779447078705\n",
      "Epoch 17/100, Training Loss: 0.44531112909317017, Validation Loss: 0.2656444013118744\n",
      "Epoch 18/100, Training Loss: 0.43239569664001465, Validation Loss: 0.24348177015781403\n",
      "Epoch 19/100, Training Loss: 0.415849506855011, Validation Loss: 0.22382216155529022\n",
      "Epoch 20/100, Training Loss: 0.40200695395469666, Validation Loss: 0.2065569907426834\n",
      "Epoch 21/100, Training Loss: 0.3869813084602356, Validation Loss: 0.1915452629327774\n",
      "Epoch 22/100, Training Loss: 0.37974318861961365, Validation Loss: 0.1785433292388916\n",
      "Epoch 23/100, Training Loss: 0.3713812530040741, Validation Loss: 0.16727031767368317\n",
      "Epoch 24/100, Training Loss: 0.3634776771068573, Validation Loss: 0.157516747713089\n",
      "Epoch 25/100, Training Loss: 0.3524293303489685, Validation Loss: 0.14898696541786194\n",
      "Epoch 26/100, Training Loss: 0.3481340706348419, Validation Loss: 0.14139105379581451\n",
      "Epoch 27/100, Training Loss: 0.3406703472137451, Validation Loss: 0.13452757894992828\n",
      "Epoch 28/100, Training Loss: 0.3325618803501129, Validation Loss: 0.12831096351146698\n",
      "Epoch 29/100, Training Loss: 0.32485276460647583, Validation Loss: 0.12276553362607956\n",
      "Epoch 30/100, Training Loss: 0.3186728060245514, Validation Loss: 0.11789637058973312\n",
      "Epoch 31/100, Training Loss: 0.30727261304855347, Validation Loss: 0.11372844874858856\n",
      "Epoch 32/100, Training Loss: 0.30281931161880493, Validation Loss: 0.1103062555193901\n",
      "Epoch 33/100, Training Loss: 0.29415008425712585, Validation Loss: 0.10766573995351791\n",
      "Epoch 34/100, Training Loss: 0.283062607049942, Validation Loss: 0.10570699721574783\n",
      "Epoch 35/100, Training Loss: 0.2791570723056793, Validation Loss: 0.10434404015541077\n",
      "Epoch 36/100, Training Loss: 0.27381598949432373, Validation Loss: 0.10346326231956482\n",
      "Epoch 37/100, Training Loss: 0.27017489075660706, Validation Loss: 0.10292120277881622\n",
      "Epoch 38/100, Training Loss: 0.2620723843574524, Validation Loss: 0.1026676818728447\n",
      "Epoch 39/100, Training Loss: 0.25759604573249817, Validation Loss: 0.10250399261713028\n",
      "Epoch 40/100, Training Loss: 0.2553810775279999, Validation Loss: 0.10228893905878067\n",
      "Epoch 41/100, Training Loss: 0.2514692544937134, Validation Loss: 0.10194911062717438\n",
      "Epoch 42/100, Training Loss: 0.2504240870475769, Validation Loss: 0.10132524371147156\n",
      "Epoch 43/100, Training Loss: 0.2434769719839096, Validation Loss: 0.10049240291118622\n",
      "Epoch 44/100, Training Loss: 0.24185660481452942, Validation Loss: 0.09941917657852173\n",
      "Epoch 45/100, Training Loss: 0.23667776584625244, Validation Loss: 0.09823855012655258\n",
      "Epoch 46/100, Training Loss: 0.23305685818195343, Validation Loss: 0.09701494127511978\n",
      "Epoch 47/100, Training Loss: 0.23188592493534088, Validation Loss: 0.09577983617782593\n",
      "Epoch 48/100, Training Loss: 0.23084141314029694, Validation Loss: 0.09456323832273483\n",
      "Epoch 49/100, Training Loss: 0.22795790433883667, Validation Loss: 0.09341849386692047\n",
      "Epoch 50/100, Training Loss: 0.22421382367610931, Validation Loss: 0.09237820655107498\n",
      "Epoch 51/100, Training Loss: 0.2254101037979126, Validation Loss: 0.0914716050028801\n",
      "Epoch 52/100, Training Loss: 0.22096841037273407, Validation Loss: 0.09072639793157578\n",
      "Epoch 53/100, Training Loss: 0.2226991057395935, Validation Loss: 0.09014258533716202\n",
      "Epoch 54/100, Training Loss: 0.21792185306549072, Validation Loss: 0.08965795487165451\n",
      "Epoch 55/100, Training Loss: 0.21899618208408356, Validation Loss: 0.08921247720718384\n",
      "Epoch 56/100, Training Loss: 0.21314436197280884, Validation Loss: 0.08882026374340057\n",
      "Epoch 57/100, Training Loss: 0.21281352639198303, Validation Loss: 0.0884648784995079\n",
      "Epoch 58/100, Training Loss: 0.2091168910264969, Validation Loss: 0.0881250649690628\n",
      "Epoch 59/100, Training Loss: 0.20692723989486694, Validation Loss: 0.0877598449587822\n",
      "Epoch 60/100, Training Loss: 0.20958839356899261, Validation Loss: 0.08730657398700714\n",
      "Epoch 61/100, Training Loss: 0.20586267113685608, Validation Loss: 0.08678701519966125\n",
      "Epoch 62/100, Training Loss: 0.2039393037557602, Validation Loss: 0.08618708699941635\n",
      "Epoch 63/100, Training Loss: 0.203044131398201, Validation Loss: 0.08543702960014343\n",
      "Epoch 64/100, Training Loss: 0.1995605081319809, Validation Loss: 0.08469164371490479\n",
      "Epoch 65/100, Training Loss: 0.19797518849372864, Validation Loss: 0.08394527435302734\n",
      "Epoch 66/100, Training Loss: 0.197212815284729, Validation Loss: 0.08317742496728897\n",
      "Epoch 67/100, Training Loss: 0.19523657858371735, Validation Loss: 0.08235130459070206\n",
      "Epoch 68/100, Training Loss: 0.1959196776151657, Validation Loss: 0.08158694207668304\n",
      "Epoch 69/100, Training Loss: 0.19509071111679077, Validation Loss: 0.0808132216334343\n",
      "Epoch 70/100, Training Loss: 0.19313187897205353, Validation Loss: 0.0800805315375328\n",
      "Epoch 71/100, Training Loss: 0.19002275168895721, Validation Loss: 0.07938304543495178\n",
      "Epoch 72/100, Training Loss: 0.18852204084396362, Validation Loss: 0.07874536514282227\n",
      "Epoch 73/100, Training Loss: 0.18698237836360931, Validation Loss: 0.07817420363426208\n",
      "Epoch 74/100, Training Loss: 0.18665826320648193, Validation Loss: 0.07764825224876404\n",
      "Epoch 75/100, Training Loss: 0.18510279059410095, Validation Loss: 0.07711419463157654\n",
      "Epoch 76/100, Training Loss: 0.18446604907512665, Validation Loss: 0.07669330388307571\n",
      "Epoch 77/100, Training Loss: 0.1837148815393448, Validation Loss: 0.07637962698936462\n",
      "Epoch 78/100, Training Loss: 0.181685209274292, Validation Loss: 0.07610378414392471\n",
      "Epoch 79/100, Training Loss: 0.1796031892299652, Validation Loss: 0.0759279727935791\n",
      "Epoch 80/100, Training Loss: 0.18006528913974762, Validation Loss: 0.0757920891046524\n",
      "Epoch 81/100, Training Loss: 0.17563967406749725, Validation Loss: 0.0756869688630104\n",
      "Epoch 82/100, Training Loss: 0.1761060357093811, Validation Loss: 0.07567498087882996\n",
      "Epoch 83/100, Training Loss: 0.17674322426319122, Validation Loss: 0.07565459609031677\n",
      "Epoch 84/100, Training Loss: 0.17465831339359283, Validation Loss: 0.07563351094722748\n",
      "Epoch 85/100, Training Loss: 0.17628081142902374, Validation Loss: 0.07559558749198914\n",
      "Epoch 86/100, Training Loss: 0.17125509679317474, Validation Loss: 0.0755578950047493\n",
      "Epoch 87/100, Training Loss: 0.17328672111034393, Validation Loss: 0.07550840824842453\n",
      "Epoch 88/100, Training Loss: 0.17369239032268524, Validation Loss: 0.0754661113023758\n",
      "Epoch 89/100, Training Loss: 0.16865630447864532, Validation Loss: 0.0754568800330162\n",
      "Epoch 90/100, Training Loss: 0.1688784509897232, Validation Loss: 0.07552308589220047\n",
      "Epoch 91/100, Training Loss: 0.17270013689994812, Validation Loss: 0.07557842880487442\n",
      "Epoch 92/100, Training Loss: 0.1688132882118225, Validation Loss: 0.0757225826382637\n",
      "Epoch 93/100, Training Loss: 0.16820350289344788, Validation Loss: 0.07595092058181763\n",
      "Epoch 94/100, Training Loss: 0.16830584406852722, Validation Loss: 0.07615964114665985\n",
      "Epoch 95/100, Training Loss: 0.16897299885749817, Validation Loss: 0.07631576806306839\n",
      "Epoch 96/100, Training Loss: 0.1666930764913559, Validation Loss: 0.07657620310783386\n",
      "Epoch 97/100, Training Loss: 0.1655050665140152, Validation Loss: 0.0767986848950386\n",
      "Epoch 98/100, Training Loss: 0.1648058444261551, Validation Loss: 0.07704930752515793\n",
      "Epoch 99/100, Training Loss: 0.1630973070859909, Validation Loss: 0.07729382067918777\n",
      "Early stopping triggered\n",
      "R² Score: 0.9245, MAE: 0.1993\n",
      "Testing parameters: {'dropout_rate': 0.5, 'hidden_dim': 16, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Training Loss: 1.2404510974884033, Validation Loss: 0.8489578366279602\n",
      "Epoch 2/100, Training Loss: 1.019741177558899, Validation Loss: 0.6879745721817017\n",
      "Epoch 3/100, Training Loss: 0.8503568172454834, Validation Loss: 0.5590301752090454\n",
      "Epoch 4/100, Training Loss: 0.7162066698074341, Validation Loss: 0.4596608579158783\n",
      "Epoch 5/100, Training Loss: 0.61988765001297, Validation Loss: 0.38791465759277344\n",
      "Epoch 6/100, Training Loss: 0.5494282841682434, Validation Loss: 0.33828216791152954\n",
      "Epoch 7/100, Training Loss: 0.5073401927947998, Validation Loss: 0.30390626192092896\n",
      "Epoch 8/100, Training Loss: 0.4796699285507202, Validation Loss: 0.279424786567688\n",
      "Epoch 9/100, Training Loss: 0.45961102843284607, Validation Loss: 0.2611805498600006\n",
      "Epoch 10/100, Training Loss: 0.4433056116104126, Validation Loss: 0.2470732182264328\n",
      "Epoch 11/100, Training Loss: 0.42831018567085266, Validation Loss: 0.23534758388996124\n",
      "Epoch 12/100, Training Loss: 0.4115164577960968, Validation Loss: 0.22447262704372406\n",
      "Epoch 13/100, Training Loss: 0.39288654923439026, Validation Loss: 0.2133904993534088\n",
      "Epoch 14/100, Training Loss: 0.3738379180431366, Validation Loss: 0.20170122385025024\n",
      "Epoch 15/100, Training Loss: 0.3530721962451935, Validation Loss: 0.19006437063217163\n",
      "Epoch 16/100, Training Loss: 0.3329187333583832, Validation Loss: 0.1789913773536682\n",
      "Epoch 17/100, Training Loss: 0.31465137004852295, Validation Loss: 0.16902253031730652\n",
      "Epoch 18/100, Training Loss: 0.29762089252471924, Validation Loss: 0.16069336235523224\n",
      "Epoch 19/100, Training Loss: 0.28992581367492676, Validation Loss: 0.15388762950897217\n",
      "Epoch 20/100, Training Loss: 0.2807428538799286, Validation Loss: 0.14833325147628784\n",
      "Epoch 21/100, Training Loss: 0.2725701630115509, Validation Loss: 0.14382119476795197\n",
      "Epoch 22/100, Training Loss: 0.2698180079460144, Validation Loss: 0.14003688097000122\n",
      "Epoch 23/100, Training Loss: 0.2694079875946045, Validation Loss: 0.13678371906280518\n",
      "Epoch 24/100, Training Loss: 0.2644026279449463, Validation Loss: 0.13361702859401703\n",
      "Epoch 25/100, Training Loss: 0.26192906498908997, Validation Loss: 0.13042360544204712\n",
      "Epoch 26/100, Training Loss: 0.2616521418094635, Validation Loss: 0.12723757326602936\n",
      "Epoch 27/100, Training Loss: 0.2586086392402649, Validation Loss: 0.12415488809347153\n",
      "Epoch 28/100, Training Loss: 0.24828992784023285, Validation Loss: 0.12140974402427673\n",
      "Epoch 29/100, Training Loss: 0.24778757989406586, Validation Loss: 0.11924181133508682\n",
      "Epoch 30/100, Training Loss: 0.2390505075454712, Validation Loss: 0.11769935488700867\n",
      "Epoch 31/100, Training Loss: 0.23579607903957367, Validation Loss: 0.11688166111707687\n",
      "Epoch 32/100, Training Loss: 0.22847551107406616, Validation Loss: 0.11691118031740189\n",
      "Epoch 33/100, Training Loss: 0.22570101916790009, Validation Loss: 0.11757572740316391\n",
      "Epoch 34/100, Training Loss: 0.22370681166648865, Validation Loss: 0.11855381727218628\n",
      "Epoch 35/100, Training Loss: 0.21837256848812103, Validation Loss: 0.11969125270843506\n",
      "Epoch 36/100, Training Loss: 0.2193746268749237, Validation Loss: 0.12078388780355453\n",
      "Epoch 37/100, Training Loss: 0.2160525619983673, Validation Loss: 0.12171819806098938\n",
      "Epoch 38/100, Training Loss: 0.21664901077747345, Validation Loss: 0.12214593589305878\n",
      "Epoch 39/100, Training Loss: 0.21244704723358154, Validation Loss: 0.12212082743644714\n",
      "Epoch 40/100, Training Loss: 0.214288130402565, Validation Loss: 0.12165211886167526\n",
      "Epoch 41/100, Training Loss: 0.20773613452911377, Validation Loss: 0.12072873115539551\n",
      "Early stopping triggered\n",
      "R² Score: 0.8821, MAE: 0.2338\n",
      "Testing parameters: {'dropout_rate': 0.5, 'hidden_dim': 32, 'learning_rate': 0.001}\n",
      "Epoch 1/100, Training Loss: 1.1816545724868774, Validation Loss: 1.1482229232788086\n",
      "Epoch 2/100, Training Loss: 1.1532318592071533, Validation Loss: 1.1186912059783936\n",
      "Epoch 3/100, Training Loss: 1.1222792863845825, Validation Loss: 1.0896297693252563\n",
      "Epoch 4/100, Training Loss: 1.091687798500061, Validation Loss: 1.0609829425811768\n",
      "Epoch 5/100, Training Loss: 1.0599380731582642, Validation Loss: 1.0326957702636719\n",
      "Epoch 6/100, Training Loss: 1.0396413803100586, Validation Loss: 1.004759669303894\n",
      "Epoch 7/100, Training Loss: 1.0107711553573608, Validation Loss: 0.9771561622619629\n",
      "Epoch 8/100, Training Loss: 0.982513964176178, Validation Loss: 0.9499176740646362\n",
      "Epoch 9/100, Training Loss: 0.9567036032676697, Validation Loss: 0.922997772693634\n",
      "Epoch 10/100, Training Loss: 0.9329535961151123, Validation Loss: 0.896364688873291\n",
      "Epoch 11/100, Training Loss: 0.9117130637168884, Validation Loss: 0.869965136051178\n",
      "Epoch 12/100, Training Loss: 0.8880887031555176, Validation Loss: 0.8437649011611938\n",
      "Epoch 13/100, Training Loss: 0.862432062625885, Validation Loss: 0.8178581595420837\n",
      "Epoch 14/100, Training Loss: 0.8363837599754333, Validation Loss: 0.7923203706741333\n",
      "Epoch 15/100, Training Loss: 0.8147501945495605, Validation Loss: 0.7671540379524231\n",
      "Epoch 16/100, Training Loss: 0.7930355072021484, Validation Loss: 0.7423831820487976\n",
      "Epoch 17/100, Training Loss: 0.7760424613952637, Validation Loss: 0.7180243730545044\n",
      "Epoch 18/100, Training Loss: 0.7552065849304199, Validation Loss: 0.6940975189208984\n",
      "Epoch 19/100, Training Loss: 0.7344566583633423, Validation Loss: 0.6706556081771851\n",
      "Epoch 20/100, Training Loss: 0.713772714138031, Validation Loss: 0.6477492451667786\n",
      "Epoch 21/100, Training Loss: 0.6955450177192688, Validation Loss: 0.6254552602767944\n",
      "Epoch 22/100, Training Loss: 0.6743892431259155, Validation Loss: 0.60380619764328\n",
      "Epoch 23/100, Training Loss: 0.658423662185669, Validation Loss: 0.5827873945236206\n",
      "Epoch 24/100, Training Loss: 0.6398658156394958, Validation Loss: 0.5623912811279297\n",
      "Epoch 25/100, Training Loss: 0.6213976144790649, Validation Loss: 0.5426502227783203\n",
      "Epoch 26/100, Training Loss: 0.6057531833648682, Validation Loss: 0.5235386490821838\n",
      "Epoch 27/100, Training Loss: 0.5894007086753845, Validation Loss: 0.5050404071807861\n",
      "Epoch 28/100, Training Loss: 0.5746167302131653, Validation Loss: 0.48713985085487366\n",
      "Epoch 29/100, Training Loss: 0.5586718320846558, Validation Loss: 0.46985042095184326\n",
      "Epoch 30/100, Training Loss: 0.5473467707633972, Validation Loss: 0.4531524181365967\n",
      "Epoch 31/100, Training Loss: 0.5291405916213989, Validation Loss: 0.4370366334915161\n",
      "Epoch 32/100, Training Loss: 0.5157610177993774, Validation Loss: 0.4215131402015686\n",
      "Epoch 33/100, Training Loss: 0.5001932382583618, Validation Loss: 0.40657374262809753\n",
      "Epoch 34/100, Training Loss: 0.491042822599411, Validation Loss: 0.392212837934494\n",
      "Epoch 35/100, Training Loss: 0.477264940738678, Validation Loss: 0.37841394543647766\n",
      "Epoch 36/100, Training Loss: 0.46569889783859253, Validation Loss: 0.3651745319366455\n",
      "Epoch 37/100, Training Loss: 0.4540788531303406, Validation Loss: 0.3524642884731293\n",
      "Epoch 38/100, Training Loss: 0.44572603702545166, Validation Loss: 0.3402729332447052\n",
      "Epoch 39/100, Training Loss: 0.4296209514141083, Validation Loss: 0.32858625054359436\n",
      "Epoch 40/100, Training Loss: 0.42508015036582947, Validation Loss: 0.31735846400260925\n",
      "Epoch 41/100, Training Loss: 0.4124775826931, Validation Loss: 0.30657732486724854\n",
      "Epoch 42/100, Training Loss: 0.4025742709636688, Validation Loss: 0.29623907804489136\n",
      "Epoch 43/100, Training Loss: 0.3970315158367157, Validation Loss: 0.28635480999946594\n",
      "Epoch 44/100, Training Loss: 0.39002323150634766, Validation Loss: 0.27690091729164124\n",
      "Epoch 45/100, Training Loss: 0.3807733356952667, Validation Loss: 0.26788029074668884\n",
      "Epoch 46/100, Training Loss: 0.37545347213745117, Validation Loss: 0.25927409529685974\n",
      "Epoch 47/100, Training Loss: 0.36738839745521545, Validation Loss: 0.2510717809200287\n",
      "Epoch 48/100, Training Loss: 0.3572620153427124, Validation Loss: 0.24325531721115112\n",
      "Epoch 49/100, Training Loss: 0.3511476516723633, Validation Loss: 0.23581598699092865\n",
      "Epoch 50/100, Training Loss: 0.34480541944503784, Validation Loss: 0.22875060141086578\n",
      "Epoch 51/100, Training Loss: 0.33890971541404724, Validation Loss: 0.22203753888607025\n",
      "Epoch 52/100, Training Loss: 0.334883451461792, Validation Loss: 0.2156457155942917\n",
      "Epoch 53/100, Training Loss: 0.33029454946517944, Validation Loss: 0.20954568684101105\n",
      "Epoch 54/100, Training Loss: 0.3220481872558594, Validation Loss: 0.20372407138347626\n",
      "Epoch 55/100, Training Loss: 0.32153061032295227, Validation Loss: 0.19815021753311157\n",
      "Epoch 56/100, Training Loss: 0.3194979727268219, Validation Loss: 0.192807137966156\n",
      "Epoch 57/100, Training Loss: 0.3107466697692871, Validation Loss: 0.1876688003540039\n",
      "Epoch 58/100, Training Loss: 0.30654674768447876, Validation Loss: 0.18271806836128235\n",
      "Epoch 59/100, Training Loss: 0.3028614819049835, Validation Loss: 0.17793498933315277\n",
      "Epoch 60/100, Training Loss: 0.2980939745903015, Validation Loss: 0.17330683767795563\n",
      "Epoch 61/100, Training Loss: 0.29697924852371216, Validation Loss: 0.16882850229740143\n",
      "Epoch 62/100, Training Loss: 0.291305273771286, Validation Loss: 0.16448400914669037\n",
      "Epoch 63/100, Training Loss: 0.2870583236217499, Validation Loss: 0.1602681279182434\n",
      "Epoch 64/100, Training Loss: 0.28158414363861084, Validation Loss: 0.15617962181568146\n",
      "Epoch 65/100, Training Loss: 0.279144287109375, Validation Loss: 0.15220774710178375\n",
      "Epoch 66/100, Training Loss: 0.2773108184337616, Validation Loss: 0.1483505368232727\n",
      "Epoch 67/100, Training Loss: 0.2720696032047272, Validation Loss: 0.14460794627666473\n",
      "Epoch 68/100, Training Loss: 0.2711917459964752, Validation Loss: 0.14097999036312103\n",
      "Epoch 69/100, Training Loss: 0.26864704489707947, Validation Loss: 0.13746695220470428\n",
      "Epoch 70/100, Training Loss: 0.26064643263816833, Validation Loss: 0.13407175242900848\n",
      "Epoch 71/100, Training Loss: 0.2601715326309204, Validation Loss: 0.1307973563671112\n",
      "Epoch 72/100, Training Loss: 0.25559595227241516, Validation Loss: 0.1276421844959259\n",
      "Epoch 73/100, Training Loss: 0.24932549893856049, Validation Loss: 0.12460646033287048\n",
      "Epoch 74/100, Training Loss: 0.24842245876789093, Validation Loss: 0.12167993187904358\n",
      "Epoch 75/100, Training Loss: 0.24407051503658295, Validation Loss: 0.11886303126811981\n",
      "Epoch 76/100, Training Loss: 0.24325688183307648, Validation Loss: 0.11614356935024261\n",
      "Epoch 77/100, Training Loss: 0.24111205339431763, Validation Loss: 0.11351673305034637\n",
      "Epoch 78/100, Training Loss: 0.2413204461336136, Validation Loss: 0.11097939312458038\n",
      "Epoch 79/100, Training Loss: 0.23796291649341583, Validation Loss: 0.10852573812007904\n",
      "Epoch 80/100, Training Loss: 0.2348002791404724, Validation Loss: 0.10615420341491699\n",
      "Epoch 81/100, Training Loss: 0.2318294197320938, Validation Loss: 0.10385853797197342\n",
      "Epoch 82/100, Training Loss: 0.22633737325668335, Validation Loss: 0.10163845121860504\n",
      "Epoch 83/100, Training Loss: 0.22617974877357483, Validation Loss: 0.09949515759944916\n",
      "Epoch 84/100, Training Loss: 0.22346249222755432, Validation Loss: 0.09742125868797302\n",
      "Epoch 85/100, Training Loss: 0.223148912191391, Validation Loss: 0.09541145712137222\n",
      "Epoch 86/100, Training Loss: 0.2192862182855606, Validation Loss: 0.09346988052129745\n",
      "Epoch 87/100, Training Loss: 0.21783775091171265, Validation Loss: 0.09159129858016968\n",
      "Epoch 88/100, Training Loss: 0.21892733871936798, Validation Loss: 0.08977659046649933\n",
      "Epoch 89/100, Training Loss: 0.21345601975917816, Validation Loss: 0.08802767097949982\n",
      "Epoch 90/100, Training Loss: 0.2113891839981079, Validation Loss: 0.08633848279714584\n",
      "Epoch 91/100, Training Loss: 0.2107437252998352, Validation Loss: 0.08470742404460907\n",
      "Epoch 92/100, Training Loss: 0.21008113026618958, Validation Loss: 0.08313225209712982\n",
      "Epoch 93/100, Training Loss: 0.20909398794174194, Validation Loss: 0.08161360770463943\n",
      "Epoch 94/100, Training Loss: 0.20432119071483612, Validation Loss: 0.0801582783460617\n",
      "Epoch 95/100, Training Loss: 0.20627541840076447, Validation Loss: 0.07875321060419083\n",
      "Epoch 96/100, Training Loss: 0.20269395411014557, Validation Loss: 0.07739178836345673\n",
      "Epoch 97/100, Training Loss: 0.20186913013458252, Validation Loss: 0.076075978577137\n",
      "Epoch 98/100, Training Loss: 0.20194511115550995, Validation Loss: 0.07481162995100021\n",
      "Epoch 99/100, Training Loss: 0.19920775294303894, Validation Loss: 0.07358858734369278\n",
      "Epoch 100/100, Training Loss: 0.19925278425216675, Validation Loss: 0.07241413742303848\n",
      "R² Score: 0.9291, MAE: 0.1841\n",
      "Testing parameters: {'dropout_rate': 0.5, 'hidden_dim': 32, 'learning_rate': 0.005}\n",
      "Epoch 1/100, Training Loss: 1.175723671913147, Validation Loss: 0.9602514505386353\n",
      "Epoch 2/100, Training Loss: 1.0186834335327148, Validation Loss: 0.8295590877532959\n",
      "Epoch 3/100, Training Loss: 0.8859955668449402, Validation Loss: 0.712906539440155\n",
      "Epoch 4/100, Training Loss: 0.7685665488243103, Validation Loss: 0.6074217557907104\n",
      "Epoch 5/100, Training Loss: 0.6695003509521484, Validation Loss: 0.5146980881690979\n",
      "Epoch 6/100, Training Loss: 0.5815973877906799, Validation Loss: 0.435117244720459\n",
      "Epoch 7/100, Training Loss: 0.5055944323539734, Validation Loss: 0.3668263554573059\n",
      "Epoch 8/100, Training Loss: 0.4427304267883301, Validation Loss: 0.3100356161594391\n",
      "Epoch 9/100, Training Loss: 0.3898453116416931, Validation Loss: 0.2633214592933655\n",
      "Epoch 10/100, Training Loss: 0.35284554958343506, Validation Loss: 0.22539810836315155\n",
      "Epoch 11/100, Training Loss: 0.3205277919769287, Validation Loss: 0.19476453959941864\n",
      "Epoch 12/100, Training Loss: 0.30040353536605835, Validation Loss: 0.1704760044813156\n",
      "Epoch 13/100, Training Loss: 0.2870888411998749, Validation Loss: 0.15227556228637695\n",
      "Epoch 14/100, Training Loss: 0.2768820524215698, Validation Loss: 0.1390518695116043\n",
      "Epoch 15/100, Training Loss: 0.2742946147918701, Validation Loss: 0.12913280725479126\n",
      "Epoch 16/100, Training Loss: 0.27078765630722046, Validation Loss: 0.1207955926656723\n",
      "Epoch 17/100, Training Loss: 0.2672140598297119, Validation Loss: 0.11261949688196182\n",
      "Epoch 18/100, Training Loss: 0.25996676087379456, Validation Loss: 0.10408767312765121\n",
      "Epoch 19/100, Training Loss: 0.2496849149465561, Validation Loss: 0.09572196006774902\n",
      "Epoch 20/100, Training Loss: 0.24026119709014893, Validation Loss: 0.08822736889123917\n",
      "Epoch 21/100, Training Loss: 0.22702427208423615, Validation Loss: 0.08236610144376755\n",
      "Epoch 22/100, Training Loss: 0.21819059550762177, Validation Loss: 0.07853259891271591\n",
      "Epoch 23/100, Training Loss: 0.20508097112178802, Validation Loss: 0.07684063166379929\n",
      "Epoch 24/100, Training Loss: 0.1969253420829773, Validation Loss: 0.07712534070014954\n",
      "Epoch 25/100, Training Loss: 0.1908373385667801, Validation Loss: 0.07890794426202774\n",
      "Epoch 26/100, Training Loss: 0.1866520643234253, Validation Loss: 0.08162704110145569\n",
      "Epoch 27/100, Training Loss: 0.18216140568256378, Validation Loss: 0.08457782864570618\n",
      "Epoch 28/100, Training Loss: 0.1774291843175888, Validation Loss: 0.08728616684675217\n",
      "Epoch 29/100, Training Loss: 0.17403370141983032, Validation Loss: 0.08922366797924042\n",
      "Epoch 30/100, Training Loss: 0.17087742686271667, Validation Loss: 0.09019515663385391\n",
      "Epoch 31/100, Training Loss: 0.1689927726984024, Validation Loss: 0.09001287072896957\n",
      "Epoch 32/100, Training Loss: 0.1662285476922989, Validation Loss: 0.08862965553998947\n",
      "Epoch 33/100, Training Loss: 0.1609596163034439, Validation Loss: 0.08609825372695923\n",
      "Early stopping triggered\n",
      "R² Score: 0.9158, MAE: 0.2040\n",
      "Testing parameters: {'dropout_rate': 0.5, 'hidden_dim': 32, 'learning_rate': 0.01}\n",
      "Epoch 1/100, Training Loss: 1.3560279607772827, Validation Loss: 0.9282304048538208\n",
      "Epoch 2/100, Training Loss: 1.0110629796981812, Validation Loss: 0.6742222309112549\n",
      "Epoch 3/100, Training Loss: 0.758509635925293, Validation Loss: 0.49885204434394836\n",
      "Epoch 4/100, Training Loss: 0.5885229706764221, Validation Loss: 0.3785129189491272\n",
      "Epoch 5/100, Training Loss: 0.4656374752521515, Validation Loss: 0.2970356345176697\n",
      "Epoch 6/100, Training Loss: 0.39254024624824524, Validation Loss: 0.23983871936798096\n",
      "Epoch 7/100, Training Loss: 0.35703617334365845, Validation Loss: 0.19790591299533844\n",
      "Epoch 8/100, Training Loss: 0.329682856798172, Validation Loss: 0.16457603871822357\n",
      "Epoch 9/100, Training Loss: 0.31788745522499084, Validation Loss: 0.1377016007900238\n",
      "Epoch 10/100, Training Loss: 0.2962402105331421, Validation Loss: 0.11672331392765045\n",
      "Epoch 11/100, Training Loss: 0.28256359696388245, Validation Loss: 0.10178133100271225\n",
      "Epoch 12/100, Training Loss: 0.25817668437957764, Validation Loss: 0.09347431361675262\n",
      "Epoch 13/100, Training Loss: 0.24021276831626892, Validation Loss: 0.09123381227254868\n",
      "Epoch 14/100, Training Loss: 0.2278060019016266, Validation Loss: 0.0929347425699234\n",
      "Epoch 15/100, Training Loss: 0.21755507588386536, Validation Loss: 0.09604409337043762\n",
      "Epoch 16/100, Training Loss: 0.2095586657524109, Validation Loss: 0.09820736199617386\n",
      "Epoch 17/100, Training Loss: 0.20402981340885162, Validation Loss: 0.098008893430233\n",
      "Epoch 18/100, Training Loss: 0.19771987199783325, Validation Loss: 0.09509758651256561\n",
      "Epoch 19/100, Training Loss: 0.19388331472873688, Validation Loss: 0.09018578380346298\n",
      "Epoch 20/100, Training Loss: 0.18416041135787964, Validation Loss: 0.08459080755710602\n",
      "Epoch 21/100, Training Loss: 0.1840270310640335, Validation Loss: 0.07935968786478043\n",
      "Epoch 22/100, Training Loss: 0.1781776398420334, Validation Loss: 0.0746237188577652\n",
      "Epoch 23/100, Training Loss: 0.17625980079174042, Validation Loss: 0.07009028643369675\n",
      "Epoch 24/100, Training Loss: 0.1701163798570633, Validation Loss: 0.0657183825969696\n",
      "Epoch 25/100, Training Loss: 0.16543611884117126, Validation Loss: 0.06189674884080887\n",
      "Epoch 26/100, Training Loss: 0.15948167443275452, Validation Loss: 0.058967459946870804\n",
      "Epoch 27/100, Training Loss: 0.15315616130828857, Validation Loss: 0.056864719837903976\n",
      "Epoch 28/100, Training Loss: 0.14974884688854218, Validation Loss: 0.05526496469974518\n",
      "Epoch 29/100, Training Loss: 0.14405491948127747, Validation Loss: 0.053792230784893036\n",
      "Epoch 30/100, Training Loss: 0.1415548026561737, Validation Loss: 0.052457768470048904\n",
      "Epoch 31/100, Training Loss: 0.1406482607126236, Validation Loss: 0.05151321738958359\n",
      "Epoch 32/100, Training Loss: 0.1380491703748703, Validation Loss: 0.05080793797969818\n",
      "Epoch 33/100, Training Loss: 0.13758282363414764, Validation Loss: 0.05014759674668312\n",
      "Epoch 34/100, Training Loss: 0.1352076381444931, Validation Loss: 0.04929157719016075\n",
      "Epoch 35/100, Training Loss: 0.13312606513500214, Validation Loss: 0.04821597784757614\n",
      "Epoch 36/100, Training Loss: 0.13052909076213837, Validation Loss: 0.04713699594140053\n",
      "Epoch 37/100, Training Loss: 0.1268312633037567, Validation Loss: 0.04635471850633621\n",
      "Epoch 38/100, Training Loss: 0.1239686831831932, Validation Loss: 0.04607762023806572\n",
      "Epoch 39/100, Training Loss: 0.12212870270013809, Validation Loss: 0.04613259807229042\n",
      "Epoch 40/100, Training Loss: 0.12169720977544785, Validation Loss: 0.04621310159564018\n",
      "Epoch 41/100, Training Loss: 0.12230272591114044, Validation Loss: 0.04600750282406807\n",
      "Epoch 42/100, Training Loss: 0.11883585900068283, Validation Loss: 0.04532437399029732\n",
      "Epoch 43/100, Training Loss: 0.1184232085943222, Validation Loss: 0.0441339947283268\n",
      "Epoch 44/100, Training Loss: 0.11535948514938354, Validation Loss: 0.0427018478512764\n",
      "Epoch 45/100, Training Loss: 0.11517661809921265, Validation Loss: 0.04133506864309311\n",
      "Epoch 46/100, Training Loss: 0.11322349309921265, Validation Loss: 0.040135908871889114\n",
      "Epoch 47/100, Training Loss: 0.11184625327587128, Validation Loss: 0.039302535355091095\n",
      "Epoch 48/100, Training Loss: 0.11227117478847504, Validation Loss: 0.0388270802795887\n",
      "Epoch 49/100, Training Loss: 0.11081591248512268, Validation Loss: 0.038751885294914246\n",
      "Epoch 50/100, Training Loss: 0.10953143984079361, Validation Loss: 0.03883557394146919\n",
      "Epoch 51/100, Training Loss: 0.10753604769706726, Validation Loss: 0.039007414132356644\n",
      "Epoch 52/100, Training Loss: 0.10841219872236252, Validation Loss: 0.03907991200685501\n",
      "Epoch 53/100, Training Loss: 0.10617122799158096, Validation Loss: 0.03899494558572769\n",
      "Epoch 54/100, Training Loss: 0.10411933809518814, Validation Loss: 0.03870491683483124\n",
      "Epoch 55/100, Training Loss: 0.10576874762773514, Validation Loss: 0.03836458548903465\n",
      "Epoch 56/100, Training Loss: 0.10411757975816727, Validation Loss: 0.03817281126976013\n",
      "Epoch 57/100, Training Loss: 0.10351331532001495, Validation Loss: 0.03801359608769417\n",
      "Epoch 58/100, Training Loss: 0.10199668258428574, Validation Loss: 0.03801625221967697\n",
      "Epoch 59/100, Training Loss: 0.10012677311897278, Validation Loss: 0.03819102793931961\n",
      "Epoch 60/100, Training Loss: 0.10226380825042725, Validation Loss: 0.03838592395186424\n",
      "Epoch 61/100, Training Loss: 0.09955904632806778, Validation Loss: 0.03860754147171974\n",
      "Epoch 62/100, Training Loss: 0.09760086983442307, Validation Loss: 0.038849592208862305\n",
      "Epoch 63/100, Training Loss: 0.09930292516946793, Validation Loss: 0.03890817612409592\n",
      "Epoch 64/100, Training Loss: 0.09908914566040039, Validation Loss: 0.03871697559952736\n",
      "Epoch 65/100, Training Loss: 0.09786100685596466, Validation Loss: 0.03822813928127289\n",
      "Epoch 66/100, Training Loss: 0.09662541002035141, Validation Loss: 0.03753822296857834\n",
      "Epoch 67/100, Training Loss: 0.09684846550226212, Validation Loss: 0.03690486028790474\n",
      "Epoch 68/100, Training Loss: 0.09635903686285019, Validation Loss: 0.036383047699928284\n",
      "Epoch 69/100, Training Loss: 0.09539791196584702, Validation Loss: 0.035857655107975006\n",
      "Epoch 70/100, Training Loss: 0.0936528667807579, Validation Loss: 0.035687483847141266\n",
      "Epoch 71/100, Training Loss: 0.09422045946121216, Validation Loss: 0.035893093794584274\n",
      "Epoch 72/100, Training Loss: 0.09414325654506683, Validation Loss: 0.0364205464720726\n",
      "Epoch 73/100, Training Loss: 0.09447988867759705, Validation Loss: 0.03697472810745239\n",
      "Epoch 74/100, Training Loss: 0.09242454916238785, Validation Loss: 0.037569645792245865\n",
      "Epoch 75/100, Training Loss: 0.09200572222471237, Validation Loss: 0.03808721899986267\n",
      "Epoch 76/100, Training Loss: 0.09362368285655975, Validation Loss: 0.03843449801206589\n",
      "Epoch 77/100, Training Loss: 0.09157855063676834, Validation Loss: 0.038618896156549454\n",
      "Epoch 78/100, Training Loss: 0.09248704463243484, Validation Loss: 0.03873234987258911\n",
      "Epoch 79/100, Training Loss: 0.09020912647247314, Validation Loss: 0.03878236934542656\n",
      "Epoch 80/100, Training Loss: 0.08878352493047714, Validation Loss: 0.03878983482718468\n",
      "Early stopping triggered\n",
      "R² Score: 0.9621, MAE: 0.1397\n"
     ]
    }
   ],
   "source": [
    "# Convert merged DataFrame to a tensor\n",
    "x = torch.tensor(merged_df[['x_1', 'y_1', 'z_1']].values, dtype=torch.float)\n",
    "y = torch.tensor(merged_df[['x_1', 'y_1', 'z_1']].values, dtype=torch.float)\n",
    "\n",
    "# Define dummy edge_index for this example\n",
    "edge_index = torch.tensor([[0, 1], [1, 2]], dtype=torch.long)  # Placeholder\n",
    "\n",
    "# Create a Data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Define an enhanced GNN model with more layers and dropout\n",
    "class EnhancedGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.5):\n",
    "        super(EnhancedGNN, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = pyg_nn.GCNConv(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X = data.x.numpy()\n",
    "y = data.y.numpy()\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_data = Data(x=torch.tensor(X_train, dtype=torch.float), edge_index=data.edge_index, y=torch.tensor(y_train, dtype=torch.float))\n",
    "val_data = Data(x=torch.tensor(X_val, dtype=torch.float), edge_index=data.edge_index, y=torch.tensor(y_val, dtype=torch.float))\n",
    "test_data = Data(x=torch.tensor(X_test, dtype=torch.float), edge_index=data.edge_index, y=torch.tensor(y_test, dtype=torch.float))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "num_epochs = 100\n",
    "patience = 10\n",
    "best_r2 = float('-inf')\n",
    "best_params = {}\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.005, 0.01],\n",
    "    'hidden_dim': [16, 32],\n",
    "    'dropout_rate': [0.3, 0.5]\n",
    "}\n",
    "\n",
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['learning_rate', 'hidden_dim', 'dropout_rate', 'training_loss', 'validation_loss', 'mae', 'r2'])\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "    model = EnhancedGNN(input_dim=3, hidden_dim=params['hidden_dim'], output_dim=3, dropout_rate=params['dropout_rate'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        loss = criterion(out, train_data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(val_data)\n",
    "            val_loss = criterion(val_out, val_data.y)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "    \n",
    "    # Calculate metrics\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_out = model(val_data)\n",
    "        mae = mean_absolute_error(val_data.y.detach().numpy(), final_out.detach().numpy())\n",
    "        r2 = r2_score(val_data.y.detach().numpy(), final_out.detach().numpy())\n",
    "        print(f\"R² Score: {r2:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "        # Record results\n",
    "        new_row = pd.DataFrame([{\n",
    "            'learning_rate': params['learning_rate'],\n",
    "            'hidden_dim': params['hidden_dim'],\n",
    "            'dropout_rate': params['dropout_rate'],\n",
    "            'training_loss': loss.item(),\n",
    "            'validation_loss': val_loss.item(),\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }])\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_params = params\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('model_optimization_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14f593a4-5289-4f8c-aef3-1f6433ef55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an enhanced GNN model with more layers, dropout, and batch normalization\n",
    "class EnhancedGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.5):\n",
    "        super(EnhancedGNN, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)  # Batch normalization\n",
    "        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)  # Batch normalization\n",
    "        self.conv3 = pyg_nn.GCNConv(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.bn1(x)  # Apply batch normalization\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.bn2(x)  # Apply batch normalization\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Hyperparameter tuning remains the same, but consider expanding the grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.005, 0.01],\n",
    "    'hidden_dim': [16, 32, 64],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d9d495-8f99-4f09-b072-abf62b1de613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9621, MAE: 0.1397\n"
     ]
    }
   ],
   "source": [
    "# After calculating metrics\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_out = model(val_data)\n",
    "    mae = mean_absolute_error(val_data.y.detach().numpy(), final_out.detach().numpy())\n",
    "    r2 = r2_score(val_data.y.detach().numpy(), final_out.detach().numpy())\n",
    "    \n",
    "    # Print R² and MAE\n",
    "    print(f\"R² Score: {r2:.4f}, MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8434b69a-8b50-4a95-8c64-e957fe402a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Record results\n",
    "    new_row = pd.DataFrame([{\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'hidden_dim': params['hidden_dim'],\n",
    "        'dropout_rate': params['dropout_rate'],\n",
    "        'training_loss': loss.item(),\n",
    "        'validation_loss': val_loss.item(),\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e84aa-bc74-4fb5-ac9e-103a7f6e2f06",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "To analyze feature importance, we’ll use a Random Forest model and calculate the importance of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44664b31-a35e-4bf0-861f-5c327dfb2085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare data\n",
    "X = train_labels_df[['x_1', 'y_1', 'z_1']]  # Features\n",
    "y = train_labels_df['resid']  # Target variable\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance Analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6785c-6867-4bbd-9ad1-a07b7d0d4bbd",
   "metadata": {},
   "source": [
    " # Cross-Validation\n",
    "Implementing k-fold cross-validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b0731-1379-4b8b-8e61-785d3942597b",
   "metadata": {},
   "source": [
    "# This code will take long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbaed7-02f4-4844-bf8c-6bfb42af1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning with cross-validation...\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.0001}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.410334825515747, Validation Loss: 1.1759902238845825\n",
      "Epoch 2/100, Training Loss: 3.3986244201660156, Validation Loss: 1.1769917011260986\n",
      "Epoch 3/100, Training Loss: 3.406024694442749, Validation Loss: 1.178821086883545\n",
      "Epoch 4/100, Training Loss: 3.395573854446411, Validation Loss: 1.1819347143173218\n",
      "Epoch 5/100, Training Loss: 3.3998239040374756, Validation Loss: 1.1861494779586792\n",
      "Epoch 6/100, Training Loss: 3.3975603580474854, Validation Loss: 1.192132830619812\n",
      "Epoch 7/100, Training Loss: 3.373955249786377, Validation Loss: 1.199785590171814\n",
      "Epoch 8/100, Training Loss: 3.349022388458252, Validation Loss: 1.2082326412200928\n",
      "Epoch 9/100, Training Loss: 3.3579599857330322, Validation Loss: 1.2180253267288208\n",
      "Epoch 10/100, Training Loss: 3.359424591064453, Validation Loss: 1.2290663719177246\n",
      "Epoch 11/100, Training Loss: 3.3196871280670166, Validation Loss: 1.2413437366485596\n",
      "Early stopping triggered\n",
      "Fold 1 - R² Score: -0.2427, MAE: 0.9014\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 3.241406202316284, Validation Loss: 0.9641821980476379\n",
      "Epoch 2/100, Training Loss: 3.2683231830596924, Validation Loss: 0.9483460783958435\n",
      "Epoch 3/100, Training Loss: 3.247422218322754, Validation Loss: 0.9356582164764404\n",
      "Epoch 4/100, Training Loss: 3.2710089683532715, Validation Loss: 0.925638735294342\n",
      "Epoch 5/100, Training Loss: 3.2393710613250732, Validation Loss: 0.9179579615592957\n",
      "Epoch 6/100, Training Loss: 3.2947402000427246, Validation Loss: 0.9123765826225281\n",
      "Epoch 7/100, Training Loss: 3.288118600845337, Validation Loss: 0.9085229635238647\n",
      "Epoch 8/100, Training Loss: 3.240530490875244, Validation Loss: 0.9063279032707214\n",
      "Epoch 9/100, Training Loss: 3.2302403450012207, Validation Loss: 0.9056341648101807\n",
      "Epoch 10/100, Training Loss: 3.1904830932617188, Validation Loss: 0.9062951803207397\n",
      "Epoch 11/100, Training Loss: 3.194106101989746, Validation Loss: 0.9081695675849915\n",
      "Epoch 12/100, Training Loss: 3.1875269412994385, Validation Loss: 0.9112907648086548\n",
      "Epoch 13/100, Training Loss: 3.182380437850952, Validation Loss: 0.9152851104736328\n",
      "Epoch 14/100, Training Loss: 3.219658374786377, Validation Loss: 0.9200045466423035\n",
      "Epoch 15/100, Training Loss: 3.1504528522491455, Validation Loss: 0.9258915781974792\n",
      "Epoch 16/100, Training Loss: 3.165703535079956, Validation Loss: 0.9322983026504517\n",
      "Epoch 17/100, Training Loss: 3.179131507873535, Validation Loss: 0.9395281076431274\n",
      "Epoch 18/100, Training Loss: 3.1501283645629883, Validation Loss: 0.9474565982818604\n",
      "Epoch 19/100, Training Loss: 3.1163551807403564, Validation Loss: 0.9557015299797058\n",
      "Early stopping triggered\n",
      "Fold 2 - R² Score: 0.0472, MAE: 0.7105\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 3.5673890113830566, Validation Loss: 1.0801106691360474\n",
      "Epoch 2/100, Training Loss: 3.5479514598846436, Validation Loss: 1.079323410987854\n",
      "Epoch 3/100, Training Loss: 3.5373425483703613, Validation Loss: 1.079360842704773\n",
      "Epoch 4/100, Training Loss: 3.5323715209960938, Validation Loss: 1.0798147916793823\n",
      "Epoch 5/100, Training Loss: 3.5541903972625732, Validation Loss: 1.0807758569717407\n",
      "Epoch 6/100, Training Loss: 3.4945554733276367, Validation Loss: 1.0820872783660889\n",
      "Epoch 7/100, Training Loss: 3.536402940750122, Validation Loss: 1.0844347476959229\n",
      "Epoch 8/100, Training Loss: 3.4980251789093018, Validation Loss: 1.0871288776397705\n",
      "Epoch 9/100, Training Loss: 3.464139461517334, Validation Loss: 1.0903165340423584\n",
      "Epoch 10/100, Training Loss: 3.4836654663085938, Validation Loss: 1.0945581197738647\n",
      "Epoch 11/100, Training Loss: 3.469773530960083, Validation Loss: 1.0999488830566406\n",
      "Epoch 12/100, Training Loss: 3.450985908508301, Validation Loss: 1.1054524183273315\n",
      "Early stopping triggered\n",
      "Fold 3 - R² Score: -0.1144, MAE: 0.7914\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 3.2651195526123047, Validation Loss: 1.1618515253067017\n",
      "Epoch 2/100, Training Loss: 3.2690930366516113, Validation Loss: 1.1705509424209595\n",
      "Epoch 3/100, Training Loss: 3.193819046020508, Validation Loss: 1.1820811033248901\n",
      "Epoch 4/100, Training Loss: 3.2065811157226562, Validation Loss: 1.1959598064422607\n",
      "Epoch 5/100, Training Loss: 3.217562437057495, Validation Loss: 1.2113630771636963\n",
      "Epoch 6/100, Training Loss: 3.234532117843628, Validation Loss: 1.2278802394866943\n",
      "Epoch 7/100, Training Loss: 3.183668375015259, Validation Loss: 1.2453196048736572\n",
      "Epoch 8/100, Training Loss: 3.1916816234588623, Validation Loss: 1.263382077217102\n",
      "Epoch 9/100, Training Loss: 3.1885626316070557, Validation Loss: 1.281432867050171\n",
      "Epoch 10/100, Training Loss: 3.1571085453033447, Validation Loss: 1.2995920181274414\n",
      "Epoch 11/100, Training Loss: 3.1823384761810303, Validation Loss: 1.3180410861968994\n",
      "Early stopping triggered\n",
      "Fold 4 - R² Score: -0.3161, MAE: 0.8510\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 4.447099685668945, Validation Loss: 1.4675103425979614\n",
      "Epoch 2/100, Training Loss: 4.454865455627441, Validation Loss: 1.493714690208435\n",
      "Epoch 3/100, Training Loss: 4.418939113616943, Validation Loss: 1.5240763425827026\n",
      "Epoch 4/100, Training Loss: 4.435813903808594, Validation Loss: 1.5584087371826172\n",
      "Epoch 5/100, Training Loss: 4.405127048492432, Validation Loss: 1.5960043668746948\n",
      "Epoch 6/100, Training Loss: 4.415961265563965, Validation Loss: 1.6367805004119873\n",
      "Epoch 7/100, Training Loss: 4.393346309661865, Validation Loss: 1.6800161600112915\n",
      "Epoch 8/100, Training Loss: 4.382544040679932, Validation Loss: 1.7252452373504639\n",
      "Epoch 9/100, Training Loss: 4.3610382080078125, Validation Loss: 1.7722142934799194\n",
      "Epoch 10/100, Training Loss: 4.357340335845947, Validation Loss: 1.821015477180481\n",
      "Epoch 11/100, Training Loss: 4.366621494293213, Validation Loss: 1.8705793619155884\n",
      "Early stopping triggered\n",
      "Fold 5 - R² Score: -0.8717, MAE: 1.1477\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.001}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 4.219261169433594, Validation Loss: 1.228432059288025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pq/m0qzt3d55l39kx3nwyjhkt8w0000gn/T/ipykernel_3782/307796953.py:80: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame(fold_results)], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Training Loss: 4.089198112487793, Validation Loss: 1.194067358970642\n",
      "Epoch 3/100, Training Loss: 3.9819087982177734, Validation Loss: 1.1708908081054688\n",
      "Epoch 4/100, Training Loss: 3.887348175048828, Validation Loss: 1.1542677879333496\n",
      "Epoch 5/100, Training Loss: 3.807406187057495, Validation Loss: 1.1411253213882446\n",
      "Epoch 6/100, Training Loss: 3.7114295959472656, Validation Loss: 1.1301729679107666\n",
      "Epoch 7/100, Training Loss: 3.6342813968658447, Validation Loss: 1.120473027229309\n",
      "Epoch 8/100, Training Loss: 3.534810781478882, Validation Loss: 1.111057996749878\n",
      "Epoch 9/100, Training Loss: 3.4672884941101074, Validation Loss: 1.1017533540725708\n",
      "Epoch 10/100, Training Loss: 3.3459291458129883, Validation Loss: 1.0922443866729736\n",
      "Epoch 11/100, Training Loss: 3.2959585189819336, Validation Loss: 1.0825334787368774\n",
      "Epoch 12/100, Training Loss: 3.2150280475616455, Validation Loss: 1.0722017288208008\n",
      "Epoch 13/100, Training Loss: 3.1452856063842773, Validation Loss: 1.0612329244613647\n",
      "Epoch 14/100, Training Loss: 3.0537617206573486, Validation Loss: 1.0495458841323853\n",
      "Epoch 15/100, Training Loss: 3.0079891681671143, Validation Loss: 1.0369845628738403\n",
      "Epoch 16/100, Training Loss: 2.9202327728271484, Validation Loss: 1.0237514972686768\n",
      "Epoch 17/100, Training Loss: 2.8703572750091553, Validation Loss: 1.0096495151519775\n",
      "Epoch 18/100, Training Loss: 2.8127830028533936, Validation Loss: 0.9949958920478821\n",
      "Epoch 19/100, Training Loss: 2.760808229446411, Validation Loss: 0.97919762134552\n",
      "Epoch 20/100, Training Loss: 2.717271089553833, Validation Loss: 0.9630360007286072\n",
      "Epoch 21/100, Training Loss: 2.642547369003296, Validation Loss: 0.9462045431137085\n",
      "Epoch 22/100, Training Loss: 2.6017701625823975, Validation Loss: 0.92900151014328\n",
      "Epoch 23/100, Training Loss: 2.5394175052642822, Validation Loss: 0.9116293787956238\n",
      "Epoch 24/100, Training Loss: 2.500410318374634, Validation Loss: 0.8940710425376892\n",
      "Epoch 25/100, Training Loss: 2.444993734359741, Validation Loss: 0.8763684034347534\n",
      "Epoch 26/100, Training Loss: 2.411863327026367, Validation Loss: 0.8586674332618713\n",
      "Epoch 27/100, Training Loss: 2.356437921524048, Validation Loss: 0.8408129215240479\n",
      "Epoch 28/100, Training Loss: 2.313596725463867, Validation Loss: 0.823026180267334\n",
      "Epoch 29/100, Training Loss: 2.2808408737182617, Validation Loss: 0.8053113222122192\n",
      "Epoch 30/100, Training Loss: 2.2430386543273926, Validation Loss: 0.7879319190979004\n",
      "Epoch 31/100, Training Loss: 2.207388401031494, Validation Loss: 0.7706071138381958\n",
      "Epoch 32/100, Training Loss: 2.1532695293426514, Validation Loss: 0.7530557513237\n",
      "Epoch 33/100, Training Loss: 2.113548517227173, Validation Loss: 0.7356979250907898\n",
      "Epoch 34/100, Training Loss: 2.087207317352295, Validation Loss: 0.7187128663063049\n",
      "Epoch 35/100, Training Loss: 2.0304579734802246, Validation Loss: 0.7019509673118591\n",
      "Epoch 36/100, Training Loss: 2.0386624336242676, Validation Loss: 0.6857603788375854\n",
      "Epoch 37/100, Training Loss: 2.000978708267212, Validation Loss: 0.6697487235069275\n",
      "Epoch 38/100, Training Loss: 1.9565544128417969, Validation Loss: 0.6541153192520142\n",
      "Epoch 39/100, Training Loss: 1.9398757219314575, Validation Loss: 0.6387894749641418\n",
      "Epoch 40/100, Training Loss: 1.8827823400497437, Validation Loss: 0.623823344707489\n",
      "Epoch 41/100, Training Loss: 1.8934084177017212, Validation Loss: 0.6092381477355957\n",
      "Epoch 42/100, Training Loss: 1.8526874780654907, Validation Loss: 0.5949485898017883\n",
      "Epoch 43/100, Training Loss: 1.8127355575561523, Validation Loss: 0.5809656381607056\n",
      "Epoch 44/100, Training Loss: 1.8029571771621704, Validation Loss: 0.5674191117286682\n",
      "Epoch 45/100, Training Loss: 1.7744578123092651, Validation Loss: 0.5543121099472046\n",
      "Epoch 46/100, Training Loss: 1.7489783763885498, Validation Loss: 0.5414472222328186\n",
      "Epoch 47/100, Training Loss: 1.7132800817489624, Validation Loss: 0.5292923450469971\n",
      "Epoch 48/100, Training Loss: 1.7109358310699463, Validation Loss: 0.5176270604133606\n",
      "Epoch 49/100, Training Loss: 1.6739810705184937, Validation Loss: 0.5060701370239258\n",
      "Epoch 50/100, Training Loss: 1.6698527336120605, Validation Loss: 0.49488958716392517\n",
      "Epoch 51/100, Training Loss: 1.6380432844161987, Validation Loss: 0.48394641280174255\n",
      "Epoch 52/100, Training Loss: 1.606429934501648, Validation Loss: 0.47308093309402466\n",
      "Epoch 53/100, Training Loss: 1.5976406335830688, Validation Loss: 0.4625222682952881\n",
      "Epoch 54/100, Training Loss: 1.5896821022033691, Validation Loss: 0.45220011472702026\n",
      "Epoch 55/100, Training Loss: 1.560754418373108, Validation Loss: 0.44229233264923096\n",
      "Epoch 56/100, Training Loss: 1.5398509502410889, Validation Loss: 0.43255680799484253\n",
      "Epoch 57/100, Training Loss: 1.5203030109405518, Validation Loss: 0.42326298356056213\n",
      "Epoch 58/100, Training Loss: 1.503173589706421, Validation Loss: 0.4144602119922638\n",
      "Epoch 59/100, Training Loss: 1.4905716180801392, Validation Loss: 0.40580132603645325\n",
      "Epoch 60/100, Training Loss: 1.4842214584350586, Validation Loss: 0.3973272442817688\n",
      "Epoch 61/100, Training Loss: 1.449662685394287, Validation Loss: 0.3893529176712036\n",
      "Epoch 62/100, Training Loss: 1.4456509351730347, Validation Loss: 0.38157764077186584\n",
      "Epoch 63/100, Training Loss: 1.414353847503662, Validation Loss: 0.3739728629589081\n",
      "Epoch 64/100, Training Loss: 1.4120913743972778, Validation Loss: 0.36678963899612427\n",
      "Epoch 65/100, Training Loss: 1.4047160148620605, Validation Loss: 0.3598039150238037\n",
      "Epoch 66/100, Training Loss: 1.3712363243103027, Validation Loss: 0.3529604971408844\n",
      "Epoch 67/100, Training Loss: 1.3667216300964355, Validation Loss: 0.3463451862335205\n",
      "Epoch 68/100, Training Loss: 1.3605005741119385, Validation Loss: 0.3399873673915863\n",
      "Epoch 69/100, Training Loss: 1.351749300956726, Validation Loss: 0.3338746428489685\n",
      "Epoch 70/100, Training Loss: 1.329587697982788, Validation Loss: 0.32794389128685\n",
      "Epoch 71/100, Training Loss: 1.31252920627594, Validation Loss: 0.3220008611679077\n",
      "Epoch 72/100, Training Loss: 1.3111108541488647, Validation Loss: 0.3161897361278534\n",
      "Epoch 73/100, Training Loss: 1.2929351329803467, Validation Loss: 0.3106358051300049\n",
      "Epoch 74/100, Training Loss: 1.276267409324646, Validation Loss: 0.30513113737106323\n",
      "Epoch 75/100, Training Loss: 1.2785640954971313, Validation Loss: 0.2998960018157959\n",
      "Epoch 76/100, Training Loss: 1.264334797859192, Validation Loss: 0.29502010345458984\n",
      "Epoch 77/100, Training Loss: 1.2458561658859253, Validation Loss: 0.2901190221309662\n",
      "Epoch 78/100, Training Loss: 1.2296521663665771, Validation Loss: 0.2852310538291931\n",
      "Epoch 79/100, Training Loss: 1.2259260416030884, Validation Loss: 0.28045618534088135\n",
      "Epoch 80/100, Training Loss: 1.214896559715271, Validation Loss: 0.27596330642700195\n",
      "Epoch 81/100, Training Loss: 1.207489013671875, Validation Loss: 0.2715235948562622\n",
      "Epoch 82/100, Training Loss: 1.191728115081787, Validation Loss: 0.2673743665218353\n",
      "Epoch 83/100, Training Loss: 1.181273341178894, Validation Loss: 0.2633834183216095\n",
      "Epoch 84/100, Training Loss: 1.169264316558838, Validation Loss: 0.25950920581817627\n",
      "Epoch 85/100, Training Loss: 1.1662068367004395, Validation Loss: 0.25573545694351196\n",
      "Epoch 86/100, Training Loss: 1.1500794887542725, Validation Loss: 0.25209730863571167\n",
      "Epoch 87/100, Training Loss: 1.147230863571167, Validation Loss: 0.24855245649814606\n",
      "Epoch 88/100, Training Loss: 1.1386295557022095, Validation Loss: 0.24497629702091217\n",
      "Epoch 89/100, Training Loss: 1.1313962936401367, Validation Loss: 0.24141113460063934\n",
      "Epoch 90/100, Training Loss: 1.1159861087799072, Validation Loss: 0.23790530860424042\n",
      "Epoch 91/100, Training Loss: 1.1049599647521973, Validation Loss: 0.23455028235912323\n",
      "Epoch 92/100, Training Loss: 1.1017944812774658, Validation Loss: 0.23140177130699158\n",
      "Epoch 93/100, Training Loss: 1.0915566682815552, Validation Loss: 0.22838667035102844\n",
      "Epoch 94/100, Training Loss: 1.0941648483276367, Validation Loss: 0.22529108822345734\n",
      "Epoch 95/100, Training Loss: 1.0781800746917725, Validation Loss: 0.22243858873844147\n",
      "Epoch 96/100, Training Loss: 1.064207911491394, Validation Loss: 0.21973606944084167\n",
      "Epoch 97/100, Training Loss: 1.0573424100875854, Validation Loss: 0.21706655621528625\n",
      "Epoch 98/100, Training Loss: 1.0484609603881836, Validation Loss: 0.21441148221492767\n",
      "Epoch 99/100, Training Loss: 1.0460454225540161, Validation Loss: 0.21180370450019836\n",
      "Epoch 100/100, Training Loss: 1.044391393661499, Validation Loss: 0.20935359597206116\n",
      "Fold 1 - R² Score: 0.7905, MAE: 0.3388\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 2.7514238357543945, Validation Loss: 1.1569008827209473\n",
      "Epoch 2/100, Training Loss: 2.6863415241241455, Validation Loss: 1.140733242034912\n",
      "Epoch 3/100, Training Loss: 2.646796703338623, Validation Loss: 1.1296712160110474\n",
      "Epoch 4/100, Training Loss: 2.615368366241455, Validation Loss: 1.12208092212677\n",
      "Epoch 5/100, Training Loss: 2.5538697242736816, Validation Loss: 1.1163243055343628\n",
      "Epoch 6/100, Training Loss: 2.501370668411255, Validation Loss: 1.1114712953567505\n",
      "Epoch 7/100, Training Loss: 2.436474084854126, Validation Loss: 1.1068021059036255\n",
      "Epoch 8/100, Training Loss: 2.3911335468292236, Validation Loss: 1.1018338203430176\n",
      "Epoch 9/100, Training Loss: 2.351656913757324, Validation Loss: 1.0959261655807495\n",
      "Epoch 10/100, Training Loss: 2.3148372173309326, Validation Loss: 1.088745355606079\n",
      "Epoch 11/100, Training Loss: 2.2771947383880615, Validation Loss: 1.0795787572860718\n",
      "Epoch 12/100, Training Loss: 2.2307848930358887, Validation Loss: 1.0684714317321777\n",
      "Epoch 13/100, Training Loss: 2.1867868900299072, Validation Loss: 1.0550075769424438\n",
      "Epoch 14/100, Training Loss: 2.1624722480773926, Validation Loss: 1.039381742477417\n",
      "Epoch 15/100, Training Loss: 2.107832908630371, Validation Loss: 1.0216913223266602\n",
      "Epoch 16/100, Training Loss: 2.0601634979248047, Validation Loss: 1.001826286315918\n",
      "Epoch 17/100, Training Loss: 2.0392234325408936, Validation Loss: 0.9793277382850647\n",
      "Epoch 18/100, Training Loss: 1.9949883222579956, Validation Loss: 0.9550357460975647\n",
      "Epoch 19/100, Training Loss: 1.9733214378356934, Validation Loss: 0.9288548231124878\n",
      "Epoch 20/100, Training Loss: 1.9184461832046509, Validation Loss: 0.9008057713508606\n",
      "Epoch 21/100, Training Loss: 1.9081755876541138, Validation Loss: 0.8718183040618896\n",
      "Epoch 22/100, Training Loss: 1.8703910112380981, Validation Loss: 0.8421658873558044\n",
      "Epoch 23/100, Training Loss: 1.83357572555542, Validation Loss: 0.8118577003479004\n",
      "Epoch 24/100, Training Loss: 1.8011620044708252, Validation Loss: 0.7815089821815491\n",
      "Epoch 25/100, Training Loss: 1.7616393566131592, Validation Loss: 0.7514017820358276\n",
      "Epoch 26/100, Training Loss: 1.7438478469848633, Validation Loss: 0.7216718792915344\n",
      "Epoch 27/100, Training Loss: 1.7279220819473267, Validation Loss: 0.6928824186325073\n",
      "Epoch 28/100, Training Loss: 1.6818907260894775, Validation Loss: 0.664375901222229\n",
      "Epoch 29/100, Training Loss: 1.6517457962036133, Validation Loss: 0.6370311975479126\n",
      "Epoch 30/100, Training Loss: 1.6286150217056274, Validation Loss: 0.6104405522346497\n",
      "Epoch 31/100, Training Loss: 1.615923285484314, Validation Loss: 0.584554135799408\n",
      "Epoch 32/100, Training Loss: 1.5728631019592285, Validation Loss: 0.5602881908416748\n",
      "Epoch 33/100, Training Loss: 1.5620625019073486, Validation Loss: 0.5364384651184082\n",
      "Epoch 34/100, Training Loss: 1.5193392038345337, Validation Loss: 0.5139762759208679\n",
      "Epoch 35/100, Training Loss: 1.5033811330795288, Validation Loss: 0.4929097890853882\n",
      "Epoch 36/100, Training Loss: 1.4862223863601685, Validation Loss: 0.47302916646003723\n",
      "Epoch 37/100, Training Loss: 1.4705320596694946, Validation Loss: 0.4542444348335266\n",
      "Epoch 38/100, Training Loss: 1.4354044198989868, Validation Loss: 0.43674492835998535\n",
      "Epoch 39/100, Training Loss: 1.4038645029067993, Validation Loss: 0.41999751329421997\n",
      "Epoch 40/100, Training Loss: 1.3887423276901245, Validation Loss: 0.40425562858581543\n",
      "Epoch 41/100, Training Loss: 1.3805532455444336, Validation Loss: 0.3894069194793701\n",
      "Epoch 42/100, Training Loss: 1.3611016273498535, Validation Loss: 0.37557557225227356\n",
      "Epoch 43/100, Training Loss: 1.3387242555618286, Validation Loss: 0.3625481128692627\n",
      "Epoch 44/100, Training Loss: 1.3153918981552124, Validation Loss: 0.35035690665245056\n",
      "Epoch 45/100, Training Loss: 1.2935281991958618, Validation Loss: 0.3388935625553131\n",
      "Epoch 46/100, Training Loss: 1.2844624519348145, Validation Loss: 0.32797694206237793\n",
      "Epoch 47/100, Training Loss: 1.272578477859497, Validation Loss: 0.31756606698036194\n",
      "Epoch 48/100, Training Loss: 1.267074704170227, Validation Loss: 0.3077123761177063\n",
      "Epoch 49/100, Training Loss: 1.2359169721603394, Validation Loss: 0.2984004318714142\n",
      "Epoch 50/100, Training Loss: 1.2238725423812866, Validation Loss: 0.2895357608795166\n",
      "Epoch 51/100, Training Loss: 1.2110662460327148, Validation Loss: 0.2811591625213623\n",
      "Epoch 52/100, Training Loss: 1.1860151290893555, Validation Loss: 0.27326881885528564\n",
      "Epoch 53/100, Training Loss: 1.1780539751052856, Validation Loss: 0.2656187415122986\n",
      "Epoch 54/100, Training Loss: 1.1670194864273071, Validation Loss: 0.2581969201564789\n",
      "Epoch 55/100, Training Loss: 1.1457620859146118, Validation Loss: 0.25123435258865356\n",
      "Epoch 56/100, Training Loss: 1.1389678716659546, Validation Loss: 0.24466313421726227\n",
      "Epoch 57/100, Training Loss: 1.1182451248168945, Validation Loss: 0.238444522023201\n",
      "Epoch 58/100, Training Loss: 1.095038652420044, Validation Loss: 0.23236650228500366\n",
      "Epoch 59/100, Training Loss: 1.098512053489685, Validation Loss: 0.22658957540988922\n",
      "Epoch 60/100, Training Loss: 1.0832911729812622, Validation Loss: 0.221281036734581\n",
      "Epoch 61/100, Training Loss: 1.0773061513900757, Validation Loss: 0.2160264402627945\n",
      "Epoch 62/100, Training Loss: 1.0581094026565552, Validation Loss: 0.21105797588825226\n",
      "Epoch 63/100, Training Loss: 1.0401726961135864, Validation Loss: 0.20654496550559998\n",
      "Epoch 64/100, Training Loss: 1.0315994024276733, Validation Loss: 0.20214101672172546\n",
      "Epoch 65/100, Training Loss: 1.0176113843917847, Validation Loss: 0.19798614084720612\n",
      "Epoch 66/100, Training Loss: 1.0062334537506104, Validation Loss: 0.1940203160047531\n",
      "Epoch 67/100, Training Loss: 1.012718677520752, Validation Loss: 0.1901264637708664\n",
      "Epoch 68/100, Training Loss: 0.9963220953941345, Validation Loss: 0.18638493120670319\n",
      "Epoch 69/100, Training Loss: 0.9925703406333923, Validation Loss: 0.18291936814785004\n",
      "Epoch 70/100, Training Loss: 0.981400728225708, Validation Loss: 0.17965656518936157\n",
      "Epoch 71/100, Training Loss: 0.9690223932266235, Validation Loss: 0.1765134334564209\n",
      "Epoch 72/100, Training Loss: 0.95620197057724, Validation Loss: 0.1735125482082367\n",
      "Epoch 73/100, Training Loss: 0.9503567814826965, Validation Loss: 0.17068831622600555\n",
      "Epoch 74/100, Training Loss: 0.9493158459663391, Validation Loss: 0.1679573506116867\n",
      "Epoch 75/100, Training Loss: 0.9329787492752075, Validation Loss: 0.16536614298820496\n",
      "Epoch 76/100, Training Loss: 0.9294370412826538, Validation Loss: 0.16298304498195648\n",
      "Epoch 77/100, Training Loss: 0.9184412360191345, Validation Loss: 0.16063639521598816\n",
      "Epoch 78/100, Training Loss: 0.9145997166633606, Validation Loss: 0.1583692729473114\n",
      "Epoch 79/100, Training Loss: 0.9091504812240601, Validation Loss: 0.1563650667667389\n",
      "Epoch 80/100, Training Loss: 0.8966243863105774, Validation Loss: 0.15439066290855408\n",
      "Epoch 81/100, Training Loss: 0.8899993896484375, Validation Loss: 0.15247711539268494\n",
      "Epoch 82/100, Training Loss: 0.884394645690918, Validation Loss: 0.1506466418504715\n",
      "Epoch 83/100, Training Loss: 0.8813205361366272, Validation Loss: 0.14897330105304718\n",
      "Epoch 84/100, Training Loss: 0.8729289174079895, Validation Loss: 0.14735907316207886\n",
      "Epoch 85/100, Training Loss: 0.8640592694282532, Validation Loss: 0.14589418470859528\n",
      "Epoch 86/100, Training Loss: 0.8509849309921265, Validation Loss: 0.1444627195596695\n",
      "Epoch 87/100, Training Loss: 0.8537325263023376, Validation Loss: 0.14304107427597046\n",
      "Epoch 88/100, Training Loss: 0.845476508140564, Validation Loss: 0.14164134860038757\n",
      "Epoch 89/100, Training Loss: 0.840189516544342, Validation Loss: 0.14030177891254425\n",
      "Epoch 90/100, Training Loss: 0.8391439318656921, Validation Loss: 0.13901971280574799\n",
      "Epoch 91/100, Training Loss: 0.8216880559921265, Validation Loss: 0.13781122863292694\n",
      "Epoch 92/100, Training Loss: 0.8188242316246033, Validation Loss: 0.13674327731132507\n",
      "Epoch 93/100, Training Loss: 0.8152426481246948, Validation Loss: 0.13569746911525726\n",
      "Epoch 94/100, Training Loss: 0.8136000037193298, Validation Loss: 0.1347372680902481\n",
      "Epoch 95/100, Training Loss: 0.8081120848655701, Validation Loss: 0.13376504182815552\n",
      "Epoch 96/100, Training Loss: 0.8010464906692505, Validation Loss: 0.13280414044857025\n",
      "Epoch 97/100, Training Loss: 0.7961264848709106, Validation Loss: 0.1318885236978531\n",
      "Epoch 98/100, Training Loss: 0.7842361927032471, Validation Loss: 0.1310967355966568\n",
      "Epoch 99/100, Training Loss: 0.7839722633361816, Validation Loss: 0.1302655041217804\n",
      "Epoch 100/100, Training Loss: 0.7790494561195374, Validation Loss: 0.12949317693710327\n",
      "Fold 2 - R² Score: 0.8714, MAE: 0.2584\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 4.498581886291504, Validation Loss: 1.5366184711456299\n",
      "Epoch 2/100, Training Loss: 4.382566928863525, Validation Loss: 1.5626245737075806\n",
      "Epoch 3/100, Training Loss: 4.265031337738037, Validation Loss: 1.5877116918563843\n",
      "Epoch 4/100, Training Loss: 4.165628910064697, Validation Loss: 1.6109329462051392\n",
      "Epoch 5/100, Training Loss: 4.069581031799316, Validation Loss: 1.6315895318984985\n",
      "Epoch 6/100, Training Loss: 3.9585464000701904, Validation Loss: 1.64907968044281\n",
      "Epoch 7/100, Training Loss: 3.8665075302124023, Validation Loss: 1.6631590127944946\n",
      "Epoch 8/100, Training Loss: 3.7414121627807617, Validation Loss: 1.6727041006088257\n",
      "Epoch 9/100, Training Loss: 3.6721882820129395, Validation Loss: 1.6785119771957397\n",
      "Epoch 10/100, Training Loss: 3.5964174270629883, Validation Loss: 1.6799554824829102\n",
      "Epoch 11/100, Training Loss: 3.5233497619628906, Validation Loss: 1.67697012424469\n",
      "Early stopping triggered\n",
      "Fold 3 - R² Score: -0.6907, MAE: 1.0422\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 3.3470077514648438, Validation Loss: 1.1971466541290283\n",
      "Epoch 2/100, Training Loss: 3.293607234954834, Validation Loss: 1.1871899366378784\n",
      "Epoch 3/100, Training Loss: 3.1946685314178467, Validation Loss: 1.1798967123031616\n",
      "Epoch 4/100, Training Loss: 3.100489616394043, Validation Loss: 1.172995924949646\n",
      "Epoch 5/100, Training Loss: 3.054931402206421, Validation Loss: 1.1665996313095093\n",
      "Epoch 6/100, Training Loss: 2.994093656539917, Validation Loss: 1.159542441368103\n",
      "Epoch 7/100, Training Loss: 2.9105257987976074, Validation Loss: 1.1521217823028564\n",
      "Epoch 8/100, Training Loss: 2.8256266117095947, Validation Loss: 1.143686294555664\n",
      "Epoch 9/100, Training Loss: 2.766336679458618, Validation Loss: 1.1349374055862427\n",
      "Epoch 10/100, Training Loss: 2.6768910884857178, Validation Loss: 1.1252954006195068\n",
      "Epoch 11/100, Training Loss: 2.6097230911254883, Validation Loss: 1.1143511533737183\n",
      "Epoch 12/100, Training Loss: 2.55649471282959, Validation Loss: 1.1024291515350342\n",
      "Epoch 13/100, Training Loss: 2.500736951828003, Validation Loss: 1.0895414352416992\n",
      "Epoch 14/100, Training Loss: 2.451619863510132, Validation Loss: 1.0755363702774048\n",
      "Epoch 15/100, Training Loss: 2.389190912246704, Validation Loss: 1.059958815574646\n",
      "Epoch 16/100, Training Loss: 2.3218655586242676, Validation Loss: 1.0435112714767456\n",
      "Epoch 17/100, Training Loss: 2.2614643573760986, Validation Loss: 1.025750994682312\n",
      "Epoch 18/100, Training Loss: 2.2178287506103516, Validation Loss: 1.0066008567810059\n",
      "Epoch 19/100, Training Loss: 2.1754519939422607, Validation Loss: 0.986180305480957\n",
      "Epoch 20/100, Training Loss: 2.1162495613098145, Validation Loss: 0.9648029804229736\n",
      "Epoch 21/100, Training Loss: 2.108804225921631, Validation Loss: 0.9421411156654358\n",
      "Epoch 22/100, Training Loss: 2.0297319889068604, Validation Loss: 0.9193702936172485\n",
      "Epoch 23/100, Training Loss: 1.9563674926757812, Validation Loss: 0.895641028881073\n",
      "Epoch 24/100, Training Loss: 1.9455164670944214, Validation Loss: 0.8705780506134033\n",
      "Epoch 25/100, Training Loss: 1.8988585472106934, Validation Loss: 0.8453608155250549\n",
      "Epoch 26/100, Training Loss: 1.8666386604309082, Validation Loss: 0.8192688822746277\n",
      "Epoch 27/100, Training Loss: 1.8133351802825928, Validation Loss: 0.7928014397621155\n",
      "Epoch 28/100, Training Loss: 1.7719882726669312, Validation Loss: 0.7663456201553345\n",
      "Epoch 29/100, Training Loss: 1.7269906997680664, Validation Loss: 0.7387441396713257\n",
      "Epoch 30/100, Training Loss: 1.693051815032959, Validation Loss: 0.7114366888999939\n",
      "Epoch 31/100, Training Loss: 1.6711558103561401, Validation Loss: 0.6846292614936829\n",
      "Epoch 32/100, Training Loss: 1.6157236099243164, Validation Loss: 0.6575806140899658\n",
      "Epoch 33/100, Training Loss: 1.6049741506576538, Validation Loss: 0.631237268447876\n",
      "Epoch 34/100, Training Loss: 1.5691242218017578, Validation Loss: 0.605542004108429\n",
      "Epoch 35/100, Training Loss: 1.5426162481307983, Validation Loss: 0.5803998112678528\n",
      "Epoch 36/100, Training Loss: 1.5111796855926514, Validation Loss: 0.5563603043556213\n",
      "Epoch 37/100, Training Loss: 1.4837380647659302, Validation Loss: 0.5333684682846069\n",
      "Epoch 38/100, Training Loss: 1.4573688507080078, Validation Loss: 0.5109767913818359\n",
      "Epoch 39/100, Training Loss: 1.4281986951828003, Validation Loss: 0.4896004796028137\n",
      "Epoch 40/100, Training Loss: 1.3982001543045044, Validation Loss: 0.46932968497276306\n",
      "Epoch 41/100, Training Loss: 1.370298981666565, Validation Loss: 0.4500546455383301\n",
      "Epoch 42/100, Training Loss: 1.352088212966919, Validation Loss: 0.43152159452438354\n",
      "Epoch 43/100, Training Loss: 1.333990216255188, Validation Loss: 0.4140980541706085\n",
      "Epoch 44/100, Training Loss: 1.3105895519256592, Validation Loss: 0.39757734537124634\n",
      "Epoch 45/100, Training Loss: 1.2900333404541016, Validation Loss: 0.3820192813873291\n",
      "Epoch 46/100, Training Loss: 1.260285496711731, Validation Loss: 0.367415189743042\n",
      "Epoch 47/100, Training Loss: 1.2440797090530396, Validation Loss: 0.3536931574344635\n",
      "Epoch 48/100, Training Loss: 1.2290759086608887, Validation Loss: 0.34100499749183655\n",
      "Epoch 49/100, Training Loss: 1.2195076942443848, Validation Loss: 0.329129695892334\n",
      "Epoch 50/100, Training Loss: 1.1994616985321045, Validation Loss: 0.3175174295902252\n",
      "Epoch 51/100, Training Loss: 1.1833840608596802, Validation Loss: 0.30678191781044006\n",
      "Epoch 52/100, Training Loss: 1.1634529829025269, Validation Loss: 0.29670557379722595\n",
      "Epoch 53/100, Training Loss: 1.1574759483337402, Validation Loss: 0.2873387932777405\n",
      "Epoch 54/100, Training Loss: 1.1278380155563354, Validation Loss: 0.27808380126953125\n",
      "Epoch 55/100, Training Loss: 1.1122524738311768, Validation Loss: 0.2693464756011963\n",
      "Epoch 56/100, Training Loss: 1.1122368574142456, Validation Loss: 0.261140912771225\n",
      "Epoch 57/100, Training Loss: 1.097409963607788, Validation Loss: 0.2534305453300476\n",
      "Epoch 58/100, Training Loss: 1.0804370641708374, Validation Loss: 0.24605856835842133\n",
      "Epoch 59/100, Training Loss: 1.067893624305725, Validation Loss: 0.23920194804668427\n",
      "Epoch 60/100, Training Loss: 1.0529905557632446, Validation Loss: 0.2328082174062729\n",
      "Epoch 61/100, Training Loss: 1.0488033294677734, Validation Loss: 0.22688114643096924\n",
      "Epoch 62/100, Training Loss: 1.0309948921203613, Validation Loss: 0.22112803161144257\n",
      "Epoch 63/100, Training Loss: 1.0202275514602661, Validation Loss: 0.2156025618314743\n",
      "Epoch 64/100, Training Loss: 1.006381630897522, Validation Loss: 0.21045345067977905\n",
      "Epoch 65/100, Training Loss: 0.9924184083938599, Validation Loss: 0.20569269359111786\n",
      "Epoch 66/100, Training Loss: 0.9941593408584595, Validation Loss: 0.20101024210453033\n",
      "Epoch 67/100, Training Loss: 0.9852185845375061, Validation Loss: 0.19666220247745514\n",
      "Epoch 68/100, Training Loss: 0.9658252596855164, Validation Loss: 0.1924070417881012\n",
      "Epoch 69/100, Training Loss: 0.9601162075996399, Validation Loss: 0.18829981982707977\n",
      "Epoch 70/100, Training Loss: 0.9487496018409729, Validation Loss: 0.18438969552516937\n",
      "Epoch 71/100, Training Loss: 0.9465171098709106, Validation Loss: 0.18072064220905304\n",
      "Epoch 72/100, Training Loss: 0.9355780482292175, Validation Loss: 0.17722812294960022\n",
      "Epoch 73/100, Training Loss: 0.9170292019844055, Validation Loss: 0.17388464510440826\n",
      "Epoch 74/100, Training Loss: 0.915418267250061, Validation Loss: 0.1707286536693573\n",
      "Epoch 75/100, Training Loss: 0.9036384224891663, Validation Loss: 0.16776397824287415\n",
      "Epoch 76/100, Training Loss: 0.8946161866188049, Validation Loss: 0.16494795680046082\n",
      "Epoch 77/100, Training Loss: 0.8930166363716125, Validation Loss: 0.16221794486045837\n",
      "Epoch 78/100, Training Loss: 0.8762654662132263, Validation Loss: 0.15971152484416962\n",
      "Epoch 79/100, Training Loss: 0.8769835829734802, Validation Loss: 0.15729635953903198\n",
      "Epoch 80/100, Training Loss: 0.8734166622161865, Validation Loss: 0.1549777090549469\n",
      "Epoch 81/100, Training Loss: 0.8610984683036804, Validation Loss: 0.1527862548828125\n",
      "Epoch 82/100, Training Loss: 0.8528721332550049, Validation Loss: 0.1504407525062561\n",
      "Epoch 83/100, Training Loss: 0.8462173938751221, Validation Loss: 0.14830610156059265\n",
      "Epoch 84/100, Training Loss: 0.8472616672515869, Validation Loss: 0.14636094868183136\n",
      "Epoch 85/100, Training Loss: 0.8349175453186035, Validation Loss: 0.1444191038608551\n",
      "Epoch 86/100, Training Loss: 0.8208531141281128, Validation Loss: 0.14262494444847107\n",
      "Epoch 87/100, Training Loss: 0.8216850757598877, Validation Loss: 0.1408008188009262\n",
      "Epoch 88/100, Training Loss: 0.8272547125816345, Validation Loss: 0.1389879584312439\n",
      "Epoch 89/100, Training Loss: 0.8044634461402893, Validation Loss: 0.13727442920207977\n",
      "Epoch 90/100, Training Loss: 0.7992285490036011, Validation Loss: 0.1357012540102005\n",
      "Epoch 91/100, Training Loss: 0.7994241714477539, Validation Loss: 0.13411018252372742\n",
      "Epoch 92/100, Training Loss: 0.7933858633041382, Validation Loss: 0.13257771730422974\n",
      "Epoch 93/100, Training Loss: 0.7879655361175537, Validation Loss: 0.13094933331012726\n",
      "Epoch 94/100, Training Loss: 0.7807817459106445, Validation Loss: 0.12952262163162231\n",
      "Epoch 95/100, Training Loss: 0.7740657925605774, Validation Loss: 0.12799806892871857\n",
      "Epoch 96/100, Training Loss: 0.7762278318405151, Validation Loss: 0.12646359205245972\n",
      "Epoch 97/100, Training Loss: 0.7618025541305542, Validation Loss: 0.12514854967594147\n",
      "Epoch 98/100, Training Loss: 0.7587658762931824, Validation Loss: 0.12380700558423996\n",
      "Epoch 99/100, Training Loss: 0.7615074515342712, Validation Loss: 0.12255126237869263\n",
      "Epoch 100/100, Training Loss: 0.7530882358551025, Validation Loss: 0.12134011834859848\n",
      "Fold 4 - R² Score: 0.8790, MAE: 0.2456\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 2.808664083480835, Validation Loss: 0.7970569729804993\n",
      "Epoch 2/100, Training Loss: 2.748807191848755, Validation Loss: 0.7789139151573181\n",
      "Epoch 3/100, Training Loss: 2.690138816833496, Validation Loss: 0.7617011070251465\n",
      "Epoch 4/100, Training Loss: 2.644606351852417, Validation Loss: 0.7449274659156799\n",
      "Epoch 5/100, Training Loss: 2.583615779876709, Validation Loss: 0.7284874320030212\n",
      "Epoch 6/100, Training Loss: 2.5322203636169434, Validation Loss: 0.7124348282814026\n",
      "Epoch 7/100, Training Loss: 2.4695773124694824, Validation Loss: 0.6965821385383606\n",
      "Epoch 8/100, Training Loss: 2.4262542724609375, Validation Loss: 0.6811742186546326\n",
      "Epoch 9/100, Training Loss: 2.37252140045166, Validation Loss: 0.6660581827163696\n",
      "Epoch 10/100, Training Loss: 2.3169400691986084, Validation Loss: 0.651214599609375\n",
      "Epoch 11/100, Training Loss: 2.283836841583252, Validation Loss: 0.636850893497467\n",
      "Epoch 12/100, Training Loss: 2.2331361770629883, Validation Loss: 0.6225228905677795\n",
      "Epoch 13/100, Training Loss: 2.1886513233184814, Validation Loss: 0.6085431575775146\n",
      "Epoch 14/100, Training Loss: 2.1418867111206055, Validation Loss: 0.5948746204376221\n",
      "Epoch 15/100, Training Loss: 2.0936667919158936, Validation Loss: 0.5814321637153625\n",
      "Epoch 16/100, Training Loss: 2.045535087585449, Validation Loss: 0.5679330229759216\n",
      "Epoch 17/100, Training Loss: 2.0198304653167725, Validation Loss: 0.5548093914985657\n",
      "Epoch 18/100, Training Loss: 1.9749755859375, Validation Loss: 0.5418871641159058\n",
      "Epoch 19/100, Training Loss: 1.937200665473938, Validation Loss: 0.5292683839797974\n",
      "Epoch 20/100, Training Loss: 1.8885722160339355, Validation Loss: 0.5169181823730469\n",
      "Epoch 21/100, Training Loss: 1.8526970148086548, Validation Loss: 0.5049232840538025\n",
      "Epoch 22/100, Training Loss: 1.8144925832748413, Validation Loss: 0.49322083592414856\n",
      "Epoch 23/100, Training Loss: 1.779028296470642, Validation Loss: 0.48181766271591187\n",
      "Epoch 24/100, Training Loss: 1.7573033571243286, Validation Loss: 0.47099822759628296\n",
      "Epoch 25/100, Training Loss: 1.7178112268447876, Validation Loss: 0.46040305495262146\n",
      "Epoch 26/100, Training Loss: 1.6791359186172485, Validation Loss: 0.45014557242393494\n",
      "Epoch 27/100, Training Loss: 1.6463935375213623, Validation Loss: 0.4404001235961914\n",
      "Epoch 28/100, Training Loss: 1.6307878494262695, Validation Loss: 0.4310151934623718\n",
      "Epoch 29/100, Training Loss: 1.595625638961792, Validation Loss: 0.421920508146286\n",
      "Epoch 30/100, Training Loss: 1.5554871559143066, Validation Loss: 0.4131234586238861\n",
      "Epoch 31/100, Training Loss: 1.5370134115219116, Validation Loss: 0.40494221448898315\n",
      "Epoch 32/100, Training Loss: 1.51190984249115, Validation Loss: 0.39710232615470886\n",
      "Epoch 33/100, Training Loss: 1.483936071395874, Validation Loss: 0.3893950581550598\n",
      "Epoch 34/100, Training Loss: 1.4575835466384888, Validation Loss: 0.382046103477478\n",
      "Epoch 35/100, Training Loss: 1.4462028741836548, Validation Loss: 0.374809592962265\n",
      "Epoch 36/100, Training Loss: 1.4055923223495483, Validation Loss: 0.3680144250392914\n",
      "Epoch 37/100, Training Loss: 1.3957278728485107, Validation Loss: 0.36141520738601685\n",
      "Epoch 38/100, Training Loss: 1.3728641271591187, Validation Loss: 0.35507073998451233\n",
      "Epoch 39/100, Training Loss: 1.3501689434051514, Validation Loss: 0.34879061579704285\n",
      "Epoch 40/100, Training Loss: 1.327988624572754, Validation Loss: 0.3427480459213257\n",
      "Epoch 41/100, Training Loss: 1.3083140850067139, Validation Loss: 0.33698004484176636\n",
      "Epoch 42/100, Training Loss: 1.2871912717819214, Validation Loss: 0.33144474029541016\n",
      "Epoch 43/100, Training Loss: 1.2705307006835938, Validation Loss: 0.3261186182498932\n",
      "Epoch 44/100, Training Loss: 1.2511593103408813, Validation Loss: 0.32077768445014954\n",
      "Epoch 45/100, Training Loss: 1.2444528341293335, Validation Loss: 0.3156087398529053\n",
      "Epoch 46/100, Training Loss: 1.2207179069519043, Validation Loss: 0.3106052279472351\n",
      "Epoch 47/100, Training Loss: 1.2146830558776855, Validation Loss: 0.305757611989975\n",
      "Epoch 48/100, Training Loss: 1.1871495246887207, Validation Loss: 0.3007436990737915\n",
      "Epoch 49/100, Training Loss: 1.1680612564086914, Validation Loss: 0.29608607292175293\n",
      "Epoch 50/100, Training Loss: 1.1528942584991455, Validation Loss: 0.2914853096008301\n",
      "Epoch 51/100, Training Loss: 1.1334598064422607, Validation Loss: 0.2869807183742523\n",
      "Epoch 52/100, Training Loss: 1.124985694885254, Validation Loss: 0.28254005312919617\n",
      "Epoch 53/100, Training Loss: 1.1136499643325806, Validation Loss: 0.2780360281467438\n",
      "Epoch 54/100, Training Loss: 1.1012077331542969, Validation Loss: 0.2737443745136261\n",
      "Epoch 55/100, Training Loss: 1.0863803625106812, Validation Loss: 0.2697072923183441\n",
      "Epoch 56/100, Training Loss: 1.0826239585876465, Validation Loss: 0.26574549078941345\n",
      "Epoch 57/100, Training Loss: 1.064196228981018, Validation Loss: 0.2618964910507202\n",
      "Epoch 58/100, Training Loss: 1.050016164779663, Validation Loss: 0.2580445408821106\n",
      "Epoch 59/100, Training Loss: 1.0380311012268066, Validation Loss: 0.2541418671607971\n",
      "Epoch 60/100, Training Loss: 1.0264785289764404, Validation Loss: 0.25048238039016724\n",
      "Epoch 61/100, Training Loss: 1.016051173210144, Validation Loss: 0.24675576388835907\n",
      "Epoch 62/100, Training Loss: 1.0045266151428223, Validation Loss: 0.24320301413536072\n",
      "Epoch 63/100, Training Loss: 0.9886124730110168, Validation Loss: 0.23975127935409546\n",
      "Epoch 64/100, Training Loss: 0.975938618183136, Validation Loss: 0.23629094660282135\n",
      "Epoch 65/100, Training Loss: 0.9711677432060242, Validation Loss: 0.23301906883716583\n",
      "Epoch 66/100, Training Loss: 0.9634647369384766, Validation Loss: 0.22971870005130768\n",
      "Epoch 67/100, Training Loss: 0.9589411020278931, Validation Loss: 0.22652049362659454\n",
      "Epoch 68/100, Training Loss: 0.9453046321868896, Validation Loss: 0.22335974872112274\n",
      "Epoch 69/100, Training Loss: 0.9272716045379639, Validation Loss: 0.22042489051818848\n",
      "Epoch 70/100, Training Loss: 0.9260504841804504, Validation Loss: 0.2173020839691162\n",
      "Epoch 71/100, Training Loss: 0.9117177128791809, Validation Loss: 0.21450278162956238\n",
      "Epoch 72/100, Training Loss: 0.9034193158149719, Validation Loss: 0.21162240207195282\n",
      "Epoch 73/100, Training Loss: 0.8906036019325256, Validation Loss: 0.20900799334049225\n",
      "Epoch 74/100, Training Loss: 0.8907136917114258, Validation Loss: 0.2062586098909378\n",
      "Epoch 75/100, Training Loss: 0.8810505867004395, Validation Loss: 0.20358315110206604\n",
      "Epoch 76/100, Training Loss: 0.8721005320549011, Validation Loss: 0.20105883479118347\n",
      "Epoch 77/100, Training Loss: 0.8665844798088074, Validation Loss: 0.1985594630241394\n",
      "Epoch 78/100, Training Loss: 0.8545839190483093, Validation Loss: 0.1961158812046051\n",
      "Epoch 79/100, Training Loss: 0.8495950698852539, Validation Loss: 0.19372490048408508\n",
      "Epoch 80/100, Training Loss: 0.8413410186767578, Validation Loss: 0.19135254621505737\n",
      "Epoch 81/100, Training Loss: 0.8276098370552063, Validation Loss: 0.18914222717285156\n",
      "Epoch 82/100, Training Loss: 0.8230952024459839, Validation Loss: 0.18699586391448975\n",
      "Epoch 83/100, Training Loss: 0.809781014919281, Validation Loss: 0.18496078252792358\n",
      "Epoch 84/100, Training Loss: 0.8084187507629395, Validation Loss: 0.18304675817489624\n",
      "Epoch 85/100, Training Loss: 0.8059815764427185, Validation Loss: 0.1810862421989441\n",
      "Epoch 86/100, Training Loss: 0.7951340675354004, Validation Loss: 0.1791291981935501\n",
      "Epoch 87/100, Training Loss: 0.7825916409492493, Validation Loss: 0.17718251049518585\n",
      "Epoch 88/100, Training Loss: 0.7883269786834717, Validation Loss: 0.17525699734687805\n",
      "Epoch 89/100, Training Loss: 0.7810271978378296, Validation Loss: 0.17340195178985596\n",
      "Epoch 90/100, Training Loss: 0.7672024965286255, Validation Loss: 0.17161865532398224\n",
      "Epoch 91/100, Training Loss: 0.7608623504638672, Validation Loss: 0.1697675585746765\n",
      "Epoch 92/100, Training Loss: 0.7551739811897278, Validation Loss: 0.16805370151996613\n",
      "Epoch 93/100, Training Loss: 0.7434091567993164, Validation Loss: 0.16637006402015686\n",
      "Epoch 94/100, Training Loss: 0.7496179938316345, Validation Loss: 0.1648077517747879\n",
      "Epoch 95/100, Training Loss: 0.7360263466835022, Validation Loss: 0.16325965523719788\n",
      "Epoch 96/100, Training Loss: 0.7346957921981812, Validation Loss: 0.16169363260269165\n",
      "Epoch 97/100, Training Loss: 0.7274906635284424, Validation Loss: 0.1600884050130844\n",
      "Epoch 98/100, Training Loss: 0.7222633957862854, Validation Loss: 0.15854516625404358\n",
      "Epoch 99/100, Training Loss: 0.7095413208007812, Validation Loss: 0.15691357851028442\n",
      "Epoch 100/100, Training Loss: 0.7030558586120605, Validation Loss: 0.1553494781255722\n",
      "Fold 5 - R² Score: 0.8444, MAE: 0.2635\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.005}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 4.2709784507751465, Validation Loss: 1.1081352233886719\n",
      "Epoch 2/100, Training Loss: 3.8519043922424316, Validation Loss: 1.0634496212005615\n",
      "Epoch 3/100, Training Loss: 3.4338841438293457, Validation Loss: 1.0201005935668945\n",
      "Epoch 4/100, Training Loss: 3.0538723468780518, Validation Loss: 0.9773901104927063\n",
      "Epoch 5/100, Training Loss: 2.799142837524414, Validation Loss: 0.934988260269165\n",
      "Epoch 6/100, Training Loss: 2.5093607902526855, Validation Loss: 0.8932746648788452\n",
      "Epoch 7/100, Training Loss: 2.27893328666687, Validation Loss: 0.8507965207099915\n",
      "Epoch 8/100, Training Loss: 2.094759702682495, Validation Loss: 0.8064554929733276\n",
      "Epoch 9/100, Training Loss: 1.9192582368850708, Validation Loss: 0.7607669234275818\n",
      "Epoch 10/100, Training Loss: 1.7675188779830933, Validation Loss: 0.714622437953949\n",
      "Epoch 11/100, Training Loss: 1.6179417371749878, Validation Loss: 0.6665868163108826\n",
      "Epoch 12/100, Training Loss: 1.5126155614852905, Validation Loss: 0.6180337071418762\n",
      "Epoch 13/100, Training Loss: 1.3988227844238281, Validation Loss: 0.5735779404640198\n",
      "Epoch 14/100, Training Loss: 1.3065829277038574, Validation Loss: 0.5332619547843933\n",
      "Epoch 15/100, Training Loss: 1.2209089994430542, Validation Loss: 0.4954255521297455\n",
      "Epoch 16/100, Training Loss: 1.1535223722457886, Validation Loss: 0.45864248275756836\n",
      "Epoch 17/100, Training Loss: 1.088004231452942, Validation Loss: 0.4245903789997101\n",
      "Epoch 18/100, Training Loss: 1.0399327278137207, Validation Loss: 0.3935074508190155\n",
      "Epoch 19/100, Training Loss: 0.9843398332595825, Validation Loss: 0.3646213114261627\n",
      "Epoch 20/100, Training Loss: 0.9402719140052795, Validation Loss: 0.33757200837135315\n",
      "Epoch 21/100, Training Loss: 0.9034128785133362, Validation Loss: 0.3129519820213318\n",
      "Epoch 22/100, Training Loss: 0.864005982875824, Validation Loss: 0.29064053297042847\n",
      "Epoch 23/100, Training Loss: 0.8260616064071655, Validation Loss: 0.27003100514411926\n",
      "Epoch 24/100, Training Loss: 0.7938953638076782, Validation Loss: 0.2511192262172699\n",
      "Epoch 25/100, Training Loss: 0.7675197124481201, Validation Loss: 0.23367393016815186\n",
      "Epoch 26/100, Training Loss: 0.7410891652107239, Validation Loss: 0.21803784370422363\n",
      "Epoch 27/100, Training Loss: 0.7165548801422119, Validation Loss: 0.2040061056613922\n",
      "Epoch 28/100, Training Loss: 0.6908980011940002, Validation Loss: 0.19146673381328583\n",
      "Epoch 29/100, Training Loss: 0.6677840352058411, Validation Loss: 0.18024207651615143\n",
      "Epoch 30/100, Training Loss: 0.6424937844276428, Validation Loss: 0.17023985087871552\n",
      "Epoch 31/100, Training Loss: 0.6255943775177002, Validation Loss: 0.16137412190437317\n",
      "Epoch 32/100, Training Loss: 0.611274242401123, Validation Loss: 0.1532316654920578\n",
      "Epoch 33/100, Training Loss: 0.5920740962028503, Validation Loss: 0.1459522545337677\n",
      "Epoch 34/100, Training Loss: 0.582105278968811, Validation Loss: 0.13934485614299774\n",
      "Epoch 35/100, Training Loss: 0.5636807680130005, Validation Loss: 0.13328199088573456\n",
      "Epoch 36/100, Training Loss: 0.5452922582626343, Validation Loss: 0.1280122697353363\n",
      "Epoch 37/100, Training Loss: 0.532980740070343, Validation Loss: 0.1233760192990303\n",
      "Epoch 38/100, Training Loss: 0.5178157091140747, Validation Loss: 0.11918903887271881\n",
      "Epoch 39/100, Training Loss: 0.5085867643356323, Validation Loss: 0.11541200429201126\n",
      "Epoch 40/100, Training Loss: 0.5010172724723816, Validation Loss: 0.11208056658506393\n",
      "Epoch 41/100, Training Loss: 0.48682740330696106, Validation Loss: 0.10907171666622162\n",
      "Epoch 42/100, Training Loss: 0.47716304659843445, Validation Loss: 0.10640498250722885\n",
      "Epoch 43/100, Training Loss: 0.46704521775245667, Validation Loss: 0.10385861992835999\n",
      "Epoch 44/100, Training Loss: 0.45882076025009155, Validation Loss: 0.10154621303081512\n",
      "Epoch 45/100, Training Loss: 0.4512406289577484, Validation Loss: 0.09950298070907593\n",
      "Epoch 46/100, Training Loss: 0.4422149360179901, Validation Loss: 0.09770888835191727\n",
      "Epoch 47/100, Training Loss: 0.43827149271965027, Validation Loss: 0.09603605419397354\n",
      "Epoch 48/100, Training Loss: 0.43231362104415894, Validation Loss: 0.09454416483640671\n",
      "Epoch 49/100, Training Loss: 0.4186989367008209, Validation Loss: 0.09323375672101974\n",
      "Epoch 50/100, Training Loss: 0.4185701012611389, Validation Loss: 0.09180013090372086\n",
      "Epoch 51/100, Training Loss: 0.40797117352485657, Validation Loss: 0.09052694588899612\n",
      "Epoch 52/100, Training Loss: 0.4019180238246918, Validation Loss: 0.0893610417842865\n",
      "Epoch 53/100, Training Loss: 0.39617234468460083, Validation Loss: 0.08825503289699554\n",
      "Epoch 54/100, Training Loss: 0.3905557096004486, Validation Loss: 0.08714305609464645\n",
      "Epoch 55/100, Training Loss: 0.38572272658348083, Validation Loss: 0.08615229278802872\n",
      "Epoch 56/100, Training Loss: 0.3790559470653534, Validation Loss: 0.0852314755320549\n",
      "Epoch 57/100, Training Loss: 0.3727536201477051, Validation Loss: 0.08436945080757141\n",
      "Epoch 58/100, Training Loss: 0.37032368779182434, Validation Loss: 0.08350776135921478\n",
      "Epoch 59/100, Training Loss: 0.3676181733608246, Validation Loss: 0.08272279053926468\n",
      "Epoch 60/100, Training Loss: 0.36265048384666443, Validation Loss: 0.081941619515419\n",
      "Epoch 61/100, Training Loss: 0.35705316066741943, Validation Loss: 0.08122137188911438\n",
      "Epoch 62/100, Training Loss: 0.349989116191864, Validation Loss: 0.0805356577038765\n",
      "Epoch 63/100, Training Loss: 0.34725144505500793, Validation Loss: 0.07990019768476486\n",
      "Epoch 64/100, Training Loss: 0.3431456387042999, Validation Loss: 0.07935390621423721\n",
      "Epoch 65/100, Training Loss: 0.33987364172935486, Validation Loss: 0.07889424264431\n",
      "Epoch 66/100, Training Loss: 0.33823490142822266, Validation Loss: 0.07836823165416718\n",
      "Epoch 67/100, Training Loss: 0.3341885209083557, Validation Loss: 0.0778580754995346\n",
      "Epoch 68/100, Training Loss: 0.3274131715297699, Validation Loss: 0.07742109149694443\n",
      "Epoch 69/100, Training Loss: 0.326802521944046, Validation Loss: 0.07695960253477097\n",
      "Epoch 70/100, Training Loss: 0.32295191287994385, Validation Loss: 0.0765184760093689\n",
      "Epoch 71/100, Training Loss: 0.3212265968322754, Validation Loss: 0.07608513534069061\n",
      "Epoch 72/100, Training Loss: 0.31449294090270996, Validation Loss: 0.07569937407970428\n",
      "Epoch 73/100, Training Loss: 0.3091343641281128, Validation Loss: 0.07526955008506775\n",
      "Epoch 74/100, Training Loss: 0.3081199824810028, Validation Loss: 0.0748630166053772\n",
      "Epoch 75/100, Training Loss: 0.30413997173309326, Validation Loss: 0.07445291429758072\n",
      "Epoch 76/100, Training Loss: 0.30433788895606995, Validation Loss: 0.07410350441932678\n",
      "Epoch 77/100, Training Loss: 0.3012159764766693, Validation Loss: 0.07372087985277176\n",
      "Epoch 78/100, Training Loss: 0.2995624542236328, Validation Loss: 0.07327279448509216\n",
      "Epoch 79/100, Training Loss: 0.29460176825523376, Validation Loss: 0.07287797331809998\n",
      "Epoch 80/100, Training Loss: 0.29188820719718933, Validation Loss: 0.07248562574386597\n",
      "Epoch 81/100, Training Loss: 0.29002857208251953, Validation Loss: 0.07216183096170425\n",
      "Epoch 82/100, Training Loss: 0.28985360264778137, Validation Loss: 0.07175233960151672\n",
      "Epoch 83/100, Training Loss: 0.28425899147987366, Validation Loss: 0.07140849530696869\n",
      "Epoch 84/100, Training Loss: 0.2812490463256836, Validation Loss: 0.0710005909204483\n",
      "Epoch 85/100, Training Loss: 0.2829272449016571, Validation Loss: 0.0705750361084938\n",
      "Epoch 86/100, Training Loss: 0.27903246879577637, Validation Loss: 0.07010994851589203\n",
      "Epoch 87/100, Training Loss: 0.2780389189720154, Validation Loss: 0.0697205439209938\n",
      "Epoch 88/100, Training Loss: 0.27362313866615295, Validation Loss: 0.06940791755914688\n",
      "Epoch 89/100, Training Loss: 0.2744576334953308, Validation Loss: 0.06906906515359879\n",
      "Epoch 90/100, Training Loss: 0.2733442783355713, Validation Loss: 0.06873224675655365\n",
      "Epoch 91/100, Training Loss: 0.2686082720756531, Validation Loss: 0.06840936839580536\n",
      "Epoch 92/100, Training Loss: 0.2665284276008606, Validation Loss: 0.0681193470954895\n",
      "Epoch 93/100, Training Loss: 0.26567012071609497, Validation Loss: 0.0677165538072586\n",
      "Epoch 94/100, Training Loss: 0.26392272114753723, Validation Loss: 0.06739114969968796\n",
      "Epoch 95/100, Training Loss: 0.2604932188987732, Validation Loss: 0.067048579454422\n",
      "Epoch 96/100, Training Loss: 0.2591870129108429, Validation Loss: 0.06673618406057358\n",
      "Epoch 97/100, Training Loss: 0.2583661377429962, Validation Loss: 0.06641995906829834\n",
      "Epoch 98/100, Training Loss: 0.2569839060306549, Validation Loss: 0.06603603065013885\n",
      "Epoch 99/100, Training Loss: 0.2543407678604126, Validation Loss: 0.06570310145616531\n",
      "Epoch 100/100, Training Loss: 0.25120973587036133, Validation Loss: 0.06539884209632874\n",
      "Fold 1 - R² Score: 0.9345, MAE: 0.1664\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 4.058403968811035, Validation Loss: 1.103692889213562\n",
      "Epoch 2/100, Training Loss: 3.6586530208587646, Validation Loss: 1.0335849523544312\n",
      "Epoch 3/100, Training Loss: 3.327805757522583, Validation Loss: 0.9671215415000916\n",
      "Epoch 4/100, Training Loss: 2.9594085216522217, Validation Loss: 0.9044290781021118\n",
      "Epoch 5/100, Training Loss: 2.6598780155181885, Validation Loss: 0.8441823124885559\n",
      "Epoch 6/100, Training Loss: 2.4082682132720947, Validation Loss: 0.7856577634811401\n",
      "Epoch 7/100, Training Loss: 2.20045804977417, Validation Loss: 0.7297049760818481\n",
      "Epoch 8/100, Training Loss: 1.981670618057251, Validation Loss: 0.6764572858810425\n",
      "Epoch 9/100, Training Loss: 1.8166067600250244, Validation Loss: 0.6264528036117554\n",
      "Epoch 10/100, Training Loss: 1.659613847732544, Validation Loss: 0.5804813504219055\n",
      "Epoch 11/100, Training Loss: 1.541176676750183, Validation Loss: 0.5382821559906006\n",
      "Epoch 12/100, Training Loss: 1.4293378591537476, Validation Loss: 0.4993772506713867\n",
      "Epoch 13/100, Training Loss: 1.3463817834854126, Validation Loss: 0.46346867084503174\n",
      "Epoch 14/100, Training Loss: 1.2587143182754517, Validation Loss: 0.4302283823490143\n",
      "Epoch 15/100, Training Loss: 1.1775699853897095, Validation Loss: 0.3993559181690216\n",
      "Epoch 16/100, Training Loss: 1.113025188446045, Validation Loss: 0.37036025524139404\n",
      "Epoch 17/100, Training Loss: 1.0444843769073486, Validation Loss: 0.34277063608169556\n",
      "Epoch 18/100, Training Loss: 0.990882158279419, Validation Loss: 0.31639647483825684\n",
      "Epoch 19/100, Training Loss: 0.9348847270011902, Validation Loss: 0.29113128781318665\n",
      "Epoch 20/100, Training Loss: 0.8854365348815918, Validation Loss: 0.2670259475708008\n",
      "Epoch 21/100, Training Loss: 0.8534887433052063, Validation Loss: 0.2441892772912979\n",
      "Epoch 22/100, Training Loss: 0.809651255607605, Validation Loss: 0.22278441488742828\n",
      "Epoch 23/100, Training Loss: 0.7751669883728027, Validation Loss: 0.20279431343078613\n",
      "Epoch 24/100, Training Loss: 0.7476516366004944, Validation Loss: 0.18407948315143585\n",
      "Epoch 25/100, Training Loss: 0.7151526808738708, Validation Loss: 0.16656474769115448\n",
      "Epoch 26/100, Training Loss: 0.6846516728401184, Validation Loss: 0.15067917108535767\n",
      "Epoch 27/100, Training Loss: 0.6683642864227295, Validation Loss: 0.1365162581205368\n",
      "Epoch 28/100, Training Loss: 0.6383195519447327, Validation Loss: 0.12398841232061386\n",
      "Epoch 29/100, Training Loss: 0.6282715797424316, Validation Loss: 0.11298219114542007\n",
      "Epoch 30/100, Training Loss: 0.5962095856666565, Validation Loss: 0.10343922674655914\n",
      "Epoch 31/100, Training Loss: 0.579671323299408, Validation Loss: 0.09538083523511887\n",
      "Epoch 32/100, Training Loss: 0.5690435171127319, Validation Loss: 0.08844659477472305\n",
      "Epoch 33/100, Training Loss: 0.5506982803344727, Validation Loss: 0.08263151347637177\n",
      "Epoch 34/100, Training Loss: 0.5410483479499817, Validation Loss: 0.07787683606147766\n",
      "Epoch 35/100, Training Loss: 0.5297239422798157, Validation Loss: 0.07379427552223206\n",
      "Epoch 36/100, Training Loss: 0.5168634653091431, Validation Loss: 0.07047252357006073\n",
      "Epoch 37/100, Training Loss: 0.5084004402160645, Validation Loss: 0.06771016120910645\n",
      "Epoch 38/100, Training Loss: 0.49634990096092224, Validation Loss: 0.06545644253492355\n",
      "Epoch 39/100, Training Loss: 0.47964221239089966, Validation Loss: 0.0635276809334755\n",
      "Epoch 40/100, Training Loss: 0.47130438685417175, Validation Loss: 0.06199207529425621\n",
      "Epoch 41/100, Training Loss: 0.4585438370704651, Validation Loss: 0.060754623264074326\n",
      "Epoch 42/100, Training Loss: 0.4561576545238495, Validation Loss: 0.05970774218440056\n",
      "Epoch 43/100, Training Loss: 0.4467851221561432, Validation Loss: 0.05888361856341362\n",
      "Epoch 44/100, Training Loss: 0.43785303831100464, Validation Loss: 0.058184221386909485\n",
      "Epoch 45/100, Training Loss: 0.4290598928928375, Validation Loss: 0.057609133422374725\n",
      "Epoch 46/100, Training Loss: 0.4206297993659973, Validation Loss: 0.05711720511317253\n",
      "Epoch 47/100, Training Loss: 0.4093976318836212, Validation Loss: 0.056871797889471054\n",
      "Epoch 48/100, Training Loss: 0.40625113248825073, Validation Loss: 0.05658338963985443\n",
      "Epoch 49/100, Training Loss: 0.39917251467704773, Validation Loss: 0.05641931667923927\n",
      "Epoch 50/100, Training Loss: 0.39686381816864014, Validation Loss: 0.056310124695301056\n",
      "Epoch 51/100, Training Loss: 0.38924017548561096, Validation Loss: 0.05620371922850609\n",
      "Epoch 52/100, Training Loss: 0.3826376497745514, Validation Loss: 0.056079763919115067\n",
      "Epoch 53/100, Training Loss: 0.3747648298740387, Validation Loss: 0.055929090827703476\n",
      "Epoch 54/100, Training Loss: 0.3694517910480499, Validation Loss: 0.05578968673944473\n",
      "Epoch 55/100, Training Loss: 0.36529621481895447, Validation Loss: 0.05559426546096802\n",
      "Epoch 56/100, Training Loss: 0.36549878120422363, Validation Loss: 0.055334024131298065\n",
      "Epoch 57/100, Training Loss: 0.35651397705078125, Validation Loss: 0.05515017732977867\n",
      "Epoch 58/100, Training Loss: 0.35152941942214966, Validation Loss: 0.054934605956077576\n",
      "Epoch 59/100, Training Loss: 0.346668541431427, Validation Loss: 0.054750896990299225\n",
      "Epoch 60/100, Training Loss: 0.3479044735431671, Validation Loss: 0.05448642373085022\n",
      "Epoch 61/100, Training Loss: 0.34398940205574036, Validation Loss: 0.05419640988111496\n",
      "Epoch 62/100, Training Loss: 0.3334389328956604, Validation Loss: 0.05391770228743553\n",
      "Epoch 63/100, Training Loss: 0.33268705010414124, Validation Loss: 0.05359334871172905\n",
      "Epoch 64/100, Training Loss: 0.3331029713153839, Validation Loss: 0.05316299945116043\n",
      "Epoch 65/100, Training Loss: 0.32220107316970825, Validation Loss: 0.05289999023079872\n",
      "Epoch 66/100, Training Loss: 0.3193518817424774, Validation Loss: 0.05265602096915245\n",
      "Epoch 67/100, Training Loss: 0.3183315098285675, Validation Loss: 0.05240803584456444\n",
      "Epoch 68/100, Training Loss: 0.3145602345466614, Validation Loss: 0.05215437710285187\n",
      "Epoch 69/100, Training Loss: 0.3132743239402771, Validation Loss: 0.051826659590005875\n",
      "Epoch 70/100, Training Loss: 0.3072359263896942, Validation Loss: 0.05155806615948677\n",
      "Epoch 71/100, Training Loss: 0.30704885721206665, Validation Loss: 0.051214925944805145\n",
      "Epoch 72/100, Training Loss: 0.30410999059677124, Validation Loss: 0.050900042057037354\n",
      "Epoch 73/100, Training Loss: 0.2978222072124481, Validation Loss: 0.05059131979942322\n",
      "Epoch 74/100, Training Loss: 0.2966551184654236, Validation Loss: 0.050415731966495514\n",
      "Epoch 75/100, Training Loss: 0.2938424348831177, Validation Loss: 0.05024339631199837\n",
      "Epoch 76/100, Training Loss: 0.2907482385635376, Validation Loss: 0.05005722492933273\n",
      "Epoch 77/100, Training Loss: 0.28850531578063965, Validation Loss: 0.04983469843864441\n",
      "Epoch 78/100, Training Loss: 0.2845759689807892, Validation Loss: 0.04962393268942833\n",
      "Epoch 79/100, Training Loss: 0.2838315963745117, Validation Loss: 0.04937248304486275\n",
      "Epoch 80/100, Training Loss: 0.2824879288673401, Validation Loss: 0.049084216356277466\n",
      "Epoch 81/100, Training Loss: 0.279022216796875, Validation Loss: 0.04888435825705528\n",
      "Epoch 82/100, Training Loss: 0.27806195616722107, Validation Loss: 0.048562124371528625\n",
      "Epoch 83/100, Training Loss: 0.275043249130249, Validation Loss: 0.048375122249126434\n",
      "Epoch 84/100, Training Loss: 0.2723175585269928, Validation Loss: 0.04811537265777588\n",
      "Epoch 85/100, Training Loss: 0.27240851521492004, Validation Loss: 0.04791044443845749\n",
      "Epoch 86/100, Training Loss: 0.2688084840774536, Validation Loss: 0.04768858104944229\n",
      "Epoch 87/100, Training Loss: 0.2681051194667816, Validation Loss: 0.047476090490818024\n",
      "Epoch 88/100, Training Loss: 0.2634938657283783, Validation Loss: 0.047341376543045044\n",
      "Epoch 89/100, Training Loss: 0.25922662019729614, Validation Loss: 0.04722001031041145\n",
      "Epoch 90/100, Training Loss: 0.2617811858654022, Validation Loss: 0.047082554548978806\n",
      "Epoch 91/100, Training Loss: 0.2555992901325226, Validation Loss: 0.04702741652727127\n",
      "Epoch 92/100, Training Loss: 0.25685998797416687, Validation Loss: 0.046940628439188004\n",
      "Epoch 93/100, Training Loss: 0.2571243345737457, Validation Loss: 0.04685080051422119\n",
      "Epoch 94/100, Training Loss: 0.2542881965637207, Validation Loss: 0.04680701717734337\n",
      "Epoch 95/100, Training Loss: 0.2518773674964905, Validation Loss: 0.04669211804866791\n",
      "Epoch 96/100, Training Loss: 0.2511656880378723, Validation Loss: 0.04665272310376167\n",
      "Epoch 97/100, Training Loss: 0.2504013180732727, Validation Loss: 0.04653915762901306\n",
      "Epoch 98/100, Training Loss: 0.24303364753723145, Validation Loss: 0.04648663476109505\n",
      "Epoch 99/100, Training Loss: 0.24494867026805878, Validation Loss: 0.0464443601667881\n",
      "Epoch 100/100, Training Loss: 0.24374611675739288, Validation Loss: 0.04630645364522934\n",
      "Fold 2 - R² Score: 0.9541, MAE: 0.1328\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 2.8183205127716064, Validation Loss: 0.8698648810386658\n",
      "Epoch 2/100, Training Loss: 2.5180318355560303, Validation Loss: 0.810221791267395\n",
      "Epoch 3/100, Training Loss: 2.246455669403076, Validation Loss: 0.746262788772583\n",
      "Epoch 4/100, Training Loss: 2.0155413150787354, Validation Loss: 0.6847984790802002\n",
      "Epoch 5/100, Training Loss: 1.8241523504257202, Validation Loss: 0.628567636013031\n",
      "Epoch 6/100, Training Loss: 1.6838675737380981, Validation Loss: 0.5783491730690002\n",
      "Epoch 7/100, Training Loss: 1.598060965538025, Validation Loss: 0.5349966883659363\n",
      "Epoch 8/100, Training Loss: 1.4778515100479126, Validation Loss: 0.4966392517089844\n",
      "Epoch 9/100, Training Loss: 1.402890920639038, Validation Loss: 0.4626261293888092\n",
      "Epoch 10/100, Training Loss: 1.3222194910049438, Validation Loss: 0.4323492646217346\n",
      "Epoch 11/100, Training Loss: 1.2612279653549194, Validation Loss: 0.40540146827697754\n",
      "Epoch 12/100, Training Loss: 1.192842960357666, Validation Loss: 0.3813243806362152\n",
      "Epoch 13/100, Training Loss: 1.1385478973388672, Validation Loss: 0.3596177101135254\n",
      "Epoch 14/100, Training Loss: 1.0842751264572144, Validation Loss: 0.3398667573928833\n",
      "Epoch 15/100, Training Loss: 1.0332893133163452, Validation Loss: 0.3218114674091339\n",
      "Epoch 16/100, Training Loss: 0.9859461188316345, Validation Loss: 0.30503442883491516\n",
      "Epoch 17/100, Training Loss: 0.942022979259491, Validation Loss: 0.28960785269737244\n",
      "Epoch 18/100, Training Loss: 0.9016342163085938, Validation Loss: 0.2752542793750763\n",
      "Epoch 19/100, Training Loss: 0.8711516261100769, Validation Loss: 0.26136335730552673\n",
      "Epoch 20/100, Training Loss: 0.8348045945167542, Validation Loss: 0.24803020060062408\n",
      "Epoch 21/100, Training Loss: 0.810200035572052, Validation Loss: 0.2350907176733017\n",
      "Epoch 22/100, Training Loss: 0.774555504322052, Validation Loss: 0.22257927060127258\n",
      "Epoch 23/100, Training Loss: 0.7487239241600037, Validation Loss: 0.21052800118923187\n",
      "Epoch 24/100, Training Loss: 0.7220790386199951, Validation Loss: 0.1988890916109085\n",
      "Epoch 25/100, Training Loss: 0.7026926279067993, Validation Loss: 0.18771880865097046\n",
      "Epoch 26/100, Training Loss: 0.6765468120574951, Validation Loss: 0.1771409660577774\n",
      "Epoch 27/100, Training Loss: 0.668161153793335, Validation Loss: 0.16722479462623596\n",
      "Epoch 28/100, Training Loss: 0.6386283040046692, Validation Loss: 0.15820777416229248\n",
      "Epoch 29/100, Training Loss: 0.6175351738929749, Validation Loss: 0.14992445707321167\n",
      "Epoch 30/100, Training Loss: 0.604744017124176, Validation Loss: 0.1424514651298523\n",
      "Epoch 31/100, Training Loss: 0.5835250616073608, Validation Loss: 0.13554856181144714\n",
      "Epoch 32/100, Training Loss: 0.5744273662567139, Validation Loss: 0.12925522029399872\n",
      "Epoch 33/100, Training Loss: 0.5585941076278687, Validation Loss: 0.12357515096664429\n",
      "Epoch 34/100, Training Loss: 0.5385758280754089, Validation Loss: 0.11828707903623581\n",
      "Epoch 35/100, Training Loss: 0.5301277041435242, Validation Loss: 0.11325596272945404\n",
      "Epoch 36/100, Training Loss: 0.5225091576576233, Validation Loss: 0.10859639197587967\n",
      "Epoch 37/100, Training Loss: 0.5091367363929749, Validation Loss: 0.10417888313531876\n",
      "Epoch 38/100, Training Loss: 0.4943765103816986, Validation Loss: 0.10005269944667816\n",
      "Epoch 39/100, Training Loss: 0.4838005304336548, Validation Loss: 0.09619101881980896\n",
      "Epoch 40/100, Training Loss: 0.474654883146286, Validation Loss: 0.09260327368974686\n",
      "Epoch 41/100, Training Loss: 0.46735164523124695, Validation Loss: 0.08929597586393356\n",
      "Epoch 42/100, Training Loss: 0.45623037219047546, Validation Loss: 0.08632922172546387\n",
      "Epoch 43/100, Training Loss: 0.44550949335098267, Validation Loss: 0.0834609866142273\n",
      "Epoch 44/100, Training Loss: 0.4405463635921478, Validation Loss: 0.08068022131919861\n",
      "Epoch 45/100, Training Loss: 0.42962267994880676, Validation Loss: 0.07813327759504318\n",
      "Epoch 46/100, Training Loss: 0.41944459080696106, Validation Loss: 0.07572051882743835\n",
      "Epoch 47/100, Training Loss: 0.4159657955169678, Validation Loss: 0.0734059289097786\n",
      "Epoch 48/100, Training Loss: 0.4056881070137024, Validation Loss: 0.07125875353813171\n",
      "Epoch 49/100, Training Loss: 0.4010421335697174, Validation Loss: 0.06923667341470718\n",
      "Epoch 50/100, Training Loss: 0.39206692576408386, Validation Loss: 0.06728624552488327\n",
      "Epoch 51/100, Training Loss: 0.3865300416946411, Validation Loss: 0.065541572868824\n",
      "Epoch 52/100, Training Loss: 0.379431813955307, Validation Loss: 0.06398648023605347\n",
      "Epoch 53/100, Training Loss: 0.37573060393333435, Validation Loss: 0.06254537403583527\n",
      "Epoch 54/100, Training Loss: 0.37166085839271545, Validation Loss: 0.061230458319187164\n",
      "Epoch 55/100, Training Loss: 0.3616962730884552, Validation Loss: 0.060003407299518585\n",
      "Epoch 56/100, Training Loss: 0.3581300675868988, Validation Loss: 0.058957308530807495\n",
      "Epoch 57/100, Training Loss: 0.352488249540329, Validation Loss: 0.058024708181619644\n",
      "Epoch 58/100, Training Loss: 0.34593138098716736, Validation Loss: 0.0571725070476532\n",
      "Epoch 59/100, Training Loss: 0.34319165349006653, Validation Loss: 0.05642988532781601\n",
      "Epoch 60/100, Training Loss: 0.3355686068534851, Validation Loss: 0.055727891623973846\n",
      "Epoch 61/100, Training Loss: 0.3357645571231842, Validation Loss: 0.05508884787559509\n",
      "Epoch 62/100, Training Loss: 0.3294907212257385, Validation Loss: 0.05439385399222374\n",
      "Epoch 63/100, Training Loss: 0.3246382474899292, Validation Loss: 0.053779248148202896\n",
      "Epoch 64/100, Training Loss: 0.32000988721847534, Validation Loss: 0.05315665900707245\n",
      "Epoch 65/100, Training Loss: 0.31936758756637573, Validation Loss: 0.05256011709570885\n",
      "Epoch 66/100, Training Loss: 0.31199437379837036, Validation Loss: 0.0521332323551178\n",
      "Epoch 67/100, Training Loss: 0.3100024461746216, Validation Loss: 0.05162741616368294\n",
      "Epoch 68/100, Training Loss: 0.3065607249736786, Validation Loss: 0.051203541457653046\n",
      "Epoch 69/100, Training Loss: 0.3040805757045746, Validation Loss: 0.0508153922855854\n",
      "Epoch 70/100, Training Loss: 0.30045682191848755, Validation Loss: 0.05043835565447807\n",
      "Epoch 71/100, Training Loss: 0.2942372262477875, Validation Loss: 0.05008973181247711\n",
      "Epoch 72/100, Training Loss: 0.29148462414741516, Validation Loss: 0.04973379522562027\n",
      "Epoch 73/100, Training Loss: 0.292779803276062, Validation Loss: 0.049399230629205704\n",
      "Epoch 74/100, Training Loss: 0.28740036487579346, Validation Loss: 0.048990845680236816\n",
      "Epoch 75/100, Training Loss: 0.28222984075546265, Validation Loss: 0.04860870912671089\n",
      "Epoch 76/100, Training Loss: 0.27897295355796814, Validation Loss: 0.0482829213142395\n",
      "Epoch 77/100, Training Loss: 0.276822566986084, Validation Loss: 0.04791538417339325\n",
      "Epoch 78/100, Training Loss: 0.27499857544898987, Validation Loss: 0.04758969321846962\n",
      "Epoch 79/100, Training Loss: 0.27123308181762695, Validation Loss: 0.04724176228046417\n",
      "Epoch 80/100, Training Loss: 0.2701098620891571, Validation Loss: 0.04695067182183266\n",
      "Epoch 81/100, Training Loss: 0.26685771346092224, Validation Loss: 0.04665372893214226\n",
      "Epoch 82/100, Training Loss: 0.2653177082538605, Validation Loss: 0.04640430212020874\n",
      "Epoch 83/100, Training Loss: 0.2621701955795288, Validation Loss: 0.046211179345846176\n",
      "Epoch 84/100, Training Loss: 0.2629089057445526, Validation Loss: 0.04600594937801361\n",
      "Epoch 85/100, Training Loss: 0.25874024629592896, Validation Loss: 0.04578442871570587\n",
      "Epoch 86/100, Training Loss: 0.25746190547943115, Validation Loss: 0.04552055895328522\n",
      "Epoch 87/100, Training Loss: 0.2535771131515503, Validation Loss: 0.04526590555906296\n",
      "Epoch 88/100, Training Loss: 0.2533634603023529, Validation Loss: 0.04501062259078026\n",
      "Epoch 89/100, Training Loss: 0.2528901994228363, Validation Loss: 0.04481862857937813\n",
      "Epoch 90/100, Training Loss: 0.24671515822410583, Validation Loss: 0.044573623687028885\n",
      "Epoch 91/100, Training Loss: 0.24621351063251495, Validation Loss: 0.04442731663584709\n",
      "Epoch 92/100, Training Loss: 0.24424898624420166, Validation Loss: 0.04425837844610214\n",
      "Epoch 93/100, Training Loss: 0.24024558067321777, Validation Loss: 0.04412338137626648\n",
      "Epoch 94/100, Training Loss: 0.23961837589740753, Validation Loss: 0.043948154896497726\n",
      "Epoch 95/100, Training Loss: 0.239397794008255, Validation Loss: 0.04374851658940315\n",
      "Epoch 96/100, Training Loss: 0.23762354254722595, Validation Loss: 0.043575115501880646\n",
      "Epoch 97/100, Training Loss: 0.23602719604969025, Validation Loss: 0.04341511055827141\n",
      "Epoch 98/100, Training Loss: 0.2345646172761917, Validation Loss: 0.043224841356277466\n",
      "Epoch 99/100, Training Loss: 0.23009485006332397, Validation Loss: 0.043077293783426285\n",
      "Epoch 100/100, Training Loss: 0.23058754205703735, Validation Loss: 0.04287862405180931\n",
      "Fold 3 - R² Score: 0.9568, MAE: 0.1234\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 3.17413067817688, Validation Loss: 0.8843501806259155\n",
      "Epoch 2/100, Training Loss: 2.813588857650757, Validation Loss: 0.8391842842102051\n",
      "Epoch 3/100, Training Loss: 2.5051980018615723, Validation Loss: 0.793452262878418\n",
      "Epoch 4/100, Training Loss: 2.271221399307251, Validation Loss: 0.746782660484314\n",
      "Epoch 5/100, Training Loss: 2.04490065574646, Validation Loss: 0.7008298635482788\n",
      "Epoch 6/100, Training Loss: 1.8744597434997559, Validation Loss: 0.6557856202125549\n",
      "Epoch 7/100, Training Loss: 1.733397126197815, Validation Loss: 0.6126235127449036\n",
      "Epoch 8/100, Training Loss: 1.6235677003860474, Validation Loss: 0.571846067905426\n",
      "Epoch 9/100, Training Loss: 1.5023298263549805, Validation Loss: 0.533992350101471\n",
      "Epoch 10/100, Training Loss: 1.4132262468338013, Validation Loss: 0.4992513358592987\n",
      "Epoch 11/100, Training Loss: 1.3419435024261475, Validation Loss: 0.4667164981365204\n",
      "Epoch 12/100, Training Loss: 1.257738471031189, Validation Loss: 0.43542081117630005\n",
      "Epoch 13/100, Training Loss: 1.1905759572982788, Validation Loss: 0.4053308963775635\n",
      "Epoch 14/100, Training Loss: 1.1409631967544556, Validation Loss: 0.3758722245693207\n",
      "Epoch 15/100, Training Loss: 1.07888662815094, Validation Loss: 0.34818726778030396\n",
      "Epoch 16/100, Training Loss: 1.0178924798965454, Validation Loss: 0.32224369049072266\n",
      "Epoch 17/100, Training Loss: 0.9755212664604187, Validation Loss: 0.29843005537986755\n",
      "Epoch 18/100, Training Loss: 0.9289519786834717, Validation Loss: 0.275910884141922\n",
      "Epoch 19/100, Training Loss: 0.8957787156105042, Validation Loss: 0.2548023462295532\n",
      "Epoch 20/100, Training Loss: 0.8606305718421936, Validation Loss: 0.23530453443527222\n",
      "Epoch 21/100, Training Loss: 0.8199501633644104, Validation Loss: 0.21779638528823853\n",
      "Epoch 22/100, Training Loss: 0.7861018180847168, Validation Loss: 0.20182077586650848\n",
      "Epoch 23/100, Training Loss: 0.7608981132507324, Validation Loss: 0.18753084540367126\n",
      "Epoch 24/100, Training Loss: 0.7378814220428467, Validation Loss: 0.1747652292251587\n",
      "Epoch 25/100, Training Loss: 0.7153509855270386, Validation Loss: 0.16280780732631683\n",
      "Epoch 26/100, Training Loss: 0.6804801225662231, Validation Loss: 0.15222971141338348\n",
      "Epoch 27/100, Training Loss: 0.6623767614364624, Validation Loss: 0.14210724830627441\n",
      "Epoch 28/100, Training Loss: 0.6403140425682068, Validation Loss: 0.13253359496593475\n",
      "Epoch 29/100, Training Loss: 0.6305620074272156, Validation Loss: 0.12387397140264511\n",
      "Epoch 30/100, Training Loss: 0.6068884134292603, Validation Loss: 0.11605875194072723\n",
      "Epoch 31/100, Training Loss: 0.5947178602218628, Validation Loss: 0.1093924269080162\n",
      "Epoch 32/100, Training Loss: 0.5778679847717285, Validation Loss: 0.10371984541416168\n",
      "Epoch 33/100, Training Loss: 0.5632789731025696, Validation Loss: 0.09886883199214935\n",
      "Epoch 34/100, Training Loss: 0.5449702739715576, Validation Loss: 0.09471229463815689\n",
      "Epoch 35/100, Training Loss: 0.5355938673019409, Validation Loss: 0.09101711958646774\n",
      "Epoch 36/100, Training Loss: 0.5208879709243774, Validation Loss: 0.0876036211848259\n",
      "Epoch 37/100, Training Loss: 0.5005825757980347, Validation Loss: 0.08469796180725098\n",
      "Epoch 38/100, Training Loss: 0.4949914515018463, Validation Loss: 0.08216699212789536\n",
      "Epoch 39/100, Training Loss: 0.48624709248542786, Validation Loss: 0.08009056746959686\n",
      "Epoch 40/100, Training Loss: 0.47130098938941956, Validation Loss: 0.07838017493486404\n",
      "Epoch 41/100, Training Loss: 0.4581788182258606, Validation Loss: 0.0770258828997612\n",
      "Epoch 42/100, Training Loss: 0.45158299803733826, Validation Loss: 0.07573205232620239\n",
      "Epoch 43/100, Training Loss: 0.44680124521255493, Validation Loss: 0.0745772272348404\n",
      "Epoch 44/100, Training Loss: 0.4350152313709259, Validation Loss: 0.073420949280262\n",
      "Epoch 45/100, Training Loss: 0.42711058259010315, Validation Loss: 0.07212211191654205\n",
      "Epoch 46/100, Training Loss: 0.4187585711479187, Validation Loss: 0.07082890719175339\n",
      "Epoch 47/100, Training Loss: 0.4154309332370758, Validation Loss: 0.06940335035324097\n",
      "Epoch 48/100, Training Loss: 0.40753769874572754, Validation Loss: 0.0680149644613266\n",
      "Epoch 49/100, Training Loss: 0.4024324119091034, Validation Loss: 0.06658293306827545\n",
      "Epoch 50/100, Training Loss: 0.390520840883255, Validation Loss: 0.06521982699632645\n",
      "Epoch 51/100, Training Loss: 0.3807810842990875, Validation Loss: 0.06411053240299225\n",
      "Epoch 52/100, Training Loss: 0.3752564489841461, Validation Loss: 0.0630325973033905\n",
      "Epoch 53/100, Training Loss: 0.3682125508785248, Validation Loss: 0.06208132952451706\n",
      "Epoch 54/100, Training Loss: 0.3665785491466522, Validation Loss: 0.061098892241716385\n",
      "Epoch 55/100, Training Loss: 0.3572421967983246, Validation Loss: 0.06025290489196777\n",
      "Epoch 56/100, Training Loss: 0.35174381732940674, Validation Loss: 0.05936649069190025\n",
      "Epoch 57/100, Training Loss: 0.3463563621044159, Validation Loss: 0.058651577681303024\n",
      "Epoch 58/100, Training Loss: 0.3494928479194641, Validation Loss: 0.0578826405107975\n",
      "Epoch 59/100, Training Loss: 0.3418049216270447, Validation Loss: 0.05709497630596161\n",
      "Epoch 60/100, Training Loss: 0.3360174000263214, Validation Loss: 0.05639968812465668\n",
      "Epoch 61/100, Training Loss: 0.33291083574295044, Validation Loss: 0.05570029094815254\n",
      "Epoch 62/100, Training Loss: 0.3288959860801697, Validation Loss: 0.05509461089968681\n",
      "Epoch 63/100, Training Loss: 0.32011258602142334, Validation Loss: 0.05451922491192818\n",
      "Epoch 64/100, Training Loss: 0.3201747536659241, Validation Loss: 0.05400892719626427\n",
      "Epoch 65/100, Training Loss: 0.3148449957370758, Validation Loss: 0.05346217006444931\n",
      "Epoch 66/100, Training Loss: 0.311432808637619, Validation Loss: 0.052947040647268295\n",
      "Epoch 67/100, Training Loss: 0.3021739423274994, Validation Loss: 0.052451640367507935\n",
      "Epoch 68/100, Training Loss: 0.3031890392303467, Validation Loss: 0.05185338109731674\n",
      "Epoch 69/100, Training Loss: 0.30095869302749634, Validation Loss: 0.05128718912601471\n",
      "Epoch 70/100, Training Loss: 0.2973414659500122, Validation Loss: 0.050624385476112366\n",
      "Epoch 71/100, Training Loss: 0.2903445363044739, Validation Loss: 0.05004359036684036\n",
      "Epoch 72/100, Training Loss: 0.2884177565574646, Validation Loss: 0.049548547714948654\n",
      "Epoch 73/100, Training Loss: 0.28639107942581177, Validation Loss: 0.049109894782304764\n",
      "Epoch 74/100, Training Loss: 0.28337007761001587, Validation Loss: 0.048695117235183716\n",
      "Epoch 75/100, Training Loss: 0.2800150513648987, Validation Loss: 0.048425909131765366\n",
      "Epoch 76/100, Training Loss: 0.277235209941864, Validation Loss: 0.048073526471853256\n",
      "Epoch 77/100, Training Loss: 0.2749612033367157, Validation Loss: 0.04761810600757599\n",
      "Epoch 78/100, Training Loss: 0.27152588963508606, Validation Loss: 0.04728303849697113\n",
      "Epoch 79/100, Training Loss: 0.27283787727355957, Validation Loss: 0.04691305756568909\n",
      "Epoch 80/100, Training Loss: 0.26680245995521545, Validation Loss: 0.046672187745571136\n",
      "Epoch 81/100, Training Loss: 0.2657662630081177, Validation Loss: 0.04643775522708893\n",
      "Epoch 82/100, Training Loss: 0.2610587477684021, Validation Loss: 0.04624131694436073\n",
      "Epoch 83/100, Training Loss: 0.26262444257736206, Validation Loss: 0.04607643559575081\n",
      "Epoch 84/100, Training Loss: 0.2579572796821594, Validation Loss: 0.04594164714217186\n",
      "Epoch 85/100, Training Loss: 0.25357526540756226, Validation Loss: 0.04587739333510399\n",
      "Epoch 86/100, Training Loss: 0.2539210319519043, Validation Loss: 0.045751675963401794\n",
      "Epoch 87/100, Training Loss: 0.2495758831501007, Validation Loss: 0.04571244493126869\n",
      "Epoch 88/100, Training Loss: 0.25293493270874023, Validation Loss: 0.04570107161998749\n",
      "Epoch 89/100, Training Loss: 0.247100830078125, Validation Loss: 0.04569888114929199\n",
      "Epoch 90/100, Training Loss: 0.2453729212284088, Validation Loss: 0.04568086192011833\n",
      "Epoch 91/100, Training Loss: 0.24854300916194916, Validation Loss: 0.04567071795463562\n",
      "Epoch 92/100, Training Loss: 0.24083910882472992, Validation Loss: 0.04570853337645531\n",
      "Epoch 93/100, Training Loss: 0.24129894375801086, Validation Loss: 0.0456271693110466\n",
      "Epoch 94/100, Training Loss: 0.23891250789165497, Validation Loss: 0.04559013247489929\n",
      "Epoch 95/100, Training Loss: 0.23876935243606567, Validation Loss: 0.04555336758494377\n",
      "Epoch 96/100, Training Loss: 0.23414286971092224, Validation Loss: 0.04546395316720009\n",
      "Epoch 97/100, Training Loss: 0.23204489052295685, Validation Loss: 0.045494258403778076\n",
      "Epoch 98/100, Training Loss: 0.22984322905540466, Validation Loss: 0.045487985014915466\n",
      "Epoch 99/100, Training Loss: 0.23072713613510132, Validation Loss: 0.04547467455267906\n",
      "Epoch 100/100, Training Loss: 0.2279849499464035, Validation Loss: 0.04546396806836128\n",
      "Fold 4 - R² Score: 0.9547, MAE: 0.1304\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 3.7071948051452637, Validation Loss: 1.310897707939148\n",
      "Epoch 2/100, Training Loss: 3.3632776737213135, Validation Loss: 1.2288572788238525\n",
      "Epoch 3/100, Training Loss: 3.0140113830566406, Validation Loss: 1.149993658065796\n",
      "Epoch 4/100, Training Loss: 2.7261791229248047, Validation Loss: 1.0731732845306396\n",
      "Epoch 5/100, Training Loss: 2.454536199569702, Validation Loss: 0.9974937438964844\n",
      "Epoch 6/100, Training Loss: 2.249699592590332, Validation Loss: 0.9236146807670593\n",
      "Epoch 7/100, Training Loss: 2.051482915878296, Validation Loss: 0.8525360822677612\n",
      "Epoch 8/100, Training Loss: 1.8925657272338867, Validation Loss: 0.7848246097564697\n",
      "Epoch 9/100, Training Loss: 1.7446993589401245, Validation Loss: 0.7209565043449402\n",
      "Epoch 10/100, Training Loss: 1.612112045288086, Validation Loss: 0.6607457399368286\n",
      "Epoch 11/100, Training Loss: 1.500982403755188, Validation Loss: 0.6049340963363647\n",
      "Epoch 12/100, Training Loss: 1.3789812326431274, Validation Loss: 0.5536608099937439\n",
      "Epoch 13/100, Training Loss: 1.3036175966262817, Validation Loss: 0.5077784061431885\n",
      "Epoch 14/100, Training Loss: 1.2310956716537476, Validation Loss: 0.46697014570236206\n",
      "Epoch 15/100, Training Loss: 1.1628955602645874, Validation Loss: 0.4305587112903595\n",
      "Epoch 16/100, Training Loss: 1.0991021394729614, Validation Loss: 0.39752331376075745\n",
      "Epoch 17/100, Training Loss: 1.048905372619629, Validation Loss: 0.36732643842697144\n",
      "Epoch 18/100, Training Loss: 0.9996355772018433, Validation Loss: 0.3399522602558136\n",
      "Epoch 19/100, Training Loss: 0.9488254189491272, Validation Loss: 0.3151380121707916\n",
      "Epoch 20/100, Training Loss: 0.9226723313331604, Validation Loss: 0.29274314641952515\n",
      "Epoch 21/100, Training Loss: 0.8730416893959045, Validation Loss: 0.27276739478111267\n",
      "Epoch 22/100, Training Loss: 0.8420360684394836, Validation Loss: 0.2551219165325165\n",
      "Epoch 23/100, Training Loss: 0.8080781698226929, Validation Loss: 0.23929843306541443\n",
      "Epoch 24/100, Training Loss: 0.7793644070625305, Validation Loss: 0.22530697286128998\n",
      "Epoch 25/100, Training Loss: 0.7474488019943237, Validation Loss: 0.21287763118743896\n",
      "Epoch 26/100, Training Loss: 0.7265717387199402, Validation Loss: 0.2017267346382141\n",
      "Epoch 27/100, Training Loss: 0.7022226452827454, Validation Loss: 0.19136615097522736\n",
      "Epoch 28/100, Training Loss: 0.6712504625320435, Validation Loss: 0.1820361614227295\n",
      "Epoch 29/100, Training Loss: 0.6662971377372742, Validation Loss: 0.17360830307006836\n",
      "Epoch 30/100, Training Loss: 0.6443207263946533, Validation Loss: 0.16598668694496155\n",
      "Epoch 31/100, Training Loss: 0.6288703680038452, Validation Loss: 0.15902242064476013\n",
      "Epoch 32/100, Training Loss: 0.6132318377494812, Validation Loss: 0.15244273841381073\n",
      "Epoch 33/100, Training Loss: 0.591383159160614, Validation Loss: 0.14639711380004883\n",
      "Epoch 34/100, Training Loss: 0.5800907611846924, Validation Loss: 0.14091454446315765\n",
      "Epoch 35/100, Training Loss: 0.5624990463256836, Validation Loss: 0.13567279279232025\n",
      "Epoch 36/100, Training Loss: 0.5509225130081177, Validation Loss: 0.13064296543598175\n",
      "Epoch 37/100, Training Loss: 0.5408257842063904, Validation Loss: 0.12584245204925537\n",
      "Epoch 38/100, Training Loss: 0.5251328945159912, Validation Loss: 0.12126964330673218\n",
      "Epoch 39/100, Training Loss: 0.5121756196022034, Validation Loss: 0.1170952320098877\n",
      "Epoch 40/100, Training Loss: 0.5008862018585205, Validation Loss: 0.11308719962835312\n",
      "Epoch 41/100, Training Loss: 0.49500513076782227, Validation Loss: 0.10903012752532959\n",
      "Epoch 42/100, Training Loss: 0.48540541529655457, Validation Loss: 0.10516880452632904\n",
      "Epoch 43/100, Training Loss: 0.474428653717041, Validation Loss: 0.10161034762859344\n",
      "Epoch 44/100, Training Loss: 0.46862316131591797, Validation Loss: 0.09843931347131729\n",
      "Epoch 45/100, Training Loss: 0.4536616802215576, Validation Loss: 0.09544520080089569\n",
      "Epoch 46/100, Training Loss: 0.4502871036529541, Validation Loss: 0.09262248128652573\n",
      "Epoch 47/100, Training Loss: 0.43925589323043823, Validation Loss: 0.08990278840065002\n",
      "Epoch 48/100, Training Loss: 0.43359702825546265, Validation Loss: 0.08748514950275421\n",
      "Epoch 49/100, Training Loss: 0.42529624700546265, Validation Loss: 0.08517293632030487\n",
      "Epoch 50/100, Training Loss: 0.41975605487823486, Validation Loss: 0.08305444568395615\n",
      "Epoch 51/100, Training Loss: 0.4117838144302368, Validation Loss: 0.08113821595907211\n",
      "Epoch 52/100, Training Loss: 0.40525075793266296, Validation Loss: 0.07930021733045578\n",
      "Epoch 53/100, Training Loss: 0.3976283669471741, Validation Loss: 0.07759397476911545\n",
      "Epoch 54/100, Training Loss: 0.3894388973712921, Validation Loss: 0.07614590227603912\n",
      "Epoch 55/100, Training Loss: 0.3823615610599518, Validation Loss: 0.0746706947684288\n",
      "Epoch 56/100, Training Loss: 0.37596186995506287, Validation Loss: 0.07337833940982819\n",
      "Epoch 57/100, Training Loss: 0.3709428310394287, Validation Loss: 0.07222754508256912\n",
      "Epoch 58/100, Training Loss: 0.36609694361686707, Validation Loss: 0.07124990224838257\n",
      "Epoch 59/100, Training Loss: 0.3642088770866394, Validation Loss: 0.07030963152647018\n",
      "Epoch 60/100, Training Loss: 0.35992151498794556, Validation Loss: 0.06938666850328445\n",
      "Epoch 61/100, Training Loss: 0.3549540936946869, Validation Loss: 0.06853602081537247\n",
      "Epoch 62/100, Training Loss: 0.3529822528362274, Validation Loss: 0.0676412582397461\n",
      "Epoch 63/100, Training Loss: 0.3458220958709717, Validation Loss: 0.06690794229507446\n",
      "Epoch 64/100, Training Loss: 0.33884477615356445, Validation Loss: 0.06609956175088882\n",
      "Epoch 65/100, Training Loss: 0.33744898438453674, Validation Loss: 0.06530532985925674\n",
      "Epoch 66/100, Training Loss: 0.3355349004268646, Validation Loss: 0.06469061225652695\n",
      "Epoch 67/100, Training Loss: 0.3268422782421112, Validation Loss: 0.06408067792654037\n",
      "Epoch 68/100, Training Loss: 0.3232332766056061, Validation Loss: 0.06344562023878098\n",
      "Epoch 69/100, Training Loss: 0.3192738890647888, Validation Loss: 0.06277553737163544\n",
      "Epoch 70/100, Training Loss: 0.31541112065315247, Validation Loss: 0.06222741678357124\n",
      "Epoch 71/100, Training Loss: 0.3140583634376526, Validation Loss: 0.061628613620996475\n",
      "Epoch 72/100, Training Loss: 0.3092184066772461, Validation Loss: 0.061110518872737885\n",
      "Epoch 73/100, Training Loss: 0.3032631278038025, Validation Loss: 0.06061040237545967\n",
      "Epoch 74/100, Training Loss: 0.3002970516681671, Validation Loss: 0.06013546139001846\n",
      "Epoch 75/100, Training Loss: 0.3014291226863861, Validation Loss: 0.05966101586818695\n",
      "Epoch 76/100, Training Loss: 0.2948104441165924, Validation Loss: 0.059204086661338806\n",
      "Epoch 77/100, Training Loss: 0.2892504334449768, Validation Loss: 0.058839086443185806\n",
      "Epoch 78/100, Training Loss: 0.28958794474601746, Validation Loss: 0.058318838477134705\n",
      "Epoch 79/100, Training Loss: 0.2890062928199768, Validation Loss: 0.05791623517870903\n",
      "Epoch 80/100, Training Loss: 0.2841031849384308, Validation Loss: 0.05752839148044586\n",
      "Epoch 81/100, Training Loss: 0.2807298004627228, Validation Loss: 0.05709197372198105\n",
      "Epoch 82/100, Training Loss: 0.2774905264377594, Validation Loss: 0.05672995001077652\n",
      "Epoch 83/100, Training Loss: 0.2743750512599945, Validation Loss: 0.056426774710416794\n",
      "Epoch 84/100, Training Loss: 0.2748044431209564, Validation Loss: 0.05611564218997955\n",
      "Epoch 85/100, Training Loss: 0.27332571148872375, Validation Loss: 0.055761225521564484\n",
      "Epoch 86/100, Training Loss: 0.26992183923721313, Validation Loss: 0.0554024837911129\n",
      "Epoch 87/100, Training Loss: 0.2654562294483185, Validation Loss: 0.05508808046579361\n",
      "Epoch 88/100, Training Loss: 0.2654019296169281, Validation Loss: 0.05475424602627754\n",
      "Epoch 89/100, Training Loss: 0.26126226782798767, Validation Loss: 0.05446266755461693\n",
      "Epoch 90/100, Training Loss: 0.2614181339740753, Validation Loss: 0.05420650914311409\n",
      "Epoch 91/100, Training Loss: 0.2603452503681183, Validation Loss: 0.05394522100687027\n",
      "Epoch 92/100, Training Loss: 0.25466495752334595, Validation Loss: 0.0536014586687088\n",
      "Epoch 93/100, Training Loss: 0.254905641078949, Validation Loss: 0.053299497812986374\n",
      "Epoch 94/100, Training Loss: 0.2533206343650818, Validation Loss: 0.05311673507094383\n",
      "Epoch 95/100, Training Loss: 0.2505178451538086, Validation Loss: 0.05304205045104027\n",
      "Epoch 96/100, Training Loss: 0.24963951110839844, Validation Loss: 0.052862197160720825\n",
      "Epoch 97/100, Training Loss: 0.2465800791978836, Validation Loss: 0.052762601524591446\n",
      "Epoch 98/100, Training Loss: 0.2455875277519226, Validation Loss: 0.05266878008842468\n",
      "Epoch 99/100, Training Loss: 0.24605146050453186, Validation Loss: 0.052507903426885605\n",
      "Epoch 100/100, Training Loss: 0.24263574182987213, Validation Loss: 0.052394330501556396\n",
      "Fold 5 - R² Score: 0.9477, MAE: 0.1235\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 16, 'learning_rate': 0.01}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.171950101852417, Validation Loss: 0.8778425455093384\n",
      "Epoch 2/100, Training Loss: 2.4921200275421143, Validation Loss: 0.7505543828010559\n",
      "Epoch 3/100, Training Loss: 1.9806517362594604, Validation Loss: 0.631965160369873\n",
      "Epoch 4/100, Training Loss: 1.5952084064483643, Validation Loss: 0.527438223361969\n",
      "Epoch 5/100, Training Loss: 1.3227362632751465, Validation Loss: 0.4409730136394501\n",
      "Epoch 6/100, Training Loss: 1.148186206817627, Validation Loss: 0.3729856312274933\n",
      "Epoch 7/100, Training Loss: 1.0167055130004883, Validation Loss: 0.3214753568172455\n",
      "Epoch 8/100, Training Loss: 0.9292647838592529, Validation Loss: 0.2829267084598541\n",
      "Epoch 9/100, Training Loss: 0.8480108380317688, Validation Loss: 0.2537587881088257\n",
      "Epoch 10/100, Training Loss: 0.771418571472168, Validation Loss: 0.23108595609664917\n",
      "Epoch 11/100, Training Loss: 0.7140267491340637, Validation Loss: 0.21239031851291656\n",
      "Epoch 12/100, Training Loss: 0.6493556499481201, Validation Loss: 0.1971210539340973\n",
      "Epoch 13/100, Training Loss: 0.5990094542503357, Validation Loss: 0.1845841258764267\n",
      "Epoch 14/100, Training Loss: 0.5548192262649536, Validation Loss: 0.17445938289165497\n",
      "Epoch 15/100, Training Loss: 0.5207068920135498, Validation Loss: 0.16638806462287903\n",
      "Epoch 16/100, Training Loss: 0.4894847571849823, Validation Loss: 0.16007013618946075\n",
      "Epoch 17/100, Training Loss: 0.45905601978302, Validation Loss: 0.15523600578308105\n",
      "Epoch 18/100, Training Loss: 0.43893036246299744, Validation Loss: 0.1514221727848053\n",
      "Epoch 19/100, Training Loss: 0.4210982918739319, Validation Loss: 0.14807218313217163\n",
      "Epoch 20/100, Training Loss: 0.39899179339408875, Validation Loss: 0.14508646726608276\n",
      "Epoch 21/100, Training Loss: 0.3965632915496826, Validation Loss: 0.14212021231651306\n",
      "Epoch 22/100, Training Loss: 0.3839835524559021, Validation Loss: 0.1390736699104309\n",
      "Epoch 23/100, Training Loss: 0.370378702878952, Validation Loss: 0.13548362255096436\n",
      "Epoch 24/100, Training Loss: 0.3622705638408661, Validation Loss: 0.1315516084432602\n",
      "Epoch 25/100, Training Loss: 0.35209494829177856, Validation Loss: 0.12694691121578217\n",
      "Epoch 26/100, Training Loss: 0.34259217977523804, Validation Loss: 0.12198757380247116\n",
      "Epoch 27/100, Training Loss: 0.33441004157066345, Validation Loss: 0.11653976887464523\n",
      "Epoch 28/100, Training Loss: 0.325815886259079, Validation Loss: 0.11096494644880295\n",
      "Epoch 29/100, Training Loss: 0.3151960074901581, Validation Loss: 0.10526533424854279\n",
      "Epoch 30/100, Training Loss: 0.30843546986579895, Validation Loss: 0.09961897134780884\n",
      "Epoch 31/100, Training Loss: 0.3011007010936737, Validation Loss: 0.09411007165908813\n",
      "Epoch 32/100, Training Loss: 0.2944500744342804, Validation Loss: 0.08905773609876633\n",
      "Epoch 33/100, Training Loss: 0.28602102398872375, Validation Loss: 0.08445993810892105\n",
      "Epoch 34/100, Training Loss: 0.2805904448032379, Validation Loss: 0.08042848855257034\n",
      "Epoch 35/100, Training Loss: 0.2770438492298126, Validation Loss: 0.07701097428798676\n",
      "Epoch 36/100, Training Loss: 0.2676357328891754, Validation Loss: 0.07406279444694519\n",
      "Epoch 37/100, Training Loss: 0.2596210837364197, Validation Loss: 0.07154782116413116\n",
      "Epoch 38/100, Training Loss: 0.25794655084609985, Validation Loss: 0.06903748959302902\n",
      "Epoch 39/100, Training Loss: 0.2540746331214905, Validation Loss: 0.06662192195653915\n",
      "Epoch 40/100, Training Loss: 0.25011011958122253, Validation Loss: 0.06414642184972763\n",
      "Epoch 41/100, Training Loss: 0.2467292696237564, Validation Loss: 0.06173102557659149\n",
      "Epoch 42/100, Training Loss: 0.242279052734375, Validation Loss: 0.05927296355366707\n",
      "Epoch 43/100, Training Loss: 0.2410879135131836, Validation Loss: 0.05711832642555237\n",
      "Epoch 44/100, Training Loss: 0.23535093665122986, Validation Loss: 0.05521944537758827\n",
      "Epoch 45/100, Training Loss: 0.2287718504667282, Validation Loss: 0.0536285936832428\n",
      "Epoch 46/100, Training Loss: 0.22905641794204712, Validation Loss: 0.05223555117845535\n",
      "Epoch 47/100, Training Loss: 0.2275211215019226, Validation Loss: 0.05107152834534645\n",
      "Epoch 48/100, Training Loss: 0.22364331781864166, Validation Loss: 0.05005182325839996\n",
      "Epoch 49/100, Training Loss: 0.22047734260559082, Validation Loss: 0.04922512173652649\n",
      "Epoch 50/100, Training Loss: 0.21770428121089935, Validation Loss: 0.04841739684343338\n",
      "Epoch 51/100, Training Loss: 0.21700610220432281, Validation Loss: 0.047802191227674484\n",
      "Epoch 52/100, Training Loss: 0.2138398438692093, Validation Loss: 0.04718358442187309\n",
      "Epoch 53/100, Training Loss: 0.21276235580444336, Validation Loss: 0.046619098633527756\n",
      "Epoch 54/100, Training Loss: 0.2092633992433548, Validation Loss: 0.04610833153128624\n",
      "Epoch 55/100, Training Loss: 0.20792677998542786, Validation Loss: 0.04572130739688873\n",
      "Epoch 56/100, Training Loss: 0.2058110386133194, Validation Loss: 0.04534657672047615\n",
      "Epoch 57/100, Training Loss: 0.20616377890110016, Validation Loss: 0.04507431015372276\n",
      "Epoch 58/100, Training Loss: 0.2033168077468872, Validation Loss: 0.04485039785504341\n",
      "Epoch 59/100, Training Loss: 0.19776038825511932, Validation Loss: 0.044733867049217224\n",
      "Epoch 60/100, Training Loss: 0.20074740052223206, Validation Loss: 0.044410549104213715\n",
      "Epoch 61/100, Training Loss: 0.19782516360282898, Validation Loss: 0.044081661850214005\n",
      "Epoch 62/100, Training Loss: 0.19638678431510925, Validation Loss: 0.043738070875406265\n",
      "Epoch 63/100, Training Loss: 0.19486872851848602, Validation Loss: 0.04335562512278557\n",
      "Epoch 64/100, Training Loss: 0.19453047215938568, Validation Loss: 0.04308946058154106\n",
      "Epoch 65/100, Training Loss: 0.18967397511005402, Validation Loss: 0.04293512925505638\n",
      "Epoch 66/100, Training Loss: 0.191700741648674, Validation Loss: 0.042881328612565994\n",
      "Epoch 67/100, Training Loss: 0.18859241902828217, Validation Loss: 0.042915139347314835\n",
      "Epoch 68/100, Training Loss: 0.18814560770988464, Validation Loss: 0.04296654835343361\n",
      "Epoch 69/100, Training Loss: 0.1845482587814331, Validation Loss: 0.04314808547496796\n",
      "Epoch 70/100, Training Loss: 0.1819709837436676, Validation Loss: 0.043357472866773605\n",
      "Epoch 71/100, Training Loss: 0.18395841121673584, Validation Loss: 0.043469782918691635\n",
      "Epoch 72/100, Training Loss: 0.18277785181999207, Validation Loss: 0.04353994503617287\n",
      "Epoch 73/100, Training Loss: 0.17950788140296936, Validation Loss: 0.04359450563788414\n",
      "Epoch 74/100, Training Loss: 0.1809529960155487, Validation Loss: 0.043632399290800095\n",
      "Epoch 75/100, Training Loss: 0.1802697777748108, Validation Loss: 0.043659016489982605\n",
      "Epoch 76/100, Training Loss: 0.17869846522808075, Validation Loss: 0.043817345052957535\n",
      "Early stopping triggered\n",
      "Fold 1 - R² Score: 0.9561, MAE: 0.1399\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 4.025205135345459, Validation Loss: 1.0415459871292114\n",
      "Epoch 2/100, Training Loss: 3.17822265625, Validation Loss: 0.9431154131889343\n",
      "Epoch 3/100, Training Loss: 2.6107120513916016, Validation Loss: 0.8384371995925903\n",
      "Epoch 4/100, Training Loss: 2.138240098953247, Validation Loss: 0.7410847544670105\n",
      "Epoch 5/100, Training Loss: 1.8373174667358398, Validation Loss: 0.655025839805603\n",
      "Epoch 6/100, Training Loss: 1.5977922677993774, Validation Loss: 0.5791478157043457\n",
      "Epoch 7/100, Training Loss: 1.4312498569488525, Validation Loss: 0.5133208632469177\n",
      "Epoch 8/100, Training Loss: 1.2774605751037598, Validation Loss: 0.4570521116256714\n",
      "Epoch 9/100, Training Loss: 1.1459803581237793, Validation Loss: 0.4106690287590027\n",
      "Epoch 10/100, Training Loss: 1.062851071357727, Validation Loss: 0.3721632957458496\n",
      "Epoch 11/100, Training Loss: 0.9741661548614502, Validation Loss: 0.33803635835647583\n",
      "Epoch 12/100, Training Loss: 0.9029510617256165, Validation Loss: 0.306594580411911\n",
      "Epoch 13/100, Training Loss: 0.8365411758422852, Validation Loss: 0.27833065390586853\n",
      "Epoch 14/100, Training Loss: 0.7922884821891785, Validation Loss: 0.25398319959640503\n",
      "Epoch 15/100, Training Loss: 0.7509427666664124, Validation Loss: 0.23338165879249573\n",
      "Epoch 16/100, Training Loss: 0.70096755027771, Validation Loss: 0.2157934457063675\n",
      "Epoch 17/100, Training Loss: 0.6684902906417847, Validation Loss: 0.2000848352909088\n",
      "Epoch 18/100, Training Loss: 0.6342360973358154, Validation Loss: 0.18627189099788666\n",
      "Epoch 19/100, Training Loss: 0.5985055565834045, Validation Loss: 0.17362387478351593\n",
      "Epoch 20/100, Training Loss: 0.5830352306365967, Validation Loss: 0.16163969039916992\n",
      "Epoch 21/100, Training Loss: 0.5450809001922607, Validation Loss: 0.1507752537727356\n",
      "Epoch 22/100, Training Loss: 0.5256938338279724, Validation Loss: 0.1408068835735321\n",
      "Epoch 23/100, Training Loss: 0.5086092352867126, Validation Loss: 0.1315554827451706\n",
      "Epoch 24/100, Training Loss: 0.48232802748680115, Validation Loss: 0.12322544306516647\n",
      "Epoch 25/100, Training Loss: 0.46776750683784485, Validation Loss: 0.11576896160840988\n",
      "Epoch 26/100, Training Loss: 0.4444914758205414, Validation Loss: 0.10934033244848251\n",
      "Epoch 27/100, Training Loss: 0.43683212995529175, Validation Loss: 0.10390524566173553\n",
      "Epoch 28/100, Training Loss: 0.4208937883377075, Validation Loss: 0.09932215511798859\n",
      "Epoch 29/100, Training Loss: 0.4076594412326813, Validation Loss: 0.09547246247529984\n",
      "Epoch 30/100, Training Loss: 0.39832401275634766, Validation Loss: 0.09193941950798035\n",
      "Epoch 31/100, Training Loss: 0.38379597663879395, Validation Loss: 0.08879221230745316\n",
      "Epoch 32/100, Training Loss: 0.37297531962394714, Validation Loss: 0.08604851365089417\n",
      "Epoch 33/100, Training Loss: 0.3678359389305115, Validation Loss: 0.08321624249219894\n",
      "Epoch 34/100, Training Loss: 0.3556824326515198, Validation Loss: 0.0807708129286766\n",
      "Epoch 35/100, Training Loss: 0.34943467378616333, Validation Loss: 0.07850062102079391\n",
      "Epoch 36/100, Training Loss: 0.3388518989086151, Validation Loss: 0.07623732835054398\n",
      "Epoch 37/100, Training Loss: 0.3344249129295349, Validation Loss: 0.0741003155708313\n",
      "Epoch 38/100, Training Loss: 0.3260737955570221, Validation Loss: 0.07198361307382584\n",
      "Epoch 39/100, Training Loss: 0.31838831305503845, Validation Loss: 0.06990469247102737\n",
      "Epoch 40/100, Training Loss: 0.3121083974838257, Validation Loss: 0.06748218834400177\n",
      "Epoch 41/100, Training Loss: 0.30813348293304443, Validation Loss: 0.06507718563079834\n",
      "Epoch 42/100, Training Loss: 0.29783812165260315, Validation Loss: 0.06263627111911774\n",
      "Epoch 43/100, Training Loss: 0.29445236921310425, Validation Loss: 0.060287315398454666\n",
      "Epoch 44/100, Training Loss: 0.2895510494709015, Validation Loss: 0.05828036367893219\n",
      "Epoch 45/100, Training Loss: 0.2848733961582184, Validation Loss: 0.056311435997486115\n",
      "Epoch 46/100, Training Loss: 0.28124934434890747, Validation Loss: 0.054511625319719315\n",
      "Epoch 47/100, Training Loss: 0.274504154920578, Validation Loss: 0.052926719188690186\n",
      "Epoch 48/100, Training Loss: 0.2712954580783844, Validation Loss: 0.051331840455532074\n",
      "Epoch 49/100, Training Loss: 0.26150083541870117, Validation Loss: 0.05001519247889519\n",
      "Epoch 50/100, Training Loss: 0.26025140285491943, Validation Loss: 0.04876227676868439\n",
      "Epoch 51/100, Training Loss: 0.26253294944763184, Validation Loss: 0.04751748964190483\n",
      "Epoch 52/100, Training Loss: 0.25496870279312134, Validation Loss: 0.046488504856824875\n",
      "Epoch 53/100, Training Loss: 0.25164803862571716, Validation Loss: 0.045716892927885056\n",
      "Epoch 54/100, Training Loss: 0.24978385865688324, Validation Loss: 0.045031048357486725\n",
      "Epoch 55/100, Training Loss: 0.24625010788440704, Validation Loss: 0.04453302174806595\n",
      "Epoch 56/100, Training Loss: 0.2427874505519867, Validation Loss: 0.04411974921822548\n",
      "Epoch 57/100, Training Loss: 0.2379547655582428, Validation Loss: 0.04392172396183014\n",
      "Epoch 58/100, Training Loss: 0.23670297861099243, Validation Loss: 0.04370728135108948\n",
      "Epoch 59/100, Training Loss: 0.23387347161769867, Validation Loss: 0.04349302500486374\n",
      "Epoch 60/100, Training Loss: 0.23191814124584198, Validation Loss: 0.04335371404886246\n",
      "Epoch 61/100, Training Loss: 0.22912649810314178, Validation Loss: 0.0432894341647625\n",
      "Epoch 62/100, Training Loss: 0.22487787902355194, Validation Loss: 0.04334517940878868\n",
      "Epoch 63/100, Training Loss: 0.22199022769927979, Validation Loss: 0.043419916182756424\n",
      "Epoch 64/100, Training Loss: 0.22280873358249664, Validation Loss: 0.043438348919153214\n",
      "Epoch 65/100, Training Loss: 0.22155822813510895, Validation Loss: 0.04361511021852493\n",
      "Epoch 66/100, Training Loss: 0.21900705993175507, Validation Loss: 0.04371752589941025\n",
      "Epoch 67/100, Training Loss: 0.21473322808742523, Validation Loss: 0.04386114701628685\n",
      "Epoch 68/100, Training Loss: 0.21202044188976288, Validation Loss: 0.04395435377955437\n",
      "Epoch 69/100, Training Loss: 0.21207545697689056, Validation Loss: 0.044033173471689224\n",
      "Epoch 70/100, Training Loss: 0.20967991650104523, Validation Loss: 0.04416969418525696\n",
      "Epoch 71/100, Training Loss: 0.20612217485904694, Validation Loss: 0.04421736299991608\n",
      "Early stopping triggered\n",
      "Fold 2 - R² Score: 0.9560, MAE: 0.1420\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 4.0510125160217285, Validation Loss: 1.097891092300415\n",
      "Epoch 2/100, Training Loss: 3.254030704498291, Validation Loss: 0.9674773812294006\n",
      "Epoch 3/100, Training Loss: 2.6747028827667236, Validation Loss: 0.85040283203125\n",
      "Epoch 4/100, Training Loss: 2.247098922729492, Validation Loss: 0.7512723803520203\n",
      "Epoch 5/100, Training Loss: 1.9005757570266724, Validation Loss: 0.6688234806060791\n",
      "Epoch 6/100, Training Loss: 1.6373059749603271, Validation Loss: 0.5944565534591675\n",
      "Epoch 7/100, Training Loss: 1.4323457479476929, Validation Loss: 0.5324001908302307\n",
      "Epoch 8/100, Training Loss: 1.2621688842773438, Validation Loss: 0.48354238271713257\n",
      "Epoch 9/100, Training Loss: 1.1246609687805176, Validation Loss: 0.4445779621601105\n",
      "Epoch 10/100, Training Loss: 1.0276399850845337, Validation Loss: 0.4112429618835449\n",
      "Epoch 11/100, Training Loss: 0.9181370735168457, Validation Loss: 0.381840318441391\n",
      "Epoch 12/100, Training Loss: 0.8559860587120056, Validation Loss: 0.35520273447036743\n",
      "Epoch 13/100, Training Loss: 0.7870990037918091, Validation Loss: 0.3303888738155365\n",
      "Epoch 14/100, Training Loss: 0.727390468120575, Validation Loss: 0.30701228976249695\n",
      "Epoch 15/100, Training Loss: 0.6775133609771729, Validation Loss: 0.28527113795280457\n",
      "Epoch 16/100, Training Loss: 0.639568567276001, Validation Loss: 0.2647324204444885\n",
      "Epoch 17/100, Training Loss: 0.6002355813980103, Validation Loss: 0.24531298875808716\n",
      "Epoch 18/100, Training Loss: 0.5731033086776733, Validation Loss: 0.22687126696109772\n",
      "Epoch 19/100, Training Loss: 0.5417904257774353, Validation Loss: 0.20935894548892975\n",
      "Epoch 20/100, Training Loss: 0.5200968384742737, Validation Loss: 0.19272495806217194\n",
      "Epoch 21/100, Training Loss: 0.4892587959766388, Validation Loss: 0.17694808542728424\n",
      "Epoch 22/100, Training Loss: 0.4673534035682678, Validation Loss: 0.1625887006521225\n",
      "Epoch 23/100, Training Loss: 0.44717109203338623, Validation Loss: 0.14927321672439575\n",
      "Epoch 24/100, Training Loss: 0.4264560639858246, Validation Loss: 0.1369999796152115\n",
      "Epoch 25/100, Training Loss: 0.4040023684501648, Validation Loss: 0.12581585347652435\n",
      "Epoch 26/100, Training Loss: 0.3926374912261963, Validation Loss: 0.11584631353616714\n",
      "Epoch 27/100, Training Loss: 0.3766191303730011, Validation Loss: 0.10707636177539825\n",
      "Epoch 28/100, Training Loss: 0.3633149266242981, Validation Loss: 0.09934697300195694\n",
      "Epoch 29/100, Training Loss: 0.3500475585460663, Validation Loss: 0.09250758588314056\n",
      "Epoch 30/100, Training Loss: 0.34302854537963867, Validation Loss: 0.08651302009820938\n",
      "Epoch 31/100, Training Loss: 0.33403506875038147, Validation Loss: 0.08146016299724579\n",
      "Epoch 32/100, Training Loss: 0.3232962489128113, Validation Loss: 0.07769060134887695\n",
      "Epoch 33/100, Training Loss: 0.3109379708766937, Validation Loss: 0.07430711388587952\n",
      "Epoch 34/100, Training Loss: 0.3110920786857605, Validation Loss: 0.07159803062677383\n",
      "Epoch 35/100, Training Loss: 0.2992062568664551, Validation Loss: 0.06955330073833466\n",
      "Epoch 36/100, Training Loss: 0.29326483607292175, Validation Loss: 0.06781773269176483\n",
      "Epoch 37/100, Training Loss: 0.28414881229400635, Validation Loss: 0.06644942611455917\n",
      "Epoch 38/100, Training Loss: 0.2822655737400055, Validation Loss: 0.06514937430620193\n",
      "Epoch 39/100, Training Loss: 0.27879559993743896, Validation Loss: 0.06376209855079651\n",
      "Epoch 40/100, Training Loss: 0.27466022968292236, Validation Loss: 0.062472280114889145\n",
      "Epoch 41/100, Training Loss: 0.2651161551475525, Validation Loss: 0.06135721504688263\n",
      "Epoch 42/100, Training Loss: 0.26250940561294556, Validation Loss: 0.06021325662732124\n",
      "Epoch 43/100, Training Loss: 0.25688624382019043, Validation Loss: 0.059088315814733505\n",
      "Epoch 44/100, Training Loss: 0.251979798078537, Validation Loss: 0.05811993405222893\n",
      "Epoch 45/100, Training Loss: 0.2486998587846756, Validation Loss: 0.05725497752428055\n",
      "Epoch 46/100, Training Loss: 0.24492095410823822, Validation Loss: 0.05642930045723915\n",
      "Epoch 47/100, Training Loss: 0.2415776550769806, Validation Loss: 0.05579704791307449\n",
      "Epoch 48/100, Training Loss: 0.2399042397737503, Validation Loss: 0.05530015379190445\n",
      "Epoch 49/100, Training Loss: 0.2342681735754013, Validation Loss: 0.0548718124628067\n",
      "Epoch 50/100, Training Loss: 0.22960244119167328, Validation Loss: 0.05461626127362251\n",
      "Epoch 51/100, Training Loss: 0.22814984619617462, Validation Loss: 0.05429597198963165\n",
      "Epoch 52/100, Training Loss: 0.22687497735023499, Validation Loss: 0.054107822477817535\n",
      "Epoch 53/100, Training Loss: 0.2229408472776413, Validation Loss: 0.053821977227926254\n",
      "Epoch 54/100, Training Loss: 0.22163914144039154, Validation Loss: 0.05349922180175781\n",
      "Epoch 55/100, Training Loss: 0.22058632969856262, Validation Loss: 0.05313487350940704\n",
      "Epoch 56/100, Training Loss: 0.21804217994213104, Validation Loss: 0.0528603158891201\n",
      "Epoch 57/100, Training Loss: 0.21554850041866302, Validation Loss: 0.0524931475520134\n",
      "Epoch 58/100, Training Loss: 0.2153901308774948, Validation Loss: 0.05200108885765076\n",
      "Epoch 59/100, Training Loss: 0.21108153462409973, Validation Loss: 0.05161096528172493\n",
      "Epoch 60/100, Training Loss: 0.20999905467033386, Validation Loss: 0.05121868848800659\n",
      "Epoch 61/100, Training Loss: 0.20990793406963348, Validation Loss: 0.050849370658397675\n",
      "Epoch 62/100, Training Loss: 0.20593143999576569, Validation Loss: 0.05043907091021538\n",
      "Epoch 63/100, Training Loss: 0.20674337446689606, Validation Loss: 0.04998086765408516\n",
      "Epoch 64/100, Training Loss: 0.2071235030889511, Validation Loss: 0.04949885606765747\n",
      "Epoch 65/100, Training Loss: 0.2036958634853363, Validation Loss: 0.0491538904607296\n",
      "Epoch 66/100, Training Loss: 0.19950607419013977, Validation Loss: 0.048801690340042114\n",
      "Epoch 67/100, Training Loss: 0.19915536046028137, Validation Loss: 0.048535510897636414\n",
      "Epoch 68/100, Training Loss: 0.19813288748264313, Validation Loss: 0.048330556601285934\n",
      "Epoch 69/100, Training Loss: 0.1970963329076767, Validation Loss: 0.04812183603644371\n",
      "Epoch 70/100, Training Loss: 0.19451135396957397, Validation Loss: 0.047914016991853714\n",
      "Epoch 71/100, Training Loss: 0.19505304098129272, Validation Loss: 0.04773692414164543\n",
      "Epoch 72/100, Training Loss: 0.19749777019023895, Validation Loss: 0.0474761500954628\n",
      "Epoch 73/100, Training Loss: 0.1931772530078888, Validation Loss: 0.047363754361867905\n",
      "Epoch 74/100, Training Loss: 0.19145861268043518, Validation Loss: 0.04727881774306297\n",
      "Epoch 75/100, Training Loss: 0.1908593475818634, Validation Loss: 0.047188758850097656\n",
      "Epoch 76/100, Training Loss: 0.18998590111732483, Validation Loss: 0.04711615666747093\n",
      "Epoch 77/100, Training Loss: 0.19147463142871857, Validation Loss: 0.04703967645764351\n",
      "Epoch 78/100, Training Loss: 0.1871410608291626, Validation Loss: 0.047099143266677856\n",
      "Epoch 79/100, Training Loss: 0.1850445717573166, Validation Loss: 0.04714955762028694\n",
      "Epoch 80/100, Training Loss: 0.1872447431087494, Validation Loss: 0.047070588916540146\n",
      "Epoch 81/100, Training Loss: 0.18638958036899567, Validation Loss: 0.04701206833124161\n",
      "Epoch 82/100, Training Loss: 0.18515312671661377, Validation Loss: 0.046960435807704926\n",
      "Epoch 83/100, Training Loss: 0.1813230961561203, Validation Loss: 0.047020550817251205\n",
      "Epoch 84/100, Training Loss: 0.18320629000663757, Validation Loss: 0.046920277178287506\n",
      "Epoch 85/100, Training Loss: 0.1818476915359497, Validation Loss: 0.0468614399433136\n",
      "Epoch 86/100, Training Loss: 0.18219664692878723, Validation Loss: 0.04679859057068825\n",
      "Epoch 87/100, Training Loss: 0.18070629239082336, Validation Loss: 0.046777188777923584\n",
      "Epoch 88/100, Training Loss: 0.1791176199913025, Validation Loss: 0.046842318028211594\n",
      "Epoch 89/100, Training Loss: 0.17880289256572723, Validation Loss: 0.046805523335933685\n",
      "Epoch 90/100, Training Loss: 0.1782284379005432, Validation Loss: 0.04679249972105026\n",
      "Epoch 91/100, Training Loss: 0.1764639914035797, Validation Loss: 0.04675903171300888\n",
      "Epoch 92/100, Training Loss: 0.17630013823509216, Validation Loss: 0.04677779972553253\n",
      "Epoch 93/100, Training Loss: 0.17779608070850372, Validation Loss: 0.046741586178541183\n",
      "Epoch 94/100, Training Loss: 0.17456193268299103, Validation Loss: 0.046716850250959396\n",
      "Epoch 95/100, Training Loss: 0.1751675307750702, Validation Loss: 0.04670706018805504\n",
      "Epoch 96/100, Training Loss: 0.1734781712293625, Validation Loss: 0.04673788323998451\n",
      "Epoch 97/100, Training Loss: 0.17391295731067657, Validation Loss: 0.04683724790811539\n",
      "Epoch 98/100, Training Loss: 0.1735704243183136, Validation Loss: 0.0470152348279953\n",
      "Epoch 99/100, Training Loss: 0.17410720884799957, Validation Loss: 0.047211840748786926\n",
      "Epoch 100/100, Training Loss: 0.17288213968276978, Validation Loss: 0.04755465313792229\n",
      "Fold 3 - R² Score: 0.9520, MAE: 0.1462\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 3.4375569820404053, Validation Loss: 0.9474522471427917\n",
      "Epoch 2/100, Training Loss: 2.7807300090789795, Validation Loss: 0.8353245854377747\n",
      "Epoch 3/100, Training Loss: 2.230971336364746, Validation Loss: 0.7389883995056152\n",
      "Epoch 4/100, Training Loss: 1.846590518951416, Validation Loss: 0.6634182929992676\n",
      "Epoch 5/100, Training Loss: 1.546631097793579, Validation Loss: 0.6056238412857056\n",
      "Epoch 6/100, Training Loss: 1.33087956905365, Validation Loss: 0.5568636059761047\n",
      "Epoch 7/100, Training Loss: 1.1951637268066406, Validation Loss: 0.5147993564605713\n",
      "Epoch 8/100, Training Loss: 1.078264832496643, Validation Loss: 0.47331979870796204\n",
      "Epoch 9/100, Training Loss: 0.9907217025756836, Validation Loss: 0.4329822361469269\n",
      "Epoch 10/100, Training Loss: 0.9022358059883118, Validation Loss: 0.3928254544734955\n",
      "Epoch 11/100, Training Loss: 0.8347923755645752, Validation Loss: 0.3541617691516876\n",
      "Epoch 12/100, Training Loss: 0.7796746492385864, Validation Loss: 0.31774795055389404\n",
      "Epoch 13/100, Training Loss: 0.7248949408531189, Validation Loss: 0.2845020592212677\n",
      "Epoch 14/100, Training Loss: 0.6736218333244324, Validation Loss: 0.2542782127857208\n",
      "Epoch 15/100, Training Loss: 0.6443982124328613, Validation Loss: 0.2274724692106247\n",
      "Epoch 16/100, Training Loss: 0.5958600640296936, Validation Loss: 0.20419400930404663\n",
      "Epoch 17/100, Training Loss: 0.5560786128044128, Validation Loss: 0.18503065407276154\n",
      "Epoch 18/100, Training Loss: 0.5252198576927185, Validation Loss: 0.16902174055576324\n",
      "Epoch 19/100, Training Loss: 0.5018750429153442, Validation Loss: 0.1557159721851349\n",
      "Epoch 20/100, Training Loss: 0.48062559962272644, Validation Loss: 0.1447601616382599\n",
      "Epoch 21/100, Training Loss: 0.4539608359336853, Validation Loss: 0.13591368496418\n",
      "Epoch 22/100, Training Loss: 0.43830132484436035, Validation Loss: 0.1287299543619156\n",
      "Epoch 23/100, Training Loss: 0.42076319456100464, Validation Loss: 0.1227462887763977\n",
      "Epoch 24/100, Training Loss: 0.4015860855579376, Validation Loss: 0.1178489625453949\n",
      "Epoch 25/100, Training Loss: 0.3856569528579712, Validation Loss: 0.11346913874149323\n",
      "Epoch 26/100, Training Loss: 0.3734488785266876, Validation Loss: 0.10942879319190979\n",
      "Epoch 27/100, Training Loss: 0.3620114028453827, Validation Loss: 0.10554930567741394\n",
      "Epoch 28/100, Training Loss: 0.3480161130428314, Validation Loss: 0.10167794674634933\n",
      "Epoch 29/100, Training Loss: 0.3441908359527588, Validation Loss: 0.09760541468858719\n",
      "Epoch 30/100, Training Loss: 0.33209165930747986, Validation Loss: 0.093538299202919\n",
      "Epoch 31/100, Training Loss: 0.3231388330459595, Validation Loss: 0.08941425383090973\n",
      "Epoch 32/100, Training Loss: 0.31683680415153503, Validation Loss: 0.08521196991205215\n",
      "Epoch 33/100, Training Loss: 0.3079635798931122, Validation Loss: 0.0811421275138855\n",
      "Epoch 34/100, Training Loss: 0.3031090795993805, Validation Loss: 0.07715298235416412\n",
      "Epoch 35/100, Training Loss: 0.29516154527664185, Validation Loss: 0.07335541397333145\n",
      "Epoch 36/100, Training Loss: 0.2874048948287964, Validation Loss: 0.06954041123390198\n",
      "Epoch 37/100, Training Loss: 0.2809102237224579, Validation Loss: 0.06603271514177322\n",
      "Epoch 38/100, Training Loss: 0.2717318832874298, Validation Loss: 0.06282161176204681\n",
      "Epoch 39/100, Training Loss: 0.2683033049106598, Validation Loss: 0.059791579842567444\n",
      "Epoch 40/100, Training Loss: 0.2668471932411194, Validation Loss: 0.056978028267621994\n",
      "Epoch 41/100, Training Loss: 0.25888413190841675, Validation Loss: 0.05438057705760002\n",
      "Epoch 42/100, Training Loss: 0.2552393972873688, Validation Loss: 0.0521572008728981\n",
      "Epoch 43/100, Training Loss: 0.24984323978424072, Validation Loss: 0.05022398754954338\n",
      "Epoch 44/100, Training Loss: 0.2461518794298172, Validation Loss: 0.04864714667201042\n",
      "Epoch 45/100, Training Loss: 0.24177254736423492, Validation Loss: 0.047317471355199814\n",
      "Epoch 46/100, Training Loss: 0.24006952345371246, Validation Loss: 0.046319380402565\n",
      "Epoch 47/100, Training Loss: 0.23487654328346252, Validation Loss: 0.04560019448399544\n",
      "Epoch 48/100, Training Loss: 0.2316145896911621, Validation Loss: 0.04505195841193199\n",
      "Epoch 49/100, Training Loss: 0.23066328465938568, Validation Loss: 0.044687461107969284\n",
      "Epoch 50/100, Training Loss: 0.2263248711824417, Validation Loss: 0.04450822249054909\n",
      "Epoch 51/100, Training Loss: 0.22483064234256744, Validation Loss: 0.04448982700705528\n",
      "Epoch 52/100, Training Loss: 0.22166934609413147, Validation Loss: 0.04461729899048805\n",
      "Epoch 53/100, Training Loss: 0.21820217370986938, Validation Loss: 0.04485763981938362\n",
      "Epoch 54/100, Training Loss: 0.2180870920419693, Validation Loss: 0.04512695595622063\n",
      "Epoch 55/100, Training Loss: 0.21498163044452667, Validation Loss: 0.04543877765536308\n",
      "Epoch 56/100, Training Loss: 0.21514520049095154, Validation Loss: 0.04576418921351433\n",
      "Epoch 57/100, Training Loss: 0.21059629321098328, Validation Loss: 0.04611092433333397\n",
      "Epoch 58/100, Training Loss: 0.20935958623886108, Validation Loss: 0.04637516289949417\n",
      "Epoch 59/100, Training Loss: 0.2070716917514801, Validation Loss: 0.04658856987953186\n",
      "Epoch 60/100, Training Loss: 0.20519454777240753, Validation Loss: 0.046730753034353256\n",
      "Epoch 61/100, Training Loss: 0.2015703022480011, Validation Loss: 0.046785108745098114\n",
      "Early stopping triggered\n",
      "Fold 4 - R² Score: 0.9533, MAE: 0.1471\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 1.8610782623291016, Validation Loss: 0.9255923628807068\n",
      "Epoch 2/100, Training Loss: 1.464562177658081, Validation Loss: 0.8451281189918518\n",
      "Epoch 3/100, Training Loss: 1.189413070678711, Validation Loss: 0.7599807381629944\n",
      "Epoch 4/100, Training Loss: 1.00454843044281, Validation Loss: 0.6750800609588623\n",
      "Epoch 5/100, Training Loss: 0.8901633024215698, Validation Loss: 0.5941234230995178\n",
      "Epoch 6/100, Training Loss: 0.8002063035964966, Validation Loss: 0.5210708975791931\n",
      "Epoch 7/100, Training Loss: 0.7158793210983276, Validation Loss: 0.45903825759887695\n",
      "Epoch 8/100, Training Loss: 0.6671128869056702, Validation Loss: 0.40835943818092346\n",
      "Epoch 9/100, Training Loss: 0.6092094779014587, Validation Loss: 0.36775732040405273\n",
      "Epoch 10/100, Training Loss: 0.5652149319648743, Validation Loss: 0.33469685912132263\n",
      "Epoch 11/100, Training Loss: 0.5233069062232971, Validation Loss: 0.30756810307502747\n",
      "Epoch 12/100, Training Loss: 0.48850077390670776, Validation Loss: 0.2841799855232239\n",
      "Epoch 13/100, Training Loss: 0.4573541283607483, Validation Loss: 0.2638944089412689\n",
      "Epoch 14/100, Training Loss: 0.42335546016693115, Validation Loss: 0.2462289035320282\n",
      "Epoch 15/100, Training Loss: 0.40021759271621704, Validation Loss: 0.23103533685207367\n",
      "Epoch 16/100, Training Loss: 0.37915509939193726, Validation Loss: 0.2177063524723053\n",
      "Epoch 17/100, Training Loss: 0.3614000976085663, Validation Loss: 0.20608770847320557\n",
      "Epoch 18/100, Training Loss: 0.35109323263168335, Validation Loss: 0.19528527557849884\n",
      "Epoch 19/100, Training Loss: 0.3348664343357086, Validation Loss: 0.18531103432178497\n",
      "Epoch 20/100, Training Loss: 0.3225891590118408, Validation Loss: 0.17568397521972656\n",
      "Epoch 21/100, Training Loss: 0.31369152665138245, Validation Loss: 0.1662638634443283\n",
      "Epoch 22/100, Training Loss: 0.30147483944892883, Validation Loss: 0.15721847116947174\n",
      "Epoch 23/100, Training Loss: 0.29309141635894775, Validation Loss: 0.14851497113704681\n",
      "Epoch 24/100, Training Loss: 0.28352734446525574, Validation Loss: 0.14010678231716156\n",
      "Epoch 25/100, Training Loss: 0.27557334303855896, Validation Loss: 0.13224156200885773\n",
      "Epoch 26/100, Training Loss: 0.26911985874176025, Validation Loss: 0.1248154565691948\n",
      "Epoch 27/100, Training Loss: 0.26026400923728943, Validation Loss: 0.11782602965831757\n",
      "Epoch 28/100, Training Loss: 0.2544594407081604, Validation Loss: 0.11140374839305878\n",
      "Epoch 29/100, Training Loss: 0.24791039526462555, Validation Loss: 0.1055966392159462\n",
      "Epoch 30/100, Training Loss: 0.24338842928409576, Validation Loss: 0.10030712187290192\n",
      "Epoch 31/100, Training Loss: 0.24046222865581512, Validation Loss: 0.09555234760046005\n",
      "Epoch 32/100, Training Loss: 0.23394745588302612, Validation Loss: 0.0913340300321579\n",
      "Epoch 33/100, Training Loss: 0.2301555573940277, Validation Loss: 0.08758851885795593\n",
      "Epoch 34/100, Training Loss: 0.22453118860721588, Validation Loss: 0.08426917344331741\n",
      "Epoch 35/100, Training Loss: 0.22200138866901398, Validation Loss: 0.08137688785791397\n",
      "Epoch 36/100, Training Loss: 0.2150731235742569, Validation Loss: 0.0787837952375412\n",
      "Epoch 37/100, Training Loss: 0.21382291615009308, Validation Loss: 0.07646174728870392\n",
      "Epoch 38/100, Training Loss: 0.20883680880069733, Validation Loss: 0.07452091574668884\n",
      "Epoch 39/100, Training Loss: 0.20636171102523804, Validation Loss: 0.07280376553535461\n",
      "Epoch 40/100, Training Loss: 0.20442511141300201, Validation Loss: 0.0712660625576973\n",
      "Epoch 41/100, Training Loss: 0.2030443698167801, Validation Loss: 0.06991912424564362\n",
      "Epoch 42/100, Training Loss: 0.19795642793178558, Validation Loss: 0.06863421201705933\n",
      "Epoch 43/100, Training Loss: 0.1992214322090149, Validation Loss: 0.0674699991941452\n",
      "Epoch 44/100, Training Loss: 0.1953105330467224, Validation Loss: 0.06634149700403214\n",
      "Epoch 45/100, Training Loss: 0.19336451590061188, Validation Loss: 0.06522764265537262\n",
      "Epoch 46/100, Training Loss: 0.19175302982330322, Validation Loss: 0.06413862854242325\n",
      "Epoch 47/100, Training Loss: 0.19094699621200562, Validation Loss: 0.0631023421883583\n",
      "Epoch 48/100, Training Loss: 0.18921679258346558, Validation Loss: 0.061966609209775925\n",
      "Epoch 49/100, Training Loss: 0.18658918142318726, Validation Loss: 0.060864150524139404\n",
      "Epoch 50/100, Training Loss: 0.18413177132606506, Validation Loss: 0.059781841933727264\n",
      "Epoch 51/100, Training Loss: 0.18228080868721008, Validation Loss: 0.058743491768836975\n",
      "Epoch 52/100, Training Loss: 0.18227867782115936, Validation Loss: 0.057744238525629044\n",
      "Epoch 53/100, Training Loss: 0.18119674921035767, Validation Loss: 0.05673865228891373\n",
      "Epoch 54/100, Training Loss: 0.1807941496372223, Validation Loss: 0.05584307014942169\n",
      "Epoch 55/100, Training Loss: 0.17827501893043518, Validation Loss: 0.05496569350361824\n",
      "Epoch 56/100, Training Loss: 0.17980915307998657, Validation Loss: 0.05411723628640175\n",
      "Epoch 57/100, Training Loss: 0.17605741322040558, Validation Loss: 0.05341145396232605\n",
      "Epoch 58/100, Training Loss: 0.17491081357002258, Validation Loss: 0.0527556836605072\n",
      "Epoch 59/100, Training Loss: 0.17588430643081665, Validation Loss: 0.05224071443080902\n",
      "Epoch 60/100, Training Loss: 0.17299321293830872, Validation Loss: 0.051840394735336304\n",
      "Epoch 61/100, Training Loss: 0.17503564059734344, Validation Loss: 0.05147353559732437\n",
      "Epoch 62/100, Training Loss: 0.1702529489994049, Validation Loss: 0.05119793117046356\n",
      "Epoch 63/100, Training Loss: 0.17177458107471466, Validation Loss: 0.050892751663923264\n",
      "Epoch 64/100, Training Loss: 0.17223238945007324, Validation Loss: 0.05055924877524376\n",
      "Epoch 65/100, Training Loss: 0.17025326192378998, Validation Loss: 0.05018152669072151\n",
      "Epoch 66/100, Training Loss: 0.17060813307762146, Validation Loss: 0.04986582696437836\n",
      "Epoch 67/100, Training Loss: 0.1695488691329956, Validation Loss: 0.04955533146858215\n",
      "Epoch 68/100, Training Loss: 0.16848330199718475, Validation Loss: 0.049240633845329285\n",
      "Epoch 69/100, Training Loss: 0.16713008284568787, Validation Loss: 0.04886539280414581\n",
      "Epoch 70/100, Training Loss: 0.16758601367473602, Validation Loss: 0.04849874973297119\n",
      "Epoch 71/100, Training Loss: 0.1660405993461609, Validation Loss: 0.048161301761865616\n",
      "Epoch 72/100, Training Loss: 0.16466683149337769, Validation Loss: 0.04779740422964096\n",
      "Epoch 73/100, Training Loss: 0.16654852032661438, Validation Loss: 0.04734162241220474\n",
      "Epoch 74/100, Training Loss: 0.16289235651493073, Validation Loss: 0.046950675547122955\n",
      "Epoch 75/100, Training Loss: 0.16295966506004333, Validation Loss: 0.046599626541137695\n",
      "Epoch 76/100, Training Loss: 0.16281941533088684, Validation Loss: 0.04620075598359108\n",
      "Epoch 77/100, Training Loss: 0.16299550235271454, Validation Loss: 0.04586467891931534\n",
      "Epoch 78/100, Training Loss: 0.16226321458816528, Validation Loss: 0.04561251029372215\n",
      "Epoch 79/100, Training Loss: 0.16270074248313904, Validation Loss: 0.04531824588775635\n",
      "Epoch 80/100, Training Loss: 0.16035395860671997, Validation Loss: 0.045074403285980225\n",
      "Epoch 81/100, Training Loss: 0.16147059202194214, Validation Loss: 0.04486808925867081\n",
      "Epoch 82/100, Training Loss: 0.16291441023349762, Validation Loss: 0.044713154435157776\n",
      "Epoch 83/100, Training Loss: 0.15780769288539886, Validation Loss: 0.04460480064153671\n",
      "Epoch 84/100, Training Loss: 0.159992054104805, Validation Loss: 0.044516853988170624\n",
      "Epoch 85/100, Training Loss: 0.16075344383716583, Validation Loss: 0.044473882764577866\n",
      "Epoch 86/100, Training Loss: 0.15987806022167206, Validation Loss: 0.044447872787714005\n",
      "Epoch 87/100, Training Loss: 0.15817366540431976, Validation Loss: 0.04446602985262871\n",
      "Epoch 88/100, Training Loss: 0.15936046838760376, Validation Loss: 0.04440031573176384\n",
      "Epoch 89/100, Training Loss: 0.15717145800590515, Validation Loss: 0.0444093756377697\n",
      "Epoch 90/100, Training Loss: 0.1572118103504181, Validation Loss: 0.04437237232923508\n",
      "Epoch 91/100, Training Loss: 0.15629272162914276, Validation Loss: 0.0444028340280056\n",
      "Epoch 92/100, Training Loss: 0.15791501104831696, Validation Loss: 0.044266749173402786\n",
      "Epoch 93/100, Training Loss: 0.15777680277824402, Validation Loss: 0.04413248971104622\n",
      "Epoch 94/100, Training Loss: 0.15565858781337738, Validation Loss: 0.044029295444488525\n",
      "Epoch 95/100, Training Loss: 0.1571449488401413, Validation Loss: 0.043938398361206055\n",
      "Epoch 96/100, Training Loss: 0.15638576447963715, Validation Loss: 0.04378419741988182\n",
      "Epoch 97/100, Training Loss: 0.15536731481552124, Validation Loss: 0.04365641251206398\n",
      "Epoch 98/100, Training Loss: 0.15648002922534943, Validation Loss: 0.04345253109931946\n",
      "Epoch 99/100, Training Loss: 0.15326888859272003, Validation Loss: 0.04325445368885994\n",
      "Epoch 100/100, Training Loss: 0.15230831503868103, Validation Loss: 0.04303499683737755\n",
      "Fold 5 - R² Score: 0.9570, MAE: 0.1235\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.0001}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.577425718307495, Validation Loss: 1.0207780599594116\n",
      "Epoch 2/100, Training Loss: 3.5721683502197266, Validation Loss: 1.0181217193603516\n",
      "Epoch 3/100, Training Loss: 3.5550246238708496, Validation Loss: 1.018197774887085\n",
      "Epoch 4/100, Training Loss: 3.5325942039489746, Validation Loss: 1.0201451778411865\n",
      "Epoch 5/100, Training Loss: 3.51414155960083, Validation Loss: 1.0233657360076904\n",
      "Epoch 6/100, Training Loss: 3.5063090324401855, Validation Loss: 1.0275986194610596\n",
      "Epoch 7/100, Training Loss: 3.449122190475464, Validation Loss: 1.0327861309051514\n",
      "Epoch 8/100, Training Loss: 3.4792730808258057, Validation Loss: 1.0387076139450073\n",
      "Epoch 9/100, Training Loss: 3.421475887298584, Validation Loss: 1.045133113861084\n",
      "Epoch 10/100, Training Loss: 3.423524856567383, Validation Loss: 1.0517985820770264\n",
      "Epoch 11/100, Training Loss: 3.41497540473938, Validation Loss: 1.0587732791900635\n",
      "Epoch 12/100, Training Loss: 3.3939945697784424, Validation Loss: 1.0657248497009277\n",
      "Early stopping triggered\n",
      "Fold 1 - R² Score: -0.0673, MAE: 0.8045\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 3.746617317199707, Validation Loss: 1.0654619932174683\n",
      "Epoch 2/100, Training Loss: 3.7192013263702393, Validation Loss: 1.0615595579147339\n",
      "Epoch 3/100, Training Loss: 3.681144952774048, Validation Loss: 1.0647178888320923\n",
      "Epoch 4/100, Training Loss: 3.663706064224243, Validation Loss: 1.073108196258545\n",
      "Epoch 5/100, Training Loss: 3.6747920513153076, Validation Loss: 1.0857983827590942\n",
      "Epoch 6/100, Training Loss: 3.5885775089263916, Validation Loss: 1.1017206907272339\n",
      "Epoch 7/100, Training Loss: 3.5973541736602783, Validation Loss: 1.1198465824127197\n",
      "Epoch 8/100, Training Loss: 3.581637144088745, Validation Loss: 1.1397533416748047\n",
      "Epoch 9/100, Training Loss: 3.561141014099121, Validation Loss: 1.1606711149215698\n",
      "Epoch 10/100, Training Loss: 3.532907485961914, Validation Loss: 1.182309865951538\n",
      "Epoch 11/100, Training Loss: 3.518885612487793, Validation Loss: 1.204020619392395\n",
      "Epoch 12/100, Training Loss: 3.5208067893981934, Validation Loss: 1.2256786823272705\n",
      "Early stopping triggered\n",
      "Fold 2 - R² Score: -0.2206, MAE: 0.8296\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 3.354771137237549, Validation Loss: 1.0486167669296265\n",
      "Epoch 2/100, Training Loss: 3.3490116596221924, Validation Loss: 1.0402947664260864\n",
      "Epoch 3/100, Training Loss: 3.323951482772827, Validation Loss: 1.0364089012145996\n",
      "Epoch 4/100, Training Loss: 3.311875104904175, Validation Loss: 1.0355286598205566\n",
      "Epoch 5/100, Training Loss: 3.2911624908447266, Validation Loss: 1.0365217924118042\n",
      "Epoch 6/100, Training Loss: 3.265369176864624, Validation Loss: 1.0385775566101074\n",
      "Epoch 7/100, Training Loss: 3.2499051094055176, Validation Loss: 1.041275143623352\n",
      "Epoch 8/100, Training Loss: 3.2278730869293213, Validation Loss: 1.0438615083694458\n",
      "Epoch 9/100, Training Loss: 3.2288615703582764, Validation Loss: 1.046319603919983\n",
      "Epoch 10/100, Training Loss: 3.2289657592773438, Validation Loss: 1.0482761859893799\n",
      "Epoch 11/100, Training Loss: 3.2103404998779297, Validation Loss: 1.0495795011520386\n",
      "Epoch 12/100, Training Loss: 3.1958067417144775, Validation Loss: 1.0504215955734253\n",
      "Epoch 13/100, Training Loss: 3.173522472381592, Validation Loss: 1.0505245923995972\n",
      "Epoch 14/100, Training Loss: 3.145357131958008, Validation Loss: 1.0499731302261353\n",
      "Early stopping triggered\n",
      "Fold 3 - R² Score: -0.0586, MAE: 0.7930\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 3.1130728721618652, Validation Loss: 0.9079868197441101\n",
      "Epoch 2/100, Training Loss: 3.0967581272125244, Validation Loss: 0.8992971181869507\n",
      "Epoch 3/100, Training Loss: 3.0817930698394775, Validation Loss: 0.9113873839378357\n",
      "Epoch 4/100, Training Loss: 3.0797057151794434, Validation Loss: 0.9396606087684631\n",
      "Epoch 5/100, Training Loss: 3.041409730911255, Validation Loss: 0.9802259206771851\n",
      "Epoch 6/100, Training Loss: 3.0247344970703125, Validation Loss: 1.0295214653015137\n",
      "Epoch 7/100, Training Loss: 3.005361318588257, Validation Loss: 1.0843313932418823\n",
      "Epoch 8/100, Training Loss: 2.9985857009887695, Validation Loss: 1.1420481204986572\n",
      "Epoch 9/100, Training Loss: 2.9640395641326904, Validation Loss: 1.2003625631332397\n",
      "Epoch 10/100, Training Loss: 2.991915702819824, Validation Loss: 1.2576335668563843\n",
      "Epoch 11/100, Training Loss: 2.9375171661376953, Validation Loss: 1.3120239973068237\n",
      "Epoch 12/100, Training Loss: 2.9284017086029053, Validation Loss: 1.3626290559768677\n",
      "Early stopping triggered\n",
      "Fold 4 - R² Score: -0.3570, MAE: 0.9182\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 5.234256267547607, Validation Loss: 1.4458426237106323\n",
      "Epoch 2/100, Training Loss: 5.267195224761963, Validation Loss: 1.4557408094406128\n",
      "Epoch 3/100, Training Loss: 5.255860805511475, Validation Loss: 1.4704442024230957\n",
      "Epoch 4/100, Training Loss: 5.151584148406982, Validation Loss: 1.48955500125885\n",
      "Epoch 5/100, Training Loss: 5.124344348907471, Validation Loss: 1.512099266052246\n",
      "Epoch 6/100, Training Loss: 5.120406150817871, Validation Loss: 1.5380007028579712\n",
      "Epoch 7/100, Training Loss: 5.1141276359558105, Validation Loss: 1.5666080713272095\n",
      "Epoch 8/100, Training Loss: 5.098060607910156, Validation Loss: 1.597272515296936\n",
      "Epoch 9/100, Training Loss: 5.045868396759033, Validation Loss: 1.6306473016738892\n",
      "Epoch 10/100, Training Loss: 5.021462440490723, Validation Loss: 1.6657001972198486\n",
      "Epoch 11/100, Training Loss: 4.994818687438965, Validation Loss: 1.7020498514175415\n",
      "Early stopping triggered\n",
      "Fold 5 - R² Score: -0.7019, MAE: 0.9517\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.001}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.92596173286438, Validation Loss: 1.1554689407348633\n",
      "Epoch 2/100, Training Loss: 3.712475538253784, Validation Loss: 1.133387804031372\n",
      "Epoch 3/100, Training Loss: 3.5361366271972656, Validation Loss: 1.1100462675094604\n",
      "Epoch 4/100, Training Loss: 3.3278255462646484, Validation Loss: 1.0844258069992065\n",
      "Epoch 5/100, Training Loss: 3.1694931983947754, Validation Loss: 1.0562704801559448\n",
      "Epoch 6/100, Training Loss: 3.033114194869995, Validation Loss: 1.0249303579330444\n",
      "Epoch 7/100, Training Loss: 2.888472557067871, Validation Loss: 0.9905054569244385\n",
      "Epoch 8/100, Training Loss: 2.7381746768951416, Validation Loss: 0.9531763792037964\n",
      "Epoch 9/100, Training Loss: 2.6188061237335205, Validation Loss: 0.9127679467201233\n",
      "Epoch 10/100, Training Loss: 2.508814811706543, Validation Loss: 0.8699493408203125\n",
      "Epoch 11/100, Training Loss: 2.4299209117889404, Validation Loss: 0.8253872990608215\n",
      "Epoch 12/100, Training Loss: 2.3519115447998047, Validation Loss: 0.7799193859100342\n",
      "Epoch 13/100, Training Loss: 2.2635743618011475, Validation Loss: 0.7340843081474304\n",
      "Epoch 14/100, Training Loss: 2.1693177223205566, Validation Loss: 0.6887339353561401\n",
      "Epoch 15/100, Training Loss: 2.0961430072784424, Validation Loss: 0.6440904140472412\n",
      "Epoch 16/100, Training Loss: 2.0547661781311035, Validation Loss: 0.6007513999938965\n",
      "Epoch 17/100, Training Loss: 2.003195285797119, Validation Loss: 0.5591316819190979\n",
      "Epoch 18/100, Training Loss: 1.9248155355453491, Validation Loss: 0.5196947455406189\n",
      "Epoch 19/100, Training Loss: 1.897449254989624, Validation Loss: 0.48228052258491516\n",
      "Epoch 20/100, Training Loss: 1.848172903060913, Validation Loss: 0.4471612274646759\n",
      "Epoch 21/100, Training Loss: 1.8295563459396362, Validation Loss: 0.41476723551750183\n",
      "Epoch 22/100, Training Loss: 1.7712892293930054, Validation Loss: 0.38496243953704834\n",
      "Epoch 23/100, Training Loss: 1.736469030380249, Validation Loss: 0.35774847865104675\n",
      "Epoch 24/100, Training Loss: 1.7093243598937988, Validation Loss: 0.33320310711860657\n",
      "Epoch 25/100, Training Loss: 1.6731470823287964, Validation Loss: 0.3112039566040039\n",
      "Epoch 26/100, Training Loss: 1.650148868560791, Validation Loss: 0.2913278341293335\n",
      "Epoch 27/100, Training Loss: 1.6244113445281982, Validation Loss: 0.2736930549144745\n",
      "Epoch 28/100, Training Loss: 1.5794085264205933, Validation Loss: 0.25782066583633423\n",
      "Epoch 29/100, Training Loss: 1.5708516836166382, Validation Loss: 0.24359183013439178\n",
      "Epoch 30/100, Training Loss: 1.5382330417633057, Validation Loss: 0.23089087009429932\n",
      "Epoch 31/100, Training Loss: 1.501201868057251, Validation Loss: 0.21947818994522095\n",
      "Epoch 32/100, Training Loss: 1.4811991453170776, Validation Loss: 0.20908761024475098\n",
      "Epoch 33/100, Training Loss: 1.4762693643569946, Validation Loss: 0.19970327615737915\n",
      "Epoch 34/100, Training Loss: 1.4260579347610474, Validation Loss: 0.19132426381111145\n",
      "Epoch 35/100, Training Loss: 1.4191511869430542, Validation Loss: 0.1835291087627411\n",
      "Epoch 36/100, Training Loss: 1.3873294591903687, Validation Loss: 0.1764858514070511\n",
      "Epoch 37/100, Training Loss: 1.3694452047348022, Validation Loss: 0.17004038393497467\n",
      "Epoch 38/100, Training Loss: 1.358846664428711, Validation Loss: 0.16419540345668793\n",
      "Epoch 39/100, Training Loss: 1.334075689315796, Validation Loss: 0.15865908563137054\n",
      "Epoch 40/100, Training Loss: 1.3178646564483643, Validation Loss: 0.15360765159130096\n",
      "Epoch 41/100, Training Loss: 1.2936606407165527, Validation Loss: 0.1488787680864334\n",
      "Epoch 42/100, Training Loss: 1.2822622060775757, Validation Loss: 0.14434696733951569\n",
      "Epoch 43/100, Training Loss: 1.244904637336731, Validation Loss: 0.14017555117607117\n",
      "Epoch 44/100, Training Loss: 1.2527194023132324, Validation Loss: 0.13614732027053833\n",
      "Epoch 45/100, Training Loss: 1.2279131412506104, Validation Loss: 0.13240624964237213\n",
      "Epoch 46/100, Training Loss: 1.2073731422424316, Validation Loss: 0.12882542610168457\n",
      "Epoch 47/100, Training Loss: 1.1813846826553345, Validation Loss: 0.12532076239585876\n",
      "Epoch 48/100, Training Loss: 1.1766340732574463, Validation Loss: 0.12212088704109192\n",
      "Epoch 49/100, Training Loss: 1.1606875658035278, Validation Loss: 0.1188901960849762\n",
      "Epoch 50/100, Training Loss: 1.1509720087051392, Validation Loss: 0.11576911807060242\n",
      "Epoch 51/100, Training Loss: 1.1311957836151123, Validation Loss: 0.11284735053777695\n",
      "Epoch 52/100, Training Loss: 1.1196377277374268, Validation Loss: 0.11000721156597137\n",
      "Epoch 53/100, Training Loss: 1.1007479429244995, Validation Loss: 0.10727817565202713\n",
      "Epoch 54/100, Training Loss: 1.102623701095581, Validation Loss: 0.10460422188043594\n",
      "Epoch 55/100, Training Loss: 1.082182765007019, Validation Loss: 0.10195335000753403\n",
      "Epoch 56/100, Training Loss: 1.0746990442276, Validation Loss: 0.0994500145316124\n",
      "Epoch 57/100, Training Loss: 1.0529698133468628, Validation Loss: 0.09700489044189453\n",
      "Epoch 58/100, Training Loss: 1.0356582403182983, Validation Loss: 0.09468493610620499\n",
      "Epoch 59/100, Training Loss: 1.0419385433197021, Validation Loss: 0.09257915616035461\n",
      "Epoch 60/100, Training Loss: 1.011012315750122, Validation Loss: 0.0904577299952507\n",
      "Epoch 61/100, Training Loss: 0.99867182970047, Validation Loss: 0.08837670087814331\n",
      "Epoch 62/100, Training Loss: 0.9983496069908142, Validation Loss: 0.08625198155641556\n",
      "Epoch 63/100, Training Loss: 0.9843159317970276, Validation Loss: 0.08422058820724487\n",
      "Epoch 64/100, Training Loss: 0.9779096245765686, Validation Loss: 0.08231689780950546\n",
      "Epoch 65/100, Training Loss: 0.9666196703910828, Validation Loss: 0.08048608154058456\n",
      "Epoch 66/100, Training Loss: 0.958218514919281, Validation Loss: 0.07867996394634247\n",
      "Epoch 67/100, Training Loss: 0.9557303190231323, Validation Loss: 0.07687430828809738\n",
      "Epoch 68/100, Training Loss: 0.9400392770767212, Validation Loss: 0.07518351078033447\n",
      "Epoch 69/100, Training Loss: 0.9312915802001953, Validation Loss: 0.07355424761772156\n",
      "Epoch 70/100, Training Loss: 0.9230127930641174, Validation Loss: 0.07197527587413788\n",
      "Epoch 71/100, Training Loss: 0.9147374033927917, Validation Loss: 0.07045645266771317\n",
      "Epoch 72/100, Training Loss: 0.9002702832221985, Validation Loss: 0.06897012144327164\n",
      "Epoch 73/100, Training Loss: 0.8940489292144775, Validation Loss: 0.06757664680480957\n",
      "Epoch 74/100, Training Loss: 0.8881240487098694, Validation Loss: 0.06621715426445007\n",
      "Epoch 75/100, Training Loss: 0.8841190934181213, Validation Loss: 0.06481760740280151\n",
      "Epoch 76/100, Training Loss: 0.8716632723808289, Validation Loss: 0.06351649761199951\n",
      "Epoch 77/100, Training Loss: 0.8627014756202698, Validation Loss: 0.06222989782691002\n",
      "Epoch 78/100, Training Loss: 0.8588049411773682, Validation Loss: 0.06104357913136482\n",
      "Epoch 79/100, Training Loss: 0.8526086807250977, Validation Loss: 0.059882428497076035\n",
      "Epoch 80/100, Training Loss: 0.8380769491195679, Validation Loss: 0.058792054653167725\n",
      "Epoch 81/100, Training Loss: 0.8328238129615784, Validation Loss: 0.05770529806613922\n",
      "Epoch 82/100, Training Loss: 0.8261089324951172, Validation Loss: 0.05664476752281189\n",
      "Epoch 83/100, Training Loss: 0.8097362518310547, Validation Loss: 0.05569165199995041\n",
      "Epoch 84/100, Training Loss: 0.8066291809082031, Validation Loss: 0.05474545806646347\n",
      "Epoch 85/100, Training Loss: 0.8031058311462402, Validation Loss: 0.053800541907548904\n",
      "Epoch 86/100, Training Loss: 0.794434130191803, Validation Loss: 0.05289832130074501\n",
      "Epoch 87/100, Training Loss: 0.7857144474983215, Validation Loss: 0.05202687531709671\n",
      "Epoch 88/100, Training Loss: 0.7871212959289551, Validation Loss: 0.05119838938117027\n",
      "Epoch 89/100, Training Loss: 0.77236008644104, Validation Loss: 0.05036121606826782\n",
      "Epoch 90/100, Training Loss: 0.7664526700973511, Validation Loss: 0.04954364523291588\n",
      "Epoch 91/100, Training Loss: 0.7594568133354187, Validation Loss: 0.04882004112005234\n",
      "Epoch 92/100, Training Loss: 0.7548775672912598, Validation Loss: 0.04809831827878952\n",
      "Epoch 93/100, Training Loss: 0.7511168122291565, Validation Loss: 0.04744253680109978\n",
      "Epoch 94/100, Training Loss: 0.7376103401184082, Validation Loss: 0.04676118865609169\n",
      "Epoch 95/100, Training Loss: 0.7359032034873962, Validation Loss: 0.046083319932222366\n",
      "Epoch 96/100, Training Loss: 0.735718846321106, Validation Loss: 0.045399151742458344\n",
      "Epoch 97/100, Training Loss: 0.7349022030830383, Validation Loss: 0.04473915323615074\n",
      "Epoch 98/100, Training Loss: 0.7239978909492493, Validation Loss: 0.04411150515079498\n",
      "Epoch 99/100, Training Loss: 0.7165248990058899, Validation Loss: 0.04350363090634346\n",
      "Epoch 100/100, Training Loss: 0.703973114490509, Validation Loss: 0.04295036569237709\n",
      "Fold 1 - R² Score: 0.9570, MAE: 0.1426\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 3.6501171588897705, Validation Loss: 1.0722737312316895\n",
      "Epoch 2/100, Training Loss: 3.4998207092285156, Validation Loss: 1.0462636947631836\n",
      "Epoch 3/100, Training Loss: 3.3096671104431152, Validation Loss: 1.023171067237854\n",
      "Epoch 4/100, Training Loss: 3.1625781059265137, Validation Loss: 1.0012351274490356\n",
      "Epoch 5/100, Training Loss: 3.024367332458496, Validation Loss: 0.9791724681854248\n",
      "Epoch 6/100, Training Loss: 2.8440017700195312, Validation Loss: 0.9563101530075073\n",
      "Epoch 7/100, Training Loss: 2.7352566719055176, Validation Loss: 0.9323155283927917\n",
      "Epoch 8/100, Training Loss: 2.601076602935791, Validation Loss: 0.9072070717811584\n",
      "Epoch 9/100, Training Loss: 2.4851326942443848, Validation Loss: 0.880480170249939\n",
      "Epoch 10/100, Training Loss: 2.3718466758728027, Validation Loss: 0.8530934453010559\n",
      "Epoch 11/100, Training Loss: 2.2586092948913574, Validation Loss: 0.8246608972549438\n",
      "Epoch 12/100, Training Loss: 2.195875883102417, Validation Loss: 0.7955115437507629\n",
      "Epoch 13/100, Training Loss: 2.08699631690979, Validation Loss: 0.7659761309623718\n",
      "Epoch 14/100, Training Loss: 2.0286386013031006, Validation Loss: 0.7356292009353638\n",
      "Epoch 15/100, Training Loss: 1.9208317995071411, Validation Loss: 0.7051762342453003\n",
      "Epoch 16/100, Training Loss: 1.8688066005706787, Validation Loss: 0.6742189526557922\n",
      "Epoch 17/100, Training Loss: 1.8223118782043457, Validation Loss: 0.6433531045913696\n",
      "Epoch 18/100, Training Loss: 1.7587264776229858, Validation Loss: 0.6126468777656555\n",
      "Epoch 19/100, Training Loss: 1.7016128301620483, Validation Loss: 0.5821395516395569\n",
      "Epoch 20/100, Training Loss: 1.6362403631210327, Validation Loss: 0.5518056154251099\n",
      "Epoch 21/100, Training Loss: 1.601904273033142, Validation Loss: 0.5222305059432983\n",
      "Epoch 22/100, Training Loss: 1.5465338230133057, Validation Loss: 0.4930751621723175\n",
      "Epoch 23/100, Training Loss: 1.4994184970855713, Validation Loss: 0.4649582803249359\n",
      "Epoch 24/100, Training Loss: 1.4690357446670532, Validation Loss: 0.4377741515636444\n",
      "Epoch 25/100, Training Loss: 1.4388556480407715, Validation Loss: 0.4114968478679657\n",
      "Epoch 26/100, Training Loss: 1.393713355064392, Validation Loss: 0.3863535523414612\n",
      "Epoch 27/100, Training Loss: 1.3649934530258179, Validation Loss: 0.36239179968833923\n",
      "Epoch 28/100, Training Loss: 1.345080018043518, Validation Loss: 0.339595764875412\n",
      "Epoch 29/100, Training Loss: 1.3055731058120728, Validation Loss: 0.31810110807418823\n",
      "Epoch 30/100, Training Loss: 1.2766677141189575, Validation Loss: 0.2978768050670624\n",
      "Epoch 31/100, Training Loss: 1.2575552463531494, Validation Loss: 0.2789600193500519\n",
      "Epoch 32/100, Training Loss: 1.2249059677124023, Validation Loss: 0.2611185908317566\n",
      "Epoch 33/100, Training Loss: 1.2058546543121338, Validation Loss: 0.2445908784866333\n",
      "Epoch 34/100, Training Loss: 1.1870298385620117, Validation Loss: 0.22920779883861542\n",
      "Epoch 35/100, Training Loss: 1.1613636016845703, Validation Loss: 0.21500587463378906\n",
      "Epoch 36/100, Training Loss: 1.134930968284607, Validation Loss: 0.20188918709754944\n",
      "Epoch 37/100, Training Loss: 1.1085172891616821, Validation Loss: 0.1898484230041504\n",
      "Epoch 38/100, Training Loss: 1.111737847328186, Validation Loss: 0.17872583866119385\n",
      "Epoch 39/100, Training Loss: 1.0783116817474365, Validation Loss: 0.1683938056230545\n",
      "Epoch 40/100, Training Loss: 1.0676835775375366, Validation Loss: 0.15883006155490875\n",
      "Epoch 41/100, Training Loss: 1.0422389507293701, Validation Loss: 0.15012839436531067\n",
      "Epoch 42/100, Training Loss: 1.0195682048797607, Validation Loss: 0.14194074273109436\n",
      "Epoch 43/100, Training Loss: 1.0104947090148926, Validation Loss: 0.13449230790138245\n",
      "Epoch 44/100, Training Loss: 0.9911007881164551, Validation Loss: 0.1275632083415985\n",
      "Epoch 45/100, Training Loss: 0.9839903712272644, Validation Loss: 0.1210632175207138\n",
      "Epoch 46/100, Training Loss: 0.9605604410171509, Validation Loss: 0.11511161923408508\n",
      "Epoch 47/100, Training Loss: 0.9671316146850586, Validation Loss: 0.1095750480890274\n",
      "Epoch 48/100, Training Loss: 0.938324511051178, Validation Loss: 0.10443367063999176\n",
      "Epoch 49/100, Training Loss: 0.9446285963058472, Validation Loss: 0.09968838095664978\n",
      "Epoch 50/100, Training Loss: 0.9207404255867004, Validation Loss: 0.09519901871681213\n",
      "Epoch 51/100, Training Loss: 0.9167743921279907, Validation Loss: 0.09093622863292694\n",
      "Epoch 52/100, Training Loss: 0.9034476280212402, Validation Loss: 0.08686145395040512\n",
      "Epoch 53/100, Training Loss: 0.8937506675720215, Validation Loss: 0.08323847502470016\n",
      "Epoch 54/100, Training Loss: 0.8780919909477234, Validation Loss: 0.07974213361740112\n",
      "Epoch 55/100, Training Loss: 0.8750355243682861, Validation Loss: 0.07645469158887863\n",
      "Epoch 56/100, Training Loss: 0.8616695404052734, Validation Loss: 0.0734216570854187\n",
      "Epoch 57/100, Training Loss: 0.8468410968780518, Validation Loss: 0.07061225175857544\n",
      "Epoch 58/100, Training Loss: 0.8433417677879333, Validation Loss: 0.06797237694263458\n",
      "Epoch 59/100, Training Loss: 0.8334108591079712, Validation Loss: 0.06547298282384872\n",
      "Epoch 60/100, Training Loss: 0.8238630890846252, Validation Loss: 0.06316628307104111\n",
      "Epoch 61/100, Training Loss: 0.8115912675857544, Validation Loss: 0.060940541326999664\n",
      "Epoch 62/100, Training Loss: 0.8097488284111023, Validation Loss: 0.05880904570221901\n",
      "Epoch 63/100, Training Loss: 0.8011366128921509, Validation Loss: 0.05686606839299202\n",
      "Epoch 64/100, Training Loss: 0.7927477359771729, Validation Loss: 0.0548972450196743\n",
      "Epoch 65/100, Training Loss: 0.7877001762390137, Validation Loss: 0.05311819911003113\n",
      "Epoch 66/100, Training Loss: 0.7823184132575989, Validation Loss: 0.05143866688013077\n",
      "Epoch 67/100, Training Loss: 0.7710325121879578, Validation Loss: 0.049955688416957855\n",
      "Epoch 68/100, Training Loss: 0.7679369449615479, Validation Loss: 0.04858061671257019\n",
      "Epoch 69/100, Training Loss: 0.7624469995498657, Validation Loss: 0.04730142280459404\n",
      "Epoch 70/100, Training Loss: 0.7500470280647278, Validation Loss: 0.046090949326753616\n",
      "Epoch 71/100, Training Loss: 0.7443445920944214, Validation Loss: 0.04498232901096344\n",
      "Epoch 72/100, Training Loss: 0.7423674464225769, Validation Loss: 0.04384125396609306\n",
      "Epoch 73/100, Training Loss: 0.7293520569801331, Validation Loss: 0.042823754251003265\n",
      "Epoch 74/100, Training Loss: 0.7251176238059998, Validation Loss: 0.04179266095161438\n",
      "Epoch 75/100, Training Loss: 0.7264588475227356, Validation Loss: 0.040815774351358414\n",
      "Epoch 76/100, Training Loss: 0.7154982089996338, Validation Loss: 0.039855968207120895\n",
      "Epoch 77/100, Training Loss: 0.7069498896598816, Validation Loss: 0.03896025940775871\n",
      "Epoch 78/100, Training Loss: 0.702189028263092, Validation Loss: 0.03814046457409859\n",
      "Epoch 79/100, Training Loss: 0.6906662583351135, Validation Loss: 0.037422943860292435\n",
      "Epoch 80/100, Training Loss: 0.6927832961082458, Validation Loss: 0.03672483190894127\n",
      "Epoch 81/100, Training Loss: 0.6826117634773254, Validation Loss: 0.03606550395488739\n",
      "Epoch 82/100, Training Loss: 0.681789219379425, Validation Loss: 0.03543254733085632\n",
      "Epoch 83/100, Training Loss: 0.6784958839416504, Validation Loss: 0.03480341657996178\n",
      "Epoch 84/100, Training Loss: 0.6755613684654236, Validation Loss: 0.03422535955905914\n",
      "Epoch 85/100, Training Loss: 0.6677401065826416, Validation Loss: 0.033671166747808456\n",
      "Epoch 86/100, Training Loss: 0.6649498343467712, Validation Loss: 0.03315276652574539\n",
      "Epoch 87/100, Training Loss: 0.6538492441177368, Validation Loss: 0.03264392539858818\n",
      "Epoch 88/100, Training Loss: 0.6536783576011658, Validation Loss: 0.03219733014702797\n",
      "Epoch 89/100, Training Loss: 0.6429547071456909, Validation Loss: 0.03176657855510712\n",
      "Epoch 90/100, Training Loss: 0.6446381211280823, Validation Loss: 0.03133930638432503\n",
      "Epoch 91/100, Training Loss: 0.6412042379379272, Validation Loss: 0.03096354380249977\n",
      "Epoch 92/100, Training Loss: 0.6366146206855774, Validation Loss: 0.030588163062930107\n",
      "Epoch 93/100, Training Loss: 0.6338220834732056, Validation Loss: 0.030252886936068535\n",
      "Epoch 94/100, Training Loss: 0.6317399740219116, Validation Loss: 0.029900727793574333\n",
      "Epoch 95/100, Training Loss: 0.6179653406143188, Validation Loss: 0.029536675661802292\n",
      "Epoch 96/100, Training Loss: 0.6156763434410095, Validation Loss: 0.029217449948191643\n",
      "Epoch 97/100, Training Loss: 0.6107960343360901, Validation Loss: 0.028910402208566666\n",
      "Epoch 98/100, Training Loss: 0.6137924194335938, Validation Loss: 0.02864319272339344\n",
      "Epoch 99/100, Training Loss: 0.6031106114387512, Validation Loss: 0.028389859944581985\n",
      "Epoch 100/100, Training Loss: 0.594674289226532, Validation Loss: 0.02814594656229019\n",
      "Fold 2 - R² Score: 0.9721, MAE: 0.1199\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 2.6364736557006836, Validation Loss: 0.8987382650375366\n",
      "Epoch 2/100, Training Loss: 2.5104477405548096, Validation Loss: 0.8766691088676453\n",
      "Epoch 3/100, Training Loss: 2.402867317199707, Validation Loss: 0.8587996363639832\n",
      "Epoch 4/100, Training Loss: 2.3051464557647705, Validation Loss: 0.8435898423194885\n",
      "Epoch 5/100, Training Loss: 2.1706979274749756, Validation Loss: 0.8293389081954956\n",
      "Epoch 6/100, Training Loss: 2.0820820331573486, Validation Loss: 0.8146869540214539\n",
      "Epoch 7/100, Training Loss: 2.0091207027435303, Validation Loss: 0.7990893125534058\n",
      "Epoch 8/100, Training Loss: 1.9427621364593506, Validation Loss: 0.7821117043495178\n",
      "Epoch 9/100, Training Loss: 1.850996732711792, Validation Loss: 0.7636321783065796\n",
      "Epoch 10/100, Training Loss: 1.760025143623352, Validation Loss: 0.7428836822509766\n",
      "Epoch 11/100, Training Loss: 1.6957515478134155, Validation Loss: 0.7196205854415894\n",
      "Epoch 12/100, Training Loss: 1.6459698677062988, Validation Loss: 0.6937219500541687\n",
      "Epoch 13/100, Training Loss: 1.590301513671875, Validation Loss: 0.6663858890533447\n",
      "Epoch 14/100, Training Loss: 1.552221417427063, Validation Loss: 0.6379945278167725\n",
      "Epoch 15/100, Training Loss: 1.4935436248779297, Validation Loss: 0.6087013483047485\n",
      "Epoch 16/100, Training Loss: 1.464967131614685, Validation Loss: 0.5796055197715759\n",
      "Epoch 17/100, Training Loss: 1.434443712234497, Validation Loss: 0.5506178736686707\n",
      "Epoch 18/100, Training Loss: 1.3876228332519531, Validation Loss: 0.5223637819290161\n",
      "Epoch 19/100, Training Loss: 1.3679687976837158, Validation Loss: 0.49465033411979675\n",
      "Epoch 20/100, Training Loss: 1.328623652458191, Validation Loss: 0.4675776958465576\n",
      "Epoch 21/100, Training Loss: 1.2963852882385254, Validation Loss: 0.4421064555644989\n",
      "Epoch 22/100, Training Loss: 1.2833704948425293, Validation Loss: 0.41794857382774353\n",
      "Epoch 23/100, Training Loss: 1.258307933807373, Validation Loss: 0.39477625489234924\n",
      "Epoch 24/100, Training Loss: 1.2281131744384766, Validation Loss: 0.37303417921066284\n",
      "Epoch 25/100, Training Loss: 1.2097227573394775, Validation Loss: 0.3525405824184418\n",
      "Epoch 26/100, Training Loss: 1.1803841590881348, Validation Loss: 0.33375638723373413\n",
      "Epoch 27/100, Training Loss: 1.166767954826355, Validation Loss: 0.3157322406768799\n",
      "Epoch 28/100, Training Loss: 1.1366065740585327, Validation Loss: 0.29910558462142944\n",
      "Epoch 29/100, Training Loss: 1.1291804313659668, Validation Loss: 0.2835932970046997\n",
      "Epoch 30/100, Training Loss: 1.0945767164230347, Validation Loss: 0.26905182003974915\n",
      "Epoch 31/100, Training Loss: 1.0835343599319458, Validation Loss: 0.2554599344730377\n",
      "Epoch 32/100, Training Loss: 1.0798548460006714, Validation Loss: 0.24263297021389008\n",
      "Epoch 33/100, Training Loss: 1.0498323440551758, Validation Loss: 0.23065832257270813\n",
      "Epoch 34/100, Training Loss: 1.0329208374023438, Validation Loss: 0.21927987039089203\n",
      "Epoch 35/100, Training Loss: 1.0154242515563965, Validation Loss: 0.20878314971923828\n",
      "Epoch 36/100, Training Loss: 0.9939193725585938, Validation Loss: 0.19897623360157013\n",
      "Epoch 37/100, Training Loss: 0.985025942325592, Validation Loss: 0.1896178424358368\n",
      "Epoch 38/100, Training Loss: 0.9625766277313232, Validation Loss: 0.18081921339035034\n",
      "Epoch 39/100, Training Loss: 0.9543532133102417, Validation Loss: 0.1725889891386032\n",
      "Epoch 40/100, Training Loss: 0.9278703331947327, Validation Loss: 0.16498267650604248\n",
      "Epoch 41/100, Training Loss: 0.928828239440918, Validation Loss: 0.15790708363056183\n",
      "Epoch 42/100, Training Loss: 0.9122179746627808, Validation Loss: 0.1510390043258667\n",
      "Epoch 43/100, Training Loss: 0.9073997139930725, Validation Loss: 0.14445897936820984\n",
      "Epoch 44/100, Training Loss: 0.8833531737327576, Validation Loss: 0.13824151456356049\n",
      "Epoch 45/100, Training Loss: 0.8776282668113708, Validation Loss: 0.13238918781280518\n",
      "Epoch 46/100, Training Loss: 0.8682975769042969, Validation Loss: 0.12681953608989716\n",
      "Epoch 47/100, Training Loss: 0.859677791595459, Validation Loss: 0.12165932357311249\n",
      "Epoch 48/100, Training Loss: 0.846153199672699, Validation Loss: 0.1169552430510521\n",
      "Epoch 49/100, Training Loss: 0.8331536650657654, Validation Loss: 0.11253931373357773\n",
      "Epoch 50/100, Training Loss: 0.8271551132202148, Validation Loss: 0.10856602340936661\n",
      "Epoch 51/100, Training Loss: 0.8159874677658081, Validation Loss: 0.10476850718259811\n",
      "Epoch 52/100, Training Loss: 0.8087204694747925, Validation Loss: 0.10125033557415009\n",
      "Epoch 53/100, Training Loss: 0.7956633567810059, Validation Loss: 0.09787530452013016\n",
      "Epoch 54/100, Training Loss: 0.788250744342804, Validation Loss: 0.09470761567354202\n",
      "Epoch 55/100, Training Loss: 0.7712904810905457, Validation Loss: 0.09180308878421783\n",
      "Epoch 56/100, Training Loss: 0.771169900894165, Validation Loss: 0.08898608386516571\n",
      "Epoch 57/100, Training Loss: 0.7594102025032043, Validation Loss: 0.08626895397901535\n",
      "Epoch 58/100, Training Loss: 0.7561216950416565, Validation Loss: 0.0837356299161911\n",
      "Epoch 59/100, Training Loss: 0.7456542253494263, Validation Loss: 0.0812494158744812\n",
      "Epoch 60/100, Training Loss: 0.7391942143440247, Validation Loss: 0.07901084423065186\n",
      "Epoch 61/100, Training Loss: 0.7384901642799377, Validation Loss: 0.07681820541620255\n",
      "Epoch 62/100, Training Loss: 0.7250219583511353, Validation Loss: 0.074787937104702\n",
      "Epoch 63/100, Training Loss: 0.7221069931983948, Validation Loss: 0.0728079155087471\n",
      "Epoch 64/100, Training Loss: 0.7065627574920654, Validation Loss: 0.07091938704252243\n",
      "Epoch 65/100, Training Loss: 0.7051414251327515, Validation Loss: 0.06910669803619385\n",
      "Epoch 66/100, Training Loss: 0.6974380016326904, Validation Loss: 0.06740642338991165\n",
      "Epoch 67/100, Training Loss: 0.6901389360427856, Validation Loss: 0.06582970917224884\n",
      "Epoch 68/100, Training Loss: 0.6862830519676208, Validation Loss: 0.06443468481302261\n",
      "Epoch 69/100, Training Loss: 0.675637423992157, Validation Loss: 0.06305146217346191\n",
      "Epoch 70/100, Training Loss: 0.6749783754348755, Validation Loss: 0.06175148859620094\n",
      "Epoch 71/100, Training Loss: 0.6683774590492249, Validation Loss: 0.06047786399722099\n",
      "Epoch 72/100, Training Loss: 0.6609019637107849, Validation Loss: 0.059230320155620575\n",
      "Epoch 73/100, Training Loss: 0.6547624468803406, Validation Loss: 0.05788391828536987\n",
      "Epoch 74/100, Training Loss: 0.6474001407623291, Validation Loss: 0.056717876344919205\n",
      "Epoch 75/100, Training Loss: 0.6403511166572571, Validation Loss: 0.05556083470582962\n",
      "Epoch 76/100, Training Loss: 0.6404014229774475, Validation Loss: 0.054506171494722366\n",
      "Epoch 77/100, Training Loss: 0.6321677565574646, Validation Loss: 0.05348905548453331\n",
      "Epoch 78/100, Training Loss: 0.622451663017273, Validation Loss: 0.05252334848046303\n",
      "Epoch 79/100, Training Loss: 0.6283931136131287, Validation Loss: 0.051661547273397446\n",
      "Epoch 80/100, Training Loss: 0.6142082810401917, Validation Loss: 0.050828929990530014\n",
      "Epoch 81/100, Training Loss: 0.6032907366752625, Validation Loss: 0.050046391785144806\n",
      "Epoch 82/100, Training Loss: 0.6030699610710144, Validation Loss: 0.049246177077293396\n",
      "Epoch 83/100, Training Loss: 0.6019891500473022, Validation Loss: 0.04844234138727188\n",
      "Epoch 84/100, Training Loss: 0.5971032381057739, Validation Loss: 0.04764115437865257\n",
      "Epoch 85/100, Training Loss: 0.59058678150177, Validation Loss: 0.04687902703881264\n",
      "Epoch 86/100, Training Loss: 0.5879328846931458, Validation Loss: 0.046126656234264374\n",
      "Epoch 87/100, Training Loss: 0.5832162499427795, Validation Loss: 0.0455087311565876\n",
      "Epoch 88/100, Training Loss: 0.5772702097892761, Validation Loss: 0.04487333819270134\n",
      "Epoch 89/100, Training Loss: 0.5717141032218933, Validation Loss: 0.0442473404109478\n",
      "Epoch 90/100, Training Loss: 0.5678461194038391, Validation Loss: 0.0436159148812294\n",
      "Epoch 91/100, Training Loss: 0.5643497109413147, Validation Loss: 0.04307236894965172\n",
      "Epoch 92/100, Training Loss: 0.5587390661239624, Validation Loss: 0.04257149621844292\n",
      "Epoch 93/100, Training Loss: 0.5527946352958679, Validation Loss: 0.042096126824617386\n",
      "Epoch 94/100, Training Loss: 0.5521248579025269, Validation Loss: 0.04154423996806145\n",
      "Epoch 95/100, Training Loss: 0.5471612811088562, Validation Loss: 0.041100744158029556\n",
      "Epoch 96/100, Training Loss: 0.5451220273971558, Validation Loss: 0.04061581939458847\n",
      "Epoch 97/100, Training Loss: 0.536130964756012, Validation Loss: 0.04014365375041962\n",
      "Epoch 98/100, Training Loss: 0.5349796414375305, Validation Loss: 0.039642997086048126\n",
      "Epoch 99/100, Training Loss: 0.5330535769462585, Validation Loss: 0.039127230644226074\n",
      "Epoch 100/100, Training Loss: 0.5288003087043762, Validation Loss: 0.038662560284137726\n",
      "Fold 3 - R² Score: 0.9610, MAE: 0.1345\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 2.9344162940979004, Validation Loss: 0.9831627011299133\n",
      "Epoch 2/100, Training Loss: 2.84269118309021, Validation Loss: 0.971117377281189\n",
      "Epoch 3/100, Training Loss: 2.673764944076538, Validation Loss: 0.9588137269020081\n",
      "Epoch 4/100, Training Loss: 2.568227767944336, Validation Loss: 0.9453945755958557\n",
      "Epoch 5/100, Training Loss: 2.4883203506469727, Validation Loss: 0.9305744767189026\n",
      "Epoch 6/100, Training Loss: 2.393193244934082, Validation Loss: 0.9142221808433533\n",
      "Epoch 7/100, Training Loss: 2.30548095703125, Validation Loss: 0.8963180780410767\n",
      "Epoch 8/100, Training Loss: 2.2196836471557617, Validation Loss: 0.8764604330062866\n",
      "Epoch 9/100, Training Loss: 2.1381959915161133, Validation Loss: 0.8548145294189453\n",
      "Epoch 10/100, Training Loss: 2.0735886096954346, Validation Loss: 0.8313403129577637\n",
      "Epoch 11/100, Training Loss: 2.0120606422424316, Validation Loss: 0.8067387938499451\n",
      "Epoch 12/100, Training Loss: 1.9457037448883057, Validation Loss: 0.7808454036712646\n",
      "Epoch 13/100, Training Loss: 1.887438178062439, Validation Loss: 0.7532978057861328\n",
      "Epoch 14/100, Training Loss: 1.811439871788025, Validation Loss: 0.7244325876235962\n",
      "Epoch 15/100, Training Loss: 1.7726211547851562, Validation Loss: 0.6945727467536926\n",
      "Epoch 16/100, Training Loss: 1.7290014028549194, Validation Loss: 0.6641004085540771\n",
      "Epoch 17/100, Training Loss: 1.7028926610946655, Validation Loss: 0.6337234973907471\n",
      "Epoch 18/100, Training Loss: 1.6468102931976318, Validation Loss: 0.6034632921218872\n",
      "Epoch 19/100, Training Loss: 1.6121536493301392, Validation Loss: 0.5738294124603271\n",
      "Epoch 20/100, Training Loss: 1.5583767890930176, Validation Loss: 0.5449820756912231\n",
      "Epoch 21/100, Training Loss: 1.5296913385391235, Validation Loss: 0.5166667699813843\n",
      "Epoch 22/100, Training Loss: 1.5045896768569946, Validation Loss: 0.4890486001968384\n",
      "Epoch 23/100, Training Loss: 1.4594998359680176, Validation Loss: 0.4622151255607605\n",
      "Epoch 24/100, Training Loss: 1.4503332376480103, Validation Loss: 0.4363226592540741\n",
      "Epoch 25/100, Training Loss: 1.4141494035720825, Validation Loss: 0.41118404269218445\n",
      "Epoch 26/100, Training Loss: 1.3904743194580078, Validation Loss: 0.3870300054550171\n",
      "Epoch 27/100, Training Loss: 1.3535568714141846, Validation Loss: 0.3639903962612152\n",
      "Epoch 28/100, Training Loss: 1.3343578577041626, Validation Loss: 0.34215620160102844\n",
      "Epoch 29/100, Training Loss: 1.3061517477035522, Validation Loss: 0.32161256670951843\n",
      "Epoch 30/100, Training Loss: 1.283289909362793, Validation Loss: 0.30242082476615906\n",
      "Epoch 31/100, Training Loss: 1.2769275903701782, Validation Loss: 0.2844183146953583\n",
      "Epoch 32/100, Training Loss: 1.2338756322860718, Validation Loss: 0.26771804690361023\n",
      "Epoch 33/100, Training Loss: 1.2371059656143188, Validation Loss: 0.25234293937683105\n",
      "Epoch 34/100, Training Loss: 1.2020418643951416, Validation Loss: 0.23816445469856262\n",
      "Epoch 35/100, Training Loss: 1.1920491456985474, Validation Loss: 0.2254399210214615\n",
      "Epoch 36/100, Training Loss: 1.1721196174621582, Validation Loss: 0.2139277160167694\n",
      "Epoch 37/100, Training Loss: 1.1537917852401733, Validation Loss: 0.20358456671237946\n",
      "Epoch 38/100, Training Loss: 1.1324753761291504, Validation Loss: 0.1942855715751648\n",
      "Epoch 39/100, Training Loss: 1.106535792350769, Validation Loss: 0.18564791977405548\n",
      "Epoch 40/100, Training Loss: 1.1039164066314697, Validation Loss: 0.17778977751731873\n",
      "Epoch 41/100, Training Loss: 1.0925198793411255, Validation Loss: 0.17043939232826233\n",
      "Epoch 42/100, Training Loss: 1.0742539167404175, Validation Loss: 0.16393473744392395\n",
      "Epoch 43/100, Training Loss: 1.0627226829528809, Validation Loss: 0.15795591473579407\n",
      "Epoch 44/100, Training Loss: 1.0241066217422485, Validation Loss: 0.15260885655879974\n",
      "Epoch 45/100, Training Loss: 1.0294520854949951, Validation Loss: 0.14764124155044556\n",
      "Epoch 46/100, Training Loss: 1.01580810546875, Validation Loss: 0.14314067363739014\n",
      "Epoch 47/100, Training Loss: 0.996015727519989, Validation Loss: 0.1390613317489624\n",
      "Epoch 48/100, Training Loss: 0.9824355840682983, Validation Loss: 0.13513827323913574\n",
      "Epoch 49/100, Training Loss: 0.974308431148529, Validation Loss: 0.1317237764596939\n",
      "Epoch 50/100, Training Loss: 0.9600659012794495, Validation Loss: 0.12846772372722626\n",
      "Epoch 51/100, Training Loss: 0.950689435005188, Validation Loss: 0.12537209689617157\n",
      "Epoch 52/100, Training Loss: 0.9368190169334412, Validation Loss: 0.12259157001972198\n",
      "Epoch 53/100, Training Loss: 0.9332627058029175, Validation Loss: 0.11997542530298233\n",
      "Epoch 54/100, Training Loss: 0.9117313027381897, Validation Loss: 0.11744388937950134\n",
      "Epoch 55/100, Training Loss: 0.9029912352561951, Validation Loss: 0.11504814773797989\n",
      "Epoch 56/100, Training Loss: 0.8949474692344666, Validation Loss: 0.11272820085287094\n",
      "Epoch 57/100, Training Loss: 0.8891303539276123, Validation Loss: 0.11055955290794373\n",
      "Epoch 58/100, Training Loss: 0.8855830430984497, Validation Loss: 0.10850919038057327\n",
      "Epoch 59/100, Training Loss: 0.87326979637146, Validation Loss: 0.10648472607135773\n",
      "Epoch 60/100, Training Loss: 0.8681716322898865, Validation Loss: 0.10448000580072403\n",
      "Epoch 61/100, Training Loss: 0.8550821542739868, Validation Loss: 0.10264815390110016\n",
      "Epoch 62/100, Training Loss: 0.8532791137695312, Validation Loss: 0.10084524750709534\n",
      "Epoch 63/100, Training Loss: 0.8379252552986145, Validation Loss: 0.0990815982222557\n",
      "Epoch 64/100, Training Loss: 0.8302978873252869, Validation Loss: 0.09736652672290802\n",
      "Epoch 65/100, Training Loss: 0.8241835832595825, Validation Loss: 0.09564719349145889\n",
      "Epoch 66/100, Training Loss: 0.8059263825416565, Validation Loss: 0.0940108671784401\n",
      "Epoch 67/100, Training Loss: 0.8045535683631897, Validation Loss: 0.09245626628398895\n",
      "Epoch 68/100, Training Loss: 0.7940512895584106, Validation Loss: 0.09095746278762817\n",
      "Epoch 69/100, Training Loss: 0.7845426797866821, Validation Loss: 0.08944796025753021\n",
      "Epoch 70/100, Training Loss: 0.7781628966331482, Validation Loss: 0.087986059486866\n",
      "Epoch 71/100, Training Loss: 0.7743915915489197, Validation Loss: 0.08661852031946182\n",
      "Epoch 72/100, Training Loss: 0.7688137292861938, Validation Loss: 0.08527703583240509\n",
      "Epoch 73/100, Training Loss: 0.756263792514801, Validation Loss: 0.08398347347974777\n",
      "Epoch 74/100, Training Loss: 0.7497249841690063, Validation Loss: 0.08276738226413727\n",
      "Epoch 75/100, Training Loss: 0.7384511828422546, Validation Loss: 0.08163391798734665\n",
      "Epoch 76/100, Training Loss: 0.7338421940803528, Validation Loss: 0.08034218847751617\n",
      "Epoch 77/100, Training Loss: 0.7343073487281799, Validation Loss: 0.0791713073849678\n",
      "Epoch 78/100, Training Loss: 0.7308634519577026, Validation Loss: 0.07793240249156952\n",
      "Epoch 79/100, Training Loss: 0.7176629900932312, Validation Loss: 0.07675295323133469\n",
      "Epoch 80/100, Training Loss: 0.7080681324005127, Validation Loss: 0.07560314238071442\n",
      "Epoch 81/100, Training Loss: 0.7007185220718384, Validation Loss: 0.07446544617414474\n",
      "Epoch 82/100, Training Loss: 0.6953307390213013, Validation Loss: 0.07343452423810959\n",
      "Epoch 83/100, Training Loss: 0.6905812621116638, Validation Loss: 0.07244311273097992\n",
      "Epoch 84/100, Training Loss: 0.6883102655410767, Validation Loss: 0.07147423177957535\n",
      "Epoch 85/100, Training Loss: 0.677734375, Validation Loss: 0.07046707719564438\n",
      "Epoch 86/100, Training Loss: 0.6773949265480042, Validation Loss: 0.06951200217008591\n",
      "Epoch 87/100, Training Loss: 0.6737316250801086, Validation Loss: 0.06853950768709183\n",
      "Epoch 88/100, Training Loss: 0.6604432463645935, Validation Loss: 0.06753633171319962\n",
      "Epoch 89/100, Training Loss: 0.6564086675643921, Validation Loss: 0.06661712378263474\n",
      "Epoch 90/100, Training Loss: 0.6544176340103149, Validation Loss: 0.06570285558700562\n",
      "Epoch 91/100, Training Loss: 0.6493865251541138, Validation Loss: 0.06481592357158661\n",
      "Epoch 92/100, Training Loss: 0.6417200565338135, Validation Loss: 0.06396208703517914\n",
      "Epoch 93/100, Training Loss: 0.6446166634559631, Validation Loss: 0.0630774199962616\n",
      "Epoch 94/100, Training Loss: 0.627239465713501, Validation Loss: 0.06222708895802498\n",
      "Epoch 95/100, Training Loss: 0.6307479739189148, Validation Loss: 0.06126711890101433\n",
      "Epoch 96/100, Training Loss: 0.6242649555206299, Validation Loss: 0.06039448454976082\n",
      "Epoch 97/100, Training Loss: 0.619144856929779, Validation Loss: 0.05952832102775574\n",
      "Epoch 98/100, Training Loss: 0.6160799264907837, Validation Loss: 0.058730728924274445\n",
      "Epoch 99/100, Training Loss: 0.6103676557540894, Validation Loss: 0.05797449126839638\n",
      "Epoch 100/100, Training Loss: 0.6072314381599426, Validation Loss: 0.05729410797357559\n",
      "Fold 4 - R² Score: 0.9428, MAE: 0.1565\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 3.069521903991699, Validation Loss: 1.1511237621307373\n",
      "Epoch 2/100, Training Loss: 2.9067728519439697, Validation Loss: 1.1314706802368164\n",
      "Epoch 3/100, Training Loss: 2.763031244277954, Validation Loss: 1.1114912033081055\n",
      "Epoch 4/100, Training Loss: 2.6101696491241455, Validation Loss: 1.0903581380844116\n",
      "Epoch 5/100, Training Loss: 2.4817798137664795, Validation Loss: 1.0681055784225464\n",
      "Epoch 6/100, Training Loss: 2.3651421070098877, Validation Loss: 1.044140100479126\n",
      "Epoch 7/100, Training Loss: 2.24440336227417, Validation Loss: 1.0179126262664795\n",
      "Epoch 8/100, Training Loss: 2.130089282989502, Validation Loss: 0.9893922209739685\n",
      "Epoch 9/100, Training Loss: 2.0417070388793945, Validation Loss: 0.9586458802223206\n",
      "Epoch 10/100, Training Loss: 1.9464137554168701, Validation Loss: 0.9256150126457214\n",
      "Epoch 11/100, Training Loss: 1.852623462677002, Validation Loss: 0.8905590772628784\n",
      "Epoch 12/100, Training Loss: 1.7619351148605347, Validation Loss: 0.8540846109390259\n",
      "Epoch 13/100, Training Loss: 1.7197115421295166, Validation Loss: 0.8165313601493835\n",
      "Epoch 14/100, Training Loss: 1.6417596340179443, Validation Loss: 0.77824866771698\n",
      "Epoch 15/100, Training Loss: 1.5849624872207642, Validation Loss: 0.739537239074707\n",
      "Epoch 16/100, Training Loss: 1.525151014328003, Validation Loss: 0.7009915113449097\n",
      "Epoch 17/100, Training Loss: 1.4801616668701172, Validation Loss: 0.6632682085037231\n",
      "Epoch 18/100, Training Loss: 1.4347069263458252, Validation Loss: 0.6264951825141907\n",
      "Epoch 19/100, Training Loss: 1.3986412286758423, Validation Loss: 0.5905579924583435\n",
      "Epoch 20/100, Training Loss: 1.3600871562957764, Validation Loss: 0.5561978220939636\n",
      "Epoch 21/100, Training Loss: 1.3184717893600464, Validation Loss: 0.5233738422393799\n",
      "Epoch 22/100, Training Loss: 1.2917362451553345, Validation Loss: 0.4920673668384552\n",
      "Epoch 23/100, Training Loss: 1.2738934755325317, Validation Loss: 0.4621888995170593\n",
      "Epoch 24/100, Training Loss: 1.2428621053695679, Validation Loss: 0.43398919701576233\n",
      "Epoch 25/100, Training Loss: 1.1982570886611938, Validation Loss: 0.4074954688549042\n",
      "Epoch 26/100, Training Loss: 1.1874843835830688, Validation Loss: 0.3825420141220093\n",
      "Epoch 27/100, Training Loss: 1.1622036695480347, Validation Loss: 0.3592663109302521\n",
      "Epoch 28/100, Training Loss: 1.1268706321716309, Validation Loss: 0.33744606375694275\n",
      "Epoch 29/100, Training Loss: 1.120886206626892, Validation Loss: 0.31676802039146423\n",
      "Epoch 30/100, Training Loss: 1.0961846113204956, Validation Loss: 0.29747912287712097\n",
      "Epoch 31/100, Training Loss: 1.0833698511123657, Validation Loss: 0.27912551164627075\n",
      "Epoch 32/100, Training Loss: 1.0659595727920532, Validation Loss: 0.2618306279182434\n",
      "Epoch 33/100, Training Loss: 1.0352730751037598, Validation Loss: 0.24551662802696228\n",
      "Epoch 34/100, Training Loss: 1.0353845357894897, Validation Loss: 0.23006363213062286\n",
      "Epoch 35/100, Training Loss: 1.011849284172058, Validation Loss: 0.21546584367752075\n",
      "Epoch 36/100, Training Loss: 0.996672511100769, Validation Loss: 0.2017366737127304\n",
      "Epoch 37/100, Training Loss: 0.9799256920814514, Validation Loss: 0.18903441727161407\n",
      "Epoch 38/100, Training Loss: 0.9596630334854126, Validation Loss: 0.1772136688232422\n",
      "Epoch 39/100, Training Loss: 0.9503159523010254, Validation Loss: 0.16627760231494904\n",
      "Epoch 40/100, Training Loss: 0.9426044225692749, Validation Loss: 0.15609967708587646\n",
      "Epoch 41/100, Training Loss: 0.9246311187744141, Validation Loss: 0.1468372941017151\n",
      "Epoch 42/100, Training Loss: 0.918703556060791, Validation Loss: 0.1386236846446991\n",
      "Epoch 43/100, Training Loss: 0.8960158824920654, Validation Loss: 0.1311424821615219\n",
      "Epoch 44/100, Training Loss: 0.8905917406082153, Validation Loss: 0.12431205809116364\n",
      "Epoch 45/100, Training Loss: 0.8824647665023804, Validation Loss: 0.11815640330314636\n",
      "Epoch 46/100, Training Loss: 0.8662794232368469, Validation Loss: 0.11247957497835159\n",
      "Epoch 47/100, Training Loss: 0.8481928110122681, Validation Loss: 0.10748053342103958\n",
      "Epoch 48/100, Training Loss: 0.8475865721702576, Validation Loss: 0.10290143638849258\n",
      "Epoch 49/100, Training Loss: 0.8384509682655334, Validation Loss: 0.09860940277576447\n",
      "Epoch 50/100, Training Loss: 0.8190184235572815, Validation Loss: 0.09473773092031479\n",
      "Epoch 51/100, Training Loss: 0.8156739473342896, Validation Loss: 0.09116970747709274\n",
      "Epoch 52/100, Training Loss: 0.806097149848938, Validation Loss: 0.08798890560865402\n",
      "Epoch 53/100, Training Loss: 0.7989411354064941, Validation Loss: 0.08503803610801697\n",
      "Epoch 54/100, Training Loss: 0.7916963696479797, Validation Loss: 0.0822439193725586\n",
      "Epoch 55/100, Training Loss: 0.7767369151115417, Validation Loss: 0.0796751007437706\n",
      "Epoch 56/100, Training Loss: 0.7735100388526917, Validation Loss: 0.0772978812456131\n",
      "Epoch 57/100, Training Loss: 0.7595058679580688, Validation Loss: 0.07509791105985641\n",
      "Epoch 58/100, Training Loss: 0.7570818662643433, Validation Loss: 0.07296888530254364\n",
      "Epoch 59/100, Training Loss: 0.7557241320610046, Validation Loss: 0.0709775984287262\n",
      "Epoch 60/100, Training Loss: 0.7445805072784424, Validation Loss: 0.06906329840421677\n",
      "Epoch 61/100, Training Loss: 0.7309706807136536, Validation Loss: 0.06715861707925797\n",
      "Epoch 62/100, Training Loss: 0.7230453491210938, Validation Loss: 0.06529927253723145\n",
      "Epoch 63/100, Training Loss: 0.7211222052574158, Validation Loss: 0.06342384219169617\n",
      "Epoch 64/100, Training Loss: 0.724112868309021, Validation Loss: 0.06177539750933647\n",
      "Epoch 65/100, Training Loss: 0.7067223191261292, Validation Loss: 0.06016828119754791\n",
      "Epoch 66/100, Training Loss: 0.6863065361976624, Validation Loss: 0.05854497849941254\n",
      "Epoch 67/100, Training Loss: 0.6935680508613586, Validation Loss: 0.0570535771548748\n",
      "Epoch 68/100, Training Loss: 0.6886875629425049, Validation Loss: 0.05561117082834244\n",
      "Epoch 69/100, Training Loss: 0.6770095229148865, Validation Loss: 0.054215412586927414\n",
      "Epoch 70/100, Training Loss: 0.6695684194564819, Validation Loss: 0.05285501852631569\n",
      "Epoch 71/100, Training Loss: 0.6649319529533386, Validation Loss: 0.05161259323358536\n",
      "Epoch 72/100, Training Loss: 0.6595700979232788, Validation Loss: 0.050325267016887665\n",
      "Epoch 73/100, Training Loss: 0.6492279171943665, Validation Loss: 0.04912738874554634\n",
      "Epoch 74/100, Training Loss: 0.649398684501648, Validation Loss: 0.04801463335752487\n",
      "Epoch 75/100, Training Loss: 0.6465271711349487, Validation Loss: 0.04698288068175316\n",
      "Epoch 76/100, Training Loss: 0.6395010948181152, Validation Loss: 0.04602592810988426\n",
      "Epoch 77/100, Training Loss: 0.6354612708091736, Validation Loss: 0.045174479484558105\n",
      "Epoch 78/100, Training Loss: 0.6272454261779785, Validation Loss: 0.044302940368652344\n",
      "Epoch 79/100, Training Loss: 0.6205016374588013, Validation Loss: 0.04351144656538963\n",
      "Epoch 80/100, Training Loss: 0.6167176365852356, Validation Loss: 0.04274539276957512\n",
      "Epoch 81/100, Training Loss: 0.6156614422798157, Validation Loss: 0.04202722758054733\n",
      "Epoch 82/100, Training Loss: 0.6058371067047119, Validation Loss: 0.04131206497550011\n",
      "Epoch 83/100, Training Loss: 0.5992456674575806, Validation Loss: 0.040643855929374695\n",
      "Epoch 84/100, Training Loss: 0.5994551777839661, Validation Loss: 0.03995658457279205\n",
      "Epoch 85/100, Training Loss: 0.5880365967750549, Validation Loss: 0.0392238013446331\n",
      "Epoch 86/100, Training Loss: 0.5927560925483704, Validation Loss: 0.038599129766225815\n",
      "Epoch 87/100, Training Loss: 0.5777869820594788, Validation Loss: 0.0379636250436306\n",
      "Epoch 88/100, Training Loss: 0.5744726657867432, Validation Loss: 0.03738231584429741\n",
      "Epoch 89/100, Training Loss: 0.5780214071273804, Validation Loss: 0.036803074181079865\n",
      "Epoch 90/100, Training Loss: 0.5710961818695068, Validation Loss: 0.03623248264193535\n",
      "Epoch 91/100, Training Loss: 0.5635422468185425, Validation Loss: 0.035673756152391434\n",
      "Epoch 92/100, Training Loss: 0.5558839440345764, Validation Loss: 0.035072680562734604\n",
      "Epoch 93/100, Training Loss: 0.55776447057724, Validation Loss: 0.034514617174863815\n",
      "Epoch 94/100, Training Loss: 0.5571550726890564, Validation Loss: 0.03394225239753723\n",
      "Epoch 95/100, Training Loss: 0.5541622638702393, Validation Loss: 0.03334181010723114\n",
      "Epoch 96/100, Training Loss: 0.5470764636993408, Validation Loss: 0.0328306220471859\n",
      "Epoch 97/100, Training Loss: 0.5417330861091614, Validation Loss: 0.032354459166526794\n",
      "Epoch 98/100, Training Loss: 0.5424586534500122, Validation Loss: 0.031869810074567795\n",
      "Epoch 99/100, Training Loss: 0.5373897552490234, Validation Loss: 0.031457386910915375\n",
      "Epoch 100/100, Training Loss: 0.53387451171875, Validation Loss: 0.031039109453558922\n",
      "Fold 5 - R² Score: 0.9689, MAE: 0.1237\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.005}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 4.66564416885376, Validation Loss: 1.139634609222412\n",
      "Epoch 2/100, Training Loss: 3.732179641723633, Validation Loss: 1.0220580101013184\n",
      "Epoch 3/100, Training Loss: 3.070295572280884, Validation Loss: 0.9114574790000916\n",
      "Epoch 4/100, Training Loss: 2.5120646953582764, Validation Loss: 0.8078612685203552\n",
      "Epoch 5/100, Training Loss: 2.0902955532073975, Validation Loss: 0.7133413553237915\n",
      "Epoch 6/100, Training Loss: 1.7904322147369385, Validation Loss: 0.6296714544296265\n",
      "Epoch 7/100, Training Loss: 1.563899278640747, Validation Loss: 0.557583749294281\n",
      "Epoch 8/100, Training Loss: 1.3904969692230225, Validation Loss: 0.49644047021865845\n",
      "Epoch 9/100, Training Loss: 1.2703757286071777, Validation Loss: 0.44475075602531433\n",
      "Epoch 10/100, Training Loss: 1.1797535419464111, Validation Loss: 0.40112805366516113\n",
      "Epoch 11/100, Training Loss: 1.0756853818893433, Validation Loss: 0.364846795797348\n",
      "Epoch 12/100, Training Loss: 1.021167516708374, Validation Loss: 0.33487287163734436\n",
      "Epoch 13/100, Training Loss: 0.9445774555206299, Validation Loss: 0.31052812933921814\n",
      "Epoch 14/100, Training Loss: 0.9003418684005737, Validation Loss: 0.29072055220603943\n",
      "Epoch 15/100, Training Loss: 0.8678929209709167, Validation Loss: 0.27472618222236633\n",
      "Epoch 16/100, Training Loss: 0.8306088447570801, Validation Loss: 0.2614388167858124\n",
      "Epoch 17/100, Training Loss: 0.7959719896316528, Validation Loss: 0.24998627603054047\n",
      "Epoch 18/100, Training Loss: 0.776333749294281, Validation Loss: 0.23974023759365082\n",
      "Epoch 19/100, Training Loss: 0.7398679852485657, Validation Loss: 0.22942915558815002\n",
      "Epoch 20/100, Training Loss: 0.716377854347229, Validation Loss: 0.2186782956123352\n",
      "Epoch 21/100, Training Loss: 0.6909225583076477, Validation Loss: 0.20731677114963531\n",
      "Epoch 22/100, Training Loss: 0.6524354219436646, Validation Loss: 0.19517359137535095\n",
      "Epoch 23/100, Training Loss: 0.6399375796318054, Validation Loss: 0.1822717934846878\n",
      "Epoch 24/100, Training Loss: 0.6142515540122986, Validation Loss: 0.16854038834571838\n",
      "Epoch 25/100, Training Loss: 0.5905025601387024, Validation Loss: 0.15444014966487885\n",
      "Epoch 26/100, Training Loss: 0.5680413246154785, Validation Loss: 0.14071141183376312\n",
      "Epoch 27/100, Training Loss: 0.5467563271522522, Validation Loss: 0.12738995254039764\n",
      "Epoch 28/100, Training Loss: 0.5240899920463562, Validation Loss: 0.11485555768013\n",
      "Epoch 29/100, Training Loss: 0.5069188475608826, Validation Loss: 0.1038379892706871\n",
      "Epoch 30/100, Training Loss: 0.49779918789863586, Validation Loss: 0.09405191987752914\n",
      "Epoch 31/100, Training Loss: 0.4820757210254669, Validation Loss: 0.08524977415800095\n",
      "Epoch 32/100, Training Loss: 0.45943117141723633, Validation Loss: 0.07751215994358063\n",
      "Epoch 33/100, Training Loss: 0.450967401266098, Validation Loss: 0.0706203281879425\n",
      "Epoch 34/100, Training Loss: 0.4418189823627472, Validation Loss: 0.06435676664113998\n",
      "Epoch 35/100, Training Loss: 0.4371331036090851, Validation Loss: 0.05879427120089531\n",
      "Epoch 36/100, Training Loss: 0.42231878638267517, Validation Loss: 0.053789347410202026\n",
      "Epoch 37/100, Training Loss: 0.4061994254589081, Validation Loss: 0.049387652426958084\n",
      "Epoch 38/100, Training Loss: 0.3999663293361664, Validation Loss: 0.045623429119586945\n",
      "Epoch 39/100, Training Loss: 0.38958820700645447, Validation Loss: 0.04236125946044922\n",
      "Epoch 40/100, Training Loss: 0.38509637117385864, Validation Loss: 0.03948500007390976\n",
      "Epoch 41/100, Training Loss: 0.37156301736831665, Validation Loss: 0.03691432252526283\n",
      "Epoch 42/100, Training Loss: 0.3669978678226471, Validation Loss: 0.034742072224617004\n",
      "Epoch 43/100, Training Loss: 0.35704246163368225, Validation Loss: 0.03295184671878815\n",
      "Epoch 44/100, Training Loss: 0.3461647927761078, Validation Loss: 0.0314674898982048\n",
      "Epoch 45/100, Training Loss: 0.3466455638408661, Validation Loss: 0.03014374151825905\n",
      "Epoch 46/100, Training Loss: 0.3382592499256134, Validation Loss: 0.029026808217167854\n",
      "Epoch 47/100, Training Loss: 0.3336494565010071, Validation Loss: 0.027975214645266533\n",
      "Epoch 48/100, Training Loss: 0.32366499304771423, Validation Loss: 0.027034850791096687\n",
      "Epoch 49/100, Training Loss: 0.3159656226634979, Validation Loss: 0.02605350874364376\n",
      "Epoch 50/100, Training Loss: 0.3105368912220001, Validation Loss: 0.025103993713855743\n",
      "Epoch 51/100, Training Loss: 0.30611154437065125, Validation Loss: 0.024183031171560287\n",
      "Epoch 52/100, Training Loss: 0.3057484030723572, Validation Loss: 0.023337028920650482\n",
      "Epoch 53/100, Training Loss: 0.29497599601745605, Validation Loss: 0.022553758695721626\n",
      "Epoch 54/100, Training Loss: 0.29083409905433655, Validation Loss: 0.021843625232577324\n",
      "Epoch 55/100, Training Loss: 0.28111034631729126, Validation Loss: 0.021152298897504807\n",
      "Epoch 56/100, Training Loss: 0.28071334958076477, Validation Loss: 0.020470064133405685\n",
      "Epoch 57/100, Training Loss: 0.2728254795074463, Validation Loss: 0.019899727776646614\n",
      "Epoch 58/100, Training Loss: 0.27052390575408936, Validation Loss: 0.019372455775737762\n",
      "Epoch 59/100, Training Loss: 0.26370465755462646, Validation Loss: 0.018875448033213615\n",
      "Epoch 60/100, Training Loss: 0.25978580117225647, Validation Loss: 0.0184058528393507\n",
      "Epoch 61/100, Training Loss: 0.2599896192550659, Validation Loss: 0.017907259985804558\n",
      "Epoch 62/100, Training Loss: 0.25589022040367126, Validation Loss: 0.017440086230635643\n",
      "Epoch 63/100, Training Loss: 0.2505786418914795, Validation Loss: 0.017009852454066277\n",
      "Epoch 64/100, Training Loss: 0.24454641342163086, Validation Loss: 0.016696041449904442\n",
      "Epoch 65/100, Training Loss: 0.2429993897676468, Validation Loss: 0.01635119877755642\n",
      "Epoch 66/100, Training Loss: 0.23985163867473602, Validation Loss: 0.01598503068089485\n",
      "Epoch 67/100, Training Loss: 0.23533090949058533, Validation Loss: 0.015655139461159706\n",
      "Epoch 68/100, Training Loss: 0.23199521005153656, Validation Loss: 0.015389089472591877\n",
      "Epoch 69/100, Training Loss: 0.22918032109737396, Validation Loss: 0.015171642415225506\n",
      "Epoch 70/100, Training Loss: 0.22781775891780853, Validation Loss: 0.014964117668569088\n",
      "Epoch 71/100, Training Loss: 0.2238689363002777, Validation Loss: 0.014768078923225403\n",
      "Epoch 72/100, Training Loss: 0.22234293818473816, Validation Loss: 0.014586095698177814\n",
      "Epoch 73/100, Training Loss: 0.2231895923614502, Validation Loss: 0.014419893734157085\n",
      "Epoch 74/100, Training Loss: 0.21694102883338928, Validation Loss: 0.014201784506440163\n",
      "Epoch 75/100, Training Loss: 0.2130764275789261, Validation Loss: 0.014020225964486599\n",
      "Epoch 76/100, Training Loss: 0.20991066098213196, Validation Loss: 0.013870973140001297\n",
      "Epoch 77/100, Training Loss: 0.2091139405965805, Validation Loss: 0.013786215335130692\n",
      "Epoch 78/100, Training Loss: 0.20573990046977997, Validation Loss: 0.01368988212198019\n",
      "Epoch 79/100, Training Loss: 0.20340599119663239, Validation Loss: 0.013641389086842537\n",
      "Epoch 80/100, Training Loss: 0.20000192523002625, Validation Loss: 0.013529013842344284\n",
      "Epoch 81/100, Training Loss: 0.19768382608890533, Validation Loss: 0.013480053283274174\n",
      "Epoch 82/100, Training Loss: 0.19395264983177185, Validation Loss: 0.01347807515412569\n",
      "Epoch 83/100, Training Loss: 0.1907912790775299, Validation Loss: 0.013444104231894016\n",
      "Epoch 84/100, Training Loss: 0.19166338443756104, Validation Loss: 0.0134036960080266\n",
      "Epoch 85/100, Training Loss: 0.18626096844673157, Validation Loss: 0.013405187986791134\n",
      "Epoch 86/100, Training Loss: 0.18618197739124298, Validation Loss: 0.013350574299693108\n",
      "Epoch 87/100, Training Loss: 0.1847413331270218, Validation Loss: 0.013321300968527794\n",
      "Epoch 88/100, Training Loss: 0.1817983239889145, Validation Loss: 0.01328789908438921\n",
      "Epoch 89/100, Training Loss: 0.1787414401769638, Validation Loss: 0.013227568008005619\n",
      "Epoch 90/100, Training Loss: 0.1778329759836197, Validation Loss: 0.013212778605520725\n",
      "Epoch 91/100, Training Loss: 0.17581990361213684, Validation Loss: 0.01320497877895832\n",
      "Epoch 92/100, Training Loss: 0.17275318503379822, Validation Loss: 0.013150540180504322\n",
      "Epoch 93/100, Training Loss: 0.17260275781154633, Validation Loss: 0.013113405555486679\n",
      "Epoch 94/100, Training Loss: 0.17078451812267303, Validation Loss: 0.013045739382505417\n",
      "Epoch 95/100, Training Loss: 0.1697646826505661, Validation Loss: 0.012992375530302525\n",
      "Epoch 96/100, Training Loss: 0.16788576543331146, Validation Loss: 0.012943079695105553\n",
      "Epoch 97/100, Training Loss: 0.16661956906318665, Validation Loss: 0.012887763790786266\n",
      "Epoch 98/100, Training Loss: 0.16335825622081757, Validation Loss: 0.0128397261723876\n",
      "Epoch 99/100, Training Loss: 0.16129352152347565, Validation Loss: 0.012756448239088058\n",
      "Epoch 100/100, Training Loss: 0.1604119837284088, Validation Loss: 0.01268609706312418\n",
      "Fold 1 - R² Score: 0.9873, MAE: 0.0801\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 2.9830024242401123, Validation Loss: 0.8023215532302856\n",
      "Epoch 2/100, Training Loss: 2.4347004890441895, Validation Loss: 0.6939147710800171\n",
      "Epoch 3/100, Training Loss: 1.9980404376983643, Validation Loss: 0.6111363172531128\n",
      "Epoch 4/100, Training Loss: 1.7341982126235962, Validation Loss: 0.5512768626213074\n",
      "Epoch 5/100, Training Loss: 1.531219244003296, Validation Loss: 0.5084553956985474\n",
      "Epoch 6/100, Training Loss: 1.3622865676879883, Validation Loss: 0.4768196940422058\n",
      "Epoch 7/100, Training Loss: 1.2596993446350098, Validation Loss: 0.45351624488830566\n",
      "Epoch 8/100, Training Loss: 1.1489335298538208, Validation Loss: 0.43512994050979614\n",
      "Epoch 9/100, Training Loss: 1.0749952793121338, Validation Loss: 0.4193640649318695\n",
      "Epoch 10/100, Training Loss: 1.0028551816940308, Validation Loss: 0.4043080508708954\n",
      "Epoch 11/100, Training Loss: 0.9488953351974487, Validation Loss: 0.38874295353889465\n",
      "Epoch 12/100, Training Loss: 0.9088656306266785, Validation Loss: 0.3711314797401428\n",
      "Epoch 13/100, Training Loss: 0.8561419248580933, Validation Loss: 0.35172486305236816\n",
      "Epoch 14/100, Training Loss: 0.798150897026062, Validation Loss: 0.329911470413208\n",
      "Epoch 15/100, Training Loss: 0.7569096684455872, Validation Loss: 0.3064347803592682\n",
      "Epoch 16/100, Training Loss: 0.7258413434028625, Validation Loss: 0.2817133069038391\n",
      "Epoch 17/100, Training Loss: 0.688245952129364, Validation Loss: 0.25714734196662903\n",
      "Epoch 18/100, Training Loss: 0.6539235711097717, Validation Loss: 0.2334604263305664\n",
      "Epoch 19/100, Training Loss: 0.617389976978302, Validation Loss: 0.2113349288702011\n",
      "Epoch 20/100, Training Loss: 0.6005297899246216, Validation Loss: 0.19159211218357086\n",
      "Epoch 21/100, Training Loss: 0.5788345336914062, Validation Loss: 0.17420347034931183\n",
      "Epoch 22/100, Training Loss: 0.5543631911277771, Validation Loss: 0.15892861783504486\n",
      "Epoch 23/100, Training Loss: 0.536742091178894, Validation Loss: 0.14609970152378082\n",
      "Epoch 24/100, Training Loss: 0.51579749584198, Validation Loss: 0.13501453399658203\n",
      "Epoch 25/100, Training Loss: 0.4944441020488739, Validation Loss: 0.12533792853355408\n",
      "Epoch 26/100, Training Loss: 0.4776516854763031, Validation Loss: 0.11692747473716736\n",
      "Epoch 27/100, Training Loss: 0.46684324741363525, Validation Loss: 0.10914893448352814\n",
      "Epoch 28/100, Training Loss: 0.45142510533332825, Validation Loss: 0.10196883231401443\n",
      "Epoch 29/100, Training Loss: 0.43211501836776733, Validation Loss: 0.09537547081708908\n",
      "Epoch 30/100, Training Loss: 0.4186876714229584, Validation Loss: 0.08932764828205109\n",
      "Epoch 31/100, Training Loss: 0.40831053256988525, Validation Loss: 0.08332739770412445\n",
      "Epoch 32/100, Training Loss: 0.3948718011379242, Validation Loss: 0.0772772878408432\n",
      "Epoch 33/100, Training Loss: 0.3853820562362671, Validation Loss: 0.07129526138305664\n",
      "Epoch 34/100, Training Loss: 0.37278491258621216, Validation Loss: 0.06550396233797073\n",
      "Epoch 35/100, Training Loss: 0.3640495538711548, Validation Loss: 0.059985481202602386\n",
      "Epoch 36/100, Training Loss: 0.357072651386261, Validation Loss: 0.05481928586959839\n",
      "Epoch 37/100, Training Loss: 0.3445730209350586, Validation Loss: 0.050034891813993454\n",
      "Epoch 38/100, Training Loss: 0.3331690728664398, Validation Loss: 0.045662134885787964\n",
      "Epoch 39/100, Training Loss: 0.32294175028800964, Validation Loss: 0.04174546152353287\n",
      "Epoch 40/100, Training Loss: 0.31782519817352295, Validation Loss: 0.03825949504971504\n",
      "Epoch 41/100, Training Loss: 0.30967748165130615, Validation Loss: 0.03530203923583031\n",
      "Epoch 42/100, Training Loss: 0.3041425049304962, Validation Loss: 0.03271861746907234\n",
      "Epoch 43/100, Training Loss: 0.2932482957839966, Validation Loss: 0.030559508129954338\n",
      "Epoch 44/100, Training Loss: 0.2889510989189148, Validation Loss: 0.028700759634375572\n",
      "Epoch 45/100, Training Loss: 0.28207501769065857, Validation Loss: 0.027125149965286255\n",
      "Epoch 46/100, Training Loss: 0.27437761425971985, Validation Loss: 0.025837751105427742\n",
      "Epoch 47/100, Training Loss: 0.27032360434532166, Validation Loss: 0.024711372330784798\n",
      "Epoch 48/100, Training Loss: 0.2622630298137665, Validation Loss: 0.0237922053784132\n",
      "Epoch 49/100, Training Loss: 0.25600457191467285, Validation Loss: 0.023030346259474754\n",
      "Epoch 50/100, Training Loss: 0.25235745310783386, Validation Loss: 0.02233361266553402\n",
      "Epoch 51/100, Training Loss: 0.24588017165660858, Validation Loss: 0.021725066006183624\n",
      "Epoch 52/100, Training Loss: 0.24140240252017975, Validation Loss: 0.02122632972896099\n",
      "Epoch 53/100, Training Loss: 0.23541851341724396, Validation Loss: 0.020763549953699112\n",
      "Epoch 54/100, Training Loss: 0.23065340518951416, Validation Loss: 0.020332707092165947\n",
      "Epoch 55/100, Training Loss: 0.228138729929924, Validation Loss: 0.019945481792092323\n",
      "Epoch 56/100, Training Loss: 0.22367261350154877, Validation Loss: 0.019636059179902077\n",
      "Epoch 57/100, Training Loss: 0.21973837912082672, Validation Loss: 0.019310910254716873\n",
      "Epoch 58/100, Training Loss: 0.21643969416618347, Validation Loss: 0.018982023000717163\n",
      "Epoch 59/100, Training Loss: 0.21198157966136932, Validation Loss: 0.01862981542944908\n",
      "Epoch 60/100, Training Loss: 0.20593182742595673, Validation Loss: 0.01826646365225315\n",
      "Epoch 61/100, Training Loss: 0.2021077275276184, Validation Loss: 0.017954278737306595\n",
      "Epoch 62/100, Training Loss: 0.20089960098266602, Validation Loss: 0.017650233581662178\n",
      "Epoch 63/100, Training Loss: 0.19742900133132935, Validation Loss: 0.017340920865535736\n",
      "Epoch 64/100, Training Loss: 0.19312900304794312, Validation Loss: 0.01704402081668377\n",
      "Epoch 65/100, Training Loss: 0.19119703769683838, Validation Loss: 0.016782941296696663\n",
      "Epoch 66/100, Training Loss: 0.18658603727817535, Validation Loss: 0.016546741127967834\n",
      "Epoch 67/100, Training Loss: 0.18388712406158447, Validation Loss: 0.016354644671082497\n",
      "Epoch 68/100, Training Loss: 0.18188875913619995, Validation Loss: 0.01611284539103508\n",
      "Epoch 69/100, Training Loss: 0.17950497567653656, Validation Loss: 0.015888795256614685\n",
      "Epoch 70/100, Training Loss: 0.17651881277561188, Validation Loss: 0.01569424755871296\n",
      "Epoch 71/100, Training Loss: 0.17217183113098145, Validation Loss: 0.015496288426220417\n",
      "Epoch 72/100, Training Loss: 0.1705394685268402, Validation Loss: 0.01527475006878376\n",
      "Epoch 73/100, Training Loss: 0.16712647676467896, Validation Loss: 0.015098333358764648\n",
      "Epoch 74/100, Training Loss: 0.1660761535167694, Validation Loss: 0.014933078549802303\n",
      "Epoch 75/100, Training Loss: 0.16501598060131073, Validation Loss: 0.014764033257961273\n",
      "Epoch 76/100, Training Loss: 0.16425280272960663, Validation Loss: 0.014637562446296215\n",
      "Epoch 77/100, Training Loss: 0.15897589921951294, Validation Loss: 0.014491697773337364\n",
      "Epoch 78/100, Training Loss: 0.1577586531639099, Validation Loss: 0.014374129474163055\n",
      "Epoch 79/100, Training Loss: 0.15505322813987732, Validation Loss: 0.014224906452000141\n",
      "Epoch 80/100, Training Loss: 0.1520129293203354, Validation Loss: 0.014095043763518333\n",
      "Epoch 81/100, Training Loss: 0.14999674260616302, Validation Loss: 0.014016004279255867\n",
      "Epoch 82/100, Training Loss: 0.14746446907520294, Validation Loss: 0.014002676121890545\n",
      "Epoch 83/100, Training Loss: 0.14704589545726776, Validation Loss: 0.01393324974924326\n",
      "Epoch 84/100, Training Loss: 0.14654535055160522, Validation Loss: 0.013890838250517845\n",
      "Epoch 85/100, Training Loss: 0.1446688324213028, Validation Loss: 0.013815290294587612\n",
      "Epoch 86/100, Training Loss: 0.1433858722448349, Validation Loss: 0.013768486678600311\n",
      "Epoch 87/100, Training Loss: 0.14163972437381744, Validation Loss: 0.013711772859096527\n",
      "Epoch 88/100, Training Loss: 0.1403825730085373, Validation Loss: 0.013631192035973072\n",
      "Epoch 89/100, Training Loss: 0.1386006474494934, Validation Loss: 0.013579887337982655\n",
      "Epoch 90/100, Training Loss: 0.13656817376613617, Validation Loss: 0.013489380478858948\n",
      "Epoch 91/100, Training Loss: 0.13603384792804718, Validation Loss: 0.013422970660030842\n",
      "Epoch 92/100, Training Loss: 0.13493762910366058, Validation Loss: 0.013354934751987457\n",
      "Epoch 93/100, Training Loss: 0.13236480951309204, Validation Loss: 0.013260746374726295\n",
      "Epoch 94/100, Training Loss: 0.13169404864311218, Validation Loss: 0.01320524699985981\n",
      "Epoch 95/100, Training Loss: 0.1301577389240265, Validation Loss: 0.013156099244952202\n",
      "Epoch 96/100, Training Loss: 0.13162082433700562, Validation Loss: 0.013070505112409592\n",
      "Epoch 97/100, Training Loss: 0.1278909295797348, Validation Loss: 0.012960193678736687\n",
      "Epoch 98/100, Training Loss: 0.12728509306907654, Validation Loss: 0.012830544263124466\n",
      "Epoch 99/100, Training Loss: 0.1259499341249466, Validation Loss: 0.012696832418441772\n",
      "Epoch 100/100, Training Loss: 0.12495733052492142, Validation Loss: 0.012604535557329655\n",
      "Fold 2 - R² Score: 0.9875, MAE: 0.0727\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 3.4547207355499268, Validation Loss: 1.1106830835342407\n",
      "Epoch 2/100, Training Loss: 2.7435801029205322, Validation Loss: 1.0071661472320557\n",
      "Epoch 3/100, Training Loss: 2.2769405841827393, Validation Loss: 0.9075455665588379\n",
      "Epoch 4/100, Training Loss: 1.8501096963882446, Validation Loss: 0.8146237730979919\n",
      "Epoch 5/100, Training Loss: 1.6160023212432861, Validation Loss: 0.7302592992782593\n",
      "Epoch 6/100, Training Loss: 1.3829426765441895, Validation Loss: 0.6557422280311584\n",
      "Epoch 7/100, Training Loss: 1.2404725551605225, Validation Loss: 0.5899844169616699\n",
      "Epoch 8/100, Training Loss: 1.1389740705490112, Validation Loss: 0.5317856669425964\n",
      "Epoch 9/100, Training Loss: 1.04608154296875, Validation Loss: 0.48184072971343994\n",
      "Epoch 10/100, Training Loss: 0.9725399613380432, Validation Loss: 0.43933001160621643\n",
      "Epoch 11/100, Training Loss: 0.9169145822525024, Validation Loss: 0.4039190411567688\n",
      "Epoch 12/100, Training Loss: 0.8897514939308167, Validation Loss: 0.37398868799209595\n",
      "Epoch 13/100, Training Loss: 0.8594388961791992, Validation Loss: 0.3485059142112732\n",
      "Epoch 14/100, Training Loss: 0.8321166634559631, Validation Loss: 0.32639920711517334\n",
      "Epoch 15/100, Training Loss: 0.806325376033783, Validation Loss: 0.30680397152900696\n",
      "Epoch 16/100, Training Loss: 0.763891875743866, Validation Loss: 0.28852322697639465\n",
      "Epoch 17/100, Training Loss: 0.7289705276489258, Validation Loss: 0.2714265286922455\n",
      "Epoch 18/100, Training Loss: 0.6951462626457214, Validation Loss: 0.2551049590110779\n",
      "Epoch 19/100, Training Loss: 0.6684494018554688, Validation Loss: 0.2392478585243225\n",
      "Epoch 20/100, Training Loss: 0.6411010026931763, Validation Loss: 0.22421512007713318\n",
      "Epoch 21/100, Training Loss: 0.6117001175880432, Validation Loss: 0.21008867025375366\n",
      "Epoch 22/100, Training Loss: 0.5858960747718811, Validation Loss: 0.19643515348434448\n",
      "Epoch 23/100, Training Loss: 0.5687854290008545, Validation Loss: 0.18335787951946259\n",
      "Epoch 24/100, Training Loss: 0.5431975722312927, Validation Loss: 0.1709425002336502\n",
      "Epoch 25/100, Training Loss: 0.5261233448982239, Validation Loss: 0.15945960581302643\n",
      "Epoch 26/100, Training Loss: 0.5095880627632141, Validation Loss: 0.14887988567352295\n",
      "Epoch 27/100, Training Loss: 0.485920786857605, Validation Loss: 0.13889288902282715\n",
      "Epoch 28/100, Training Loss: 0.4740462005138397, Validation Loss: 0.12936288118362427\n",
      "Epoch 29/100, Training Loss: 0.4641776382923126, Validation Loss: 0.1202818900346756\n",
      "Epoch 30/100, Training Loss: 0.4490932822227478, Validation Loss: 0.11123725771903992\n",
      "Epoch 31/100, Training Loss: 0.437948614358902, Validation Loss: 0.10290579497814178\n",
      "Epoch 32/100, Training Loss: 0.42229053378105164, Validation Loss: 0.09469584375619888\n",
      "Epoch 33/100, Training Loss: 0.4116048812866211, Validation Loss: 0.08653879165649414\n",
      "Epoch 34/100, Training Loss: 0.40543240308761597, Validation Loss: 0.07864405959844589\n",
      "Epoch 35/100, Training Loss: 0.3924162983894348, Validation Loss: 0.07129580527544022\n",
      "Epoch 36/100, Training Loss: 0.37890613079071045, Validation Loss: 0.06458336859941483\n",
      "Epoch 37/100, Training Loss: 0.37130194902420044, Validation Loss: 0.058439888060092926\n",
      "Epoch 38/100, Training Loss: 0.36204832792282104, Validation Loss: 0.052724141627550125\n",
      "Epoch 39/100, Training Loss: 0.3569695055484772, Validation Loss: 0.047378502786159515\n",
      "Epoch 40/100, Training Loss: 0.34540417790412903, Validation Loss: 0.04266653582453728\n",
      "Epoch 41/100, Training Loss: 0.33749690651893616, Validation Loss: 0.03824588283896446\n",
      "Epoch 42/100, Training Loss: 0.3305063843727112, Validation Loss: 0.03429830074310303\n",
      "Epoch 43/100, Training Loss: 0.3261732757091522, Validation Loss: 0.030839955434203148\n",
      "Epoch 44/100, Training Loss: 0.31622061133384705, Validation Loss: 0.027905400842428207\n",
      "Epoch 45/100, Training Loss: 0.30703046917915344, Validation Loss: 0.025382742285728455\n",
      "Epoch 46/100, Training Loss: 0.30345723032951355, Validation Loss: 0.023203372955322266\n",
      "Epoch 47/100, Training Loss: 0.2958928942680359, Validation Loss: 0.021417181938886642\n",
      "Epoch 48/100, Training Loss: 0.2899208664894104, Validation Loss: 0.019921589642763138\n",
      "Epoch 49/100, Training Loss: 0.2844923138618469, Validation Loss: 0.018736712634563446\n",
      "Epoch 50/100, Training Loss: 0.2772500216960907, Validation Loss: 0.017702214419841766\n",
      "Epoch 51/100, Training Loss: 0.2758615016937256, Validation Loss: 0.016861937940120697\n",
      "Epoch 52/100, Training Loss: 0.2688859701156616, Validation Loss: 0.01618115045130253\n",
      "Epoch 53/100, Training Loss: 0.2642408609390259, Validation Loss: 0.015592841431498528\n",
      "Epoch 54/100, Training Loss: 0.2553538382053375, Validation Loss: 0.01509882602840662\n",
      "Epoch 55/100, Training Loss: 0.25447189807891846, Validation Loss: 0.014743275009095669\n",
      "Epoch 56/100, Training Loss: 0.24781838059425354, Validation Loss: 0.01439735572785139\n",
      "Epoch 57/100, Training Loss: 0.24471604824066162, Validation Loss: 0.014066976495087147\n",
      "Epoch 58/100, Training Loss: 0.241399884223938, Validation Loss: 0.01379906665533781\n",
      "Epoch 59/100, Training Loss: 0.23605941236019135, Validation Loss: 0.01356700249016285\n",
      "Epoch 60/100, Training Loss: 0.23134873807430267, Validation Loss: 0.013371544890105724\n",
      "Epoch 61/100, Training Loss: 0.22668613493442535, Validation Loss: 0.013165108859539032\n",
      "Epoch 62/100, Training Loss: 0.22421739995479584, Validation Loss: 0.012967783957719803\n",
      "Epoch 63/100, Training Loss: 0.2234789878129959, Validation Loss: 0.012753743678331375\n",
      "Epoch 64/100, Training Loss: 0.2182197868824005, Validation Loss: 0.012517687864601612\n",
      "Epoch 65/100, Training Loss: 0.21259309351444244, Validation Loss: 0.01228476595133543\n",
      "Epoch 66/100, Training Loss: 0.2092629373073578, Validation Loss: 0.01205931231379509\n",
      "Epoch 67/100, Training Loss: 0.2086845338344574, Validation Loss: 0.011834797449409962\n",
      "Epoch 68/100, Training Loss: 0.20405925810337067, Validation Loss: 0.011595897376537323\n",
      "Epoch 69/100, Training Loss: 0.20113293826580048, Validation Loss: 0.011398778297007084\n",
      "Epoch 70/100, Training Loss: 0.19922050833702087, Validation Loss: 0.011185399256646633\n",
      "Epoch 71/100, Training Loss: 0.19399477541446686, Validation Loss: 0.011046514846384525\n",
      "Epoch 72/100, Training Loss: 0.19222816824913025, Validation Loss: 0.010887072421610355\n",
      "Epoch 73/100, Training Loss: 0.1899895966053009, Validation Loss: 0.010764597915112972\n",
      "Epoch 74/100, Training Loss: 0.1868678778409958, Validation Loss: 0.010717167519032955\n",
      "Epoch 75/100, Training Loss: 0.18433193862438202, Validation Loss: 0.010630766861140728\n",
      "Epoch 76/100, Training Loss: 0.18135055899620056, Validation Loss: 0.010589169338345528\n",
      "Epoch 77/100, Training Loss: 0.18072813749313354, Validation Loss: 0.01055682823061943\n",
      "Epoch 78/100, Training Loss: 0.17499475181102753, Validation Loss: 0.010530473664402962\n",
      "Epoch 79/100, Training Loss: 0.17354197800159454, Validation Loss: 0.010505486279726028\n",
      "Epoch 80/100, Training Loss: 0.17265373468399048, Validation Loss: 0.010460726916790009\n",
      "Epoch 81/100, Training Loss: 0.17012351751327515, Validation Loss: 0.010399062186479568\n",
      "Epoch 82/100, Training Loss: 0.16728772222995758, Validation Loss: 0.01036735437810421\n",
      "Epoch 83/100, Training Loss: 0.16535484790802002, Validation Loss: 0.010319353081285954\n",
      "Epoch 84/100, Training Loss: 0.1643092781305313, Validation Loss: 0.010317141190171242\n",
      "Epoch 85/100, Training Loss: 0.16156955063343048, Validation Loss: 0.010338355787098408\n",
      "Epoch 86/100, Training Loss: 0.15961554646492004, Validation Loss: 0.010386618785560131\n",
      "Epoch 87/100, Training Loss: 0.15844084322452545, Validation Loss: 0.010394576005637646\n",
      "Epoch 88/100, Training Loss: 0.15632586181163788, Validation Loss: 0.010424217209219933\n",
      "Epoch 89/100, Training Loss: 0.15577332675457, Validation Loss: 0.010405546985566616\n",
      "Epoch 90/100, Training Loss: 0.15357621014118195, Validation Loss: 0.01040338072925806\n",
      "Epoch 91/100, Training Loss: 0.1521802395582199, Validation Loss: 0.010400606319308281\n",
      "Epoch 92/100, Training Loss: 0.14959067106246948, Validation Loss: 0.010343477129936218\n",
      "Epoch 93/100, Training Loss: 0.14830735325813293, Validation Loss: 0.010276127606630325\n",
      "Epoch 94/100, Training Loss: 0.1480637937784195, Validation Loss: 0.01023764256387949\n",
      "Epoch 95/100, Training Loss: 0.14526250958442688, Validation Loss: 0.01019853912293911\n",
      "Epoch 96/100, Training Loss: 0.14450949430465698, Validation Loss: 0.010173389688134193\n",
      "Epoch 97/100, Training Loss: 0.142155721783638, Validation Loss: 0.010171196423470974\n",
      "Epoch 98/100, Training Loss: 0.14161038398742676, Validation Loss: 0.01016833633184433\n",
      "Epoch 99/100, Training Loss: 0.13833269476890564, Validation Loss: 0.010147936642169952\n",
      "Epoch 100/100, Training Loss: 0.13669614493846893, Validation Loss: 0.01014892477542162\n",
      "Fold 3 - R² Score: 0.9898, MAE: 0.0685\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 3.164170980453491, Validation Loss: 0.9701687693595886\n",
      "Epoch 2/100, Training Loss: 2.5216596126556396, Validation Loss: 0.8770849108695984\n",
      "Epoch 3/100, Training Loss: 2.0427913665771484, Validation Loss: 0.7902477383613586\n",
      "Epoch 4/100, Training Loss: 1.7000914812088013, Validation Loss: 0.7113545536994934\n",
      "Epoch 5/100, Training Loss: 1.506611704826355, Validation Loss: 0.6422677040100098\n",
      "Epoch 6/100, Training Loss: 1.333278775215149, Validation Loss: 0.5821053385734558\n",
      "Epoch 7/100, Training Loss: 1.2446187734603882, Validation Loss: 0.5308893918991089\n",
      "Epoch 8/100, Training Loss: 1.1487337350845337, Validation Loss: 0.4886501729488373\n",
      "Epoch 9/100, Training Loss: 1.0948171615600586, Validation Loss: 0.45415928959846497\n",
      "Epoch 10/100, Training Loss: 1.0525245666503906, Validation Loss: 0.42522069811820984\n",
      "Epoch 11/100, Training Loss: 0.9803187251091003, Validation Loss: 0.4007250964641571\n",
      "Epoch 12/100, Training Loss: 0.9360457062721252, Validation Loss: 0.37946978211402893\n",
      "Epoch 13/100, Training Loss: 0.8831810355186462, Validation Loss: 0.360514760017395\n",
      "Epoch 14/100, Training Loss: 0.8390676379203796, Validation Loss: 0.3429214060306549\n",
      "Epoch 15/100, Training Loss: 0.7896986603736877, Validation Loss: 0.32566380500793457\n",
      "Epoch 16/100, Training Loss: 0.7547176480293274, Validation Loss: 0.3086428940296173\n",
      "Epoch 17/100, Training Loss: 0.7192133069038391, Validation Loss: 0.29127949476242065\n",
      "Epoch 18/100, Training Loss: 0.6879402995109558, Validation Loss: 0.27411624789237976\n",
      "Epoch 19/100, Training Loss: 0.6535223126411438, Validation Loss: 0.25706785917282104\n",
      "Epoch 20/100, Training Loss: 0.6340410709381104, Validation Loss: 0.24087494611740112\n",
      "Epoch 21/100, Training Loss: 0.6046813726425171, Validation Loss: 0.22513514757156372\n",
      "Epoch 22/100, Training Loss: 0.5937079191207886, Validation Loss: 0.20980551838874817\n",
      "Epoch 23/100, Training Loss: 0.5704385638237, Validation Loss: 0.1947355419397354\n",
      "Epoch 24/100, Training Loss: 0.5448678135871887, Validation Loss: 0.17987419664859772\n",
      "Epoch 25/100, Training Loss: 0.5320046544075012, Validation Loss: 0.16555173695087433\n",
      "Epoch 26/100, Training Loss: 0.5077913403511047, Validation Loss: 0.15189027786254883\n",
      "Epoch 27/100, Training Loss: 0.4925524592399597, Validation Loss: 0.13926894962787628\n",
      "Epoch 28/100, Training Loss: 0.4805789589881897, Validation Loss: 0.12739959359169006\n",
      "Epoch 29/100, Training Loss: 0.4679708480834961, Validation Loss: 0.11600361764431\n",
      "Epoch 30/100, Training Loss: 0.4487147033214569, Validation Loss: 0.10572647303342819\n",
      "Epoch 31/100, Training Loss: 0.4367712438106537, Validation Loss: 0.0959898829460144\n",
      "Epoch 32/100, Training Loss: 0.4231770932674408, Validation Loss: 0.08723467588424683\n",
      "Epoch 33/100, Training Loss: 0.4094095528125763, Validation Loss: 0.07916126400232315\n",
      "Epoch 34/100, Training Loss: 0.3982880413532257, Validation Loss: 0.07205986976623535\n",
      "Epoch 35/100, Training Loss: 0.3832107484340668, Validation Loss: 0.06566211581230164\n",
      "Epoch 36/100, Training Loss: 0.37792518734931946, Validation Loss: 0.060198742896318436\n",
      "Epoch 37/100, Training Loss: 0.3563474416732788, Validation Loss: 0.055196795612573624\n",
      "Epoch 38/100, Training Loss: 0.3574540615081787, Validation Loss: 0.050852756947278976\n",
      "Epoch 39/100, Training Loss: 0.343938410282135, Validation Loss: 0.04693376645445824\n",
      "Epoch 40/100, Training Loss: 0.33932849764823914, Validation Loss: 0.04327811673283577\n",
      "Epoch 41/100, Training Loss: 0.3285398483276367, Validation Loss: 0.040060870349407196\n",
      "Epoch 42/100, Training Loss: 0.32198309898376465, Validation Loss: 0.03689970448613167\n",
      "Epoch 43/100, Training Loss: 0.31977829337120056, Validation Loss: 0.03399286046624184\n",
      "Epoch 44/100, Training Loss: 0.30695292353630066, Validation Loss: 0.031349293887615204\n",
      "Epoch 45/100, Training Loss: 0.2976497709751129, Validation Loss: 0.028904719278216362\n",
      "Epoch 46/100, Training Loss: 0.2912134528160095, Validation Loss: 0.02674764022231102\n",
      "Epoch 47/100, Training Loss: 0.2876562178134918, Validation Loss: 0.024733860045671463\n",
      "Epoch 48/100, Training Loss: 0.28164955973625183, Validation Loss: 0.022904202342033386\n",
      "Epoch 49/100, Training Loss: 0.2725283205509186, Validation Loss: 0.02127252332866192\n",
      "Epoch 50/100, Training Loss: 0.265878289937973, Validation Loss: 0.01977703906595707\n",
      "Epoch 51/100, Training Loss: 0.2615034580230713, Validation Loss: 0.018530914559960365\n",
      "Epoch 52/100, Training Loss: 0.2550940215587616, Validation Loss: 0.01750274933874607\n",
      "Epoch 53/100, Training Loss: 0.24974608421325684, Validation Loss: 0.016549503430724144\n",
      "Epoch 54/100, Training Loss: 0.2463422566652298, Validation Loss: 0.015716353431344032\n",
      "Epoch 55/100, Training Loss: 0.24210487306118011, Validation Loss: 0.015029985457658768\n",
      "Epoch 56/100, Training Loss: 0.23593561351299286, Validation Loss: 0.014448313042521477\n",
      "Epoch 57/100, Training Loss: 0.22878782451152802, Validation Loss: 0.013964233919978142\n",
      "Epoch 58/100, Training Loss: 0.23006179928779602, Validation Loss: 0.013475959189236164\n",
      "Epoch 59/100, Training Loss: 0.22109286487102509, Validation Loss: 0.013058955781161785\n",
      "Epoch 60/100, Training Loss: 0.22068913280963898, Validation Loss: 0.012739816680550575\n",
      "Epoch 61/100, Training Loss: 0.21677391231060028, Validation Loss: 0.012475120835006237\n",
      "Epoch 62/100, Training Loss: 0.21093161404132843, Validation Loss: 0.012279653921723366\n",
      "Epoch 63/100, Training Loss: 0.2060367465019226, Validation Loss: 0.012113776989281178\n",
      "Epoch 64/100, Training Loss: 0.20305027067661285, Validation Loss: 0.012056203559041023\n",
      "Epoch 65/100, Training Loss: 0.19911441206932068, Validation Loss: 0.01200730912387371\n",
      "Epoch 66/100, Training Loss: 0.19735713303089142, Validation Loss: 0.011985976248979568\n",
      "Epoch 67/100, Training Loss: 0.1927146017551422, Validation Loss: 0.011971923522651196\n",
      "Epoch 68/100, Training Loss: 0.18936598300933838, Validation Loss: 0.011990993283689022\n",
      "Epoch 69/100, Training Loss: 0.18529348075389862, Validation Loss: 0.011997930705547333\n",
      "Epoch 70/100, Training Loss: 0.18506601452827454, Validation Loss: 0.012045965529978275\n",
      "Epoch 71/100, Training Loss: 0.18185076117515564, Validation Loss: 0.01207983773201704\n",
      "Epoch 72/100, Training Loss: 0.18018893897533417, Validation Loss: 0.012058695778250694\n",
      "Epoch 73/100, Training Loss: 0.17607229948043823, Validation Loss: 0.01208586897701025\n",
      "Epoch 74/100, Training Loss: 0.17406819760799408, Validation Loss: 0.012102640233933926\n",
      "Epoch 75/100, Training Loss: 0.17157213389873505, Validation Loss: 0.012080961838364601\n",
      "Epoch 76/100, Training Loss: 0.17011620104312897, Validation Loss: 0.012054583057761192\n",
      "Epoch 77/100, Training Loss: 0.1645829677581787, Validation Loss: 0.011993926018476486\n",
      "Early stopping triggered\n",
      "Fold 4 - R² Score: 0.9880, MAE: 0.0747\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 3.412576675415039, Validation Loss: 0.9581618905067444\n",
      "Epoch 2/100, Training Loss: 2.57535982131958, Validation Loss: 0.8711211681365967\n",
      "Epoch 3/100, Training Loss: 2.0654654502868652, Validation Loss: 0.7817146182060242\n",
      "Epoch 4/100, Training Loss: 1.7168896198272705, Validation Loss: 0.6924670934677124\n",
      "Epoch 5/100, Training Loss: 1.504075288772583, Validation Loss: 0.6090397238731384\n",
      "Epoch 6/100, Training Loss: 1.3374791145324707, Validation Loss: 0.5372995138168335\n",
      "Epoch 7/100, Training Loss: 1.2336013317108154, Validation Loss: 0.4780421853065491\n",
      "Epoch 8/100, Training Loss: 1.1353535652160645, Validation Loss: 0.43029630184173584\n",
      "Epoch 9/100, Training Loss: 1.063348412513733, Validation Loss: 0.3929874002933502\n",
      "Epoch 10/100, Training Loss: 0.9911817908287048, Validation Loss: 0.3632878363132477\n",
      "Epoch 11/100, Training Loss: 0.922116219997406, Validation Loss: 0.3393895626068115\n",
      "Epoch 12/100, Training Loss: 0.8752461671829224, Validation Loss: 0.319527268409729\n",
      "Epoch 13/100, Training Loss: 0.8122876286506653, Validation Loss: 0.30249089002609253\n",
      "Epoch 14/100, Training Loss: 0.7765308022499084, Validation Loss: 0.28734052181243896\n",
      "Epoch 15/100, Training Loss: 0.7303251624107361, Validation Loss: 0.27231577038764954\n",
      "Epoch 16/100, Training Loss: 0.689681351184845, Validation Loss: 0.2570188045501709\n",
      "Epoch 17/100, Training Loss: 0.6423726081848145, Validation Loss: 0.24131658673286438\n",
      "Epoch 18/100, Training Loss: 0.6169713139533997, Validation Loss: 0.22501496970653534\n",
      "Epoch 19/100, Training Loss: 0.5880207419395447, Validation Loss: 0.20852436125278473\n",
      "Epoch 20/100, Training Loss: 0.5640147924423218, Validation Loss: 0.19230972230434418\n",
      "Epoch 21/100, Training Loss: 0.5391252040863037, Validation Loss: 0.1769305318593979\n",
      "Epoch 22/100, Training Loss: 0.5136989951133728, Validation Loss: 0.16244713962078094\n",
      "Epoch 23/100, Training Loss: 0.49628350138664246, Validation Loss: 0.14908984303474426\n",
      "Epoch 24/100, Training Loss: 0.474266916513443, Validation Loss: 0.13679413497447968\n",
      "Epoch 25/100, Training Loss: 0.45768484473228455, Validation Loss: 0.12574496865272522\n",
      "Epoch 26/100, Training Loss: 0.4409545958042145, Validation Loss: 0.11567137390375137\n",
      "Epoch 27/100, Training Loss: 0.432496577501297, Validation Loss: 0.1064714640378952\n",
      "Epoch 28/100, Training Loss: 0.41763657331466675, Validation Loss: 0.09826672822237015\n",
      "Epoch 29/100, Training Loss: 0.40780147910118103, Validation Loss: 0.09071575850248337\n",
      "Epoch 30/100, Training Loss: 0.39091625809669495, Validation Loss: 0.08405935764312744\n",
      "Epoch 31/100, Training Loss: 0.37563151121139526, Validation Loss: 0.07809405028820038\n",
      "Epoch 32/100, Training Loss: 0.36581870913505554, Validation Loss: 0.07285904139280319\n",
      "Epoch 33/100, Training Loss: 0.35724082589149475, Validation Loss: 0.06797272711992264\n",
      "Epoch 34/100, Training Loss: 0.34095069766044617, Validation Loss: 0.06384564191102982\n",
      "Epoch 35/100, Training Loss: 0.3349763751029968, Validation Loss: 0.06012639030814171\n",
      "Epoch 36/100, Training Loss: 0.3236881494522095, Validation Loss: 0.05677121877670288\n",
      "Epoch 37/100, Training Loss: 0.31828823685646057, Validation Loss: 0.05367724969983101\n",
      "Epoch 38/100, Training Loss: 0.3071097433567047, Validation Loss: 0.050853099673986435\n",
      "Epoch 39/100, Training Loss: 0.3029075860977173, Validation Loss: 0.04816901683807373\n",
      "Epoch 40/100, Training Loss: 0.2956017553806305, Validation Loss: 0.04572008177638054\n",
      "Epoch 41/100, Training Loss: 0.28905463218688965, Validation Loss: 0.04329962655901909\n",
      "Epoch 42/100, Training Loss: 0.27950790524482727, Validation Loss: 0.04090909659862518\n",
      "Epoch 43/100, Training Loss: 0.2734600007534027, Validation Loss: 0.03871579095721245\n",
      "Epoch 44/100, Training Loss: 0.269363135099411, Validation Loss: 0.03671775758266449\n",
      "Epoch 45/100, Training Loss: 0.2584401071071625, Validation Loss: 0.034854594618082047\n",
      "Epoch 46/100, Training Loss: 0.25814059376716614, Validation Loss: 0.03316064551472664\n",
      "Epoch 47/100, Training Loss: 0.25104185938835144, Validation Loss: 0.03168216347694397\n",
      "Epoch 48/100, Training Loss: 0.2468235343694687, Validation Loss: 0.030332649126648903\n",
      "Epoch 49/100, Training Loss: 0.24226872622966766, Validation Loss: 0.02917896769940853\n",
      "Epoch 50/100, Training Loss: 0.2403528392314911, Validation Loss: 0.028166241943836212\n",
      "Epoch 51/100, Training Loss: 0.2342233657836914, Validation Loss: 0.02727527730166912\n",
      "Epoch 52/100, Training Loss: 0.22667405009269714, Validation Loss: 0.02654215507209301\n",
      "Epoch 53/100, Training Loss: 0.22528599202632904, Validation Loss: 0.025890955701470375\n",
      "Epoch 54/100, Training Loss: 0.2229204773902893, Validation Loss: 0.025275209918618202\n",
      "Epoch 55/100, Training Loss: 0.21567802131175995, Validation Loss: 0.024731900542974472\n",
      "Epoch 56/100, Training Loss: 0.2110530436038971, Validation Loss: 0.0241866372525692\n",
      "Epoch 57/100, Training Loss: 0.21075832843780518, Validation Loss: 0.02368857152760029\n",
      "Epoch 58/100, Training Loss: 0.20505623519420624, Validation Loss: 0.023190094158053398\n",
      "Epoch 59/100, Training Loss: 0.20412082970142365, Validation Loss: 0.022730041295289993\n",
      "Epoch 60/100, Training Loss: 0.19907157123088837, Validation Loss: 0.022255918011069298\n",
      "Epoch 61/100, Training Loss: 0.19635258615016937, Validation Loss: 0.02175583504140377\n",
      "Epoch 62/100, Training Loss: 0.19341333210468292, Validation Loss: 0.02136417105793953\n",
      "Epoch 63/100, Training Loss: 0.18981029093265533, Validation Loss: 0.02100362628698349\n",
      "Epoch 64/100, Training Loss: 0.18682833015918732, Validation Loss: 0.020694201812148094\n",
      "Epoch 65/100, Training Loss: 0.18523240089416504, Validation Loss: 0.020404549315571785\n",
      "Epoch 66/100, Training Loss: 0.17862261831760406, Validation Loss: 0.020166773349046707\n",
      "Epoch 67/100, Training Loss: 0.17778702080249786, Validation Loss: 0.019924895837903023\n",
      "Epoch 68/100, Training Loss: 0.1783204972743988, Validation Loss: 0.01969599351286888\n",
      "Epoch 69/100, Training Loss: 0.17435815930366516, Validation Loss: 0.01947433315217495\n",
      "Epoch 70/100, Training Loss: 0.1725706309080124, Validation Loss: 0.019197748973965645\n",
      "Epoch 71/100, Training Loss: 0.1683056503534317, Validation Loss: 0.018985290080308914\n",
      "Epoch 72/100, Training Loss: 0.16645923256874084, Validation Loss: 0.018793046474456787\n",
      "Epoch 73/100, Training Loss: 0.16418249905109406, Validation Loss: 0.018560348078608513\n",
      "Epoch 74/100, Training Loss: 0.16202908754348755, Validation Loss: 0.018475467339158058\n",
      "Epoch 75/100, Training Loss: 0.16199974715709686, Validation Loss: 0.01831112988293171\n",
      "Epoch 76/100, Training Loss: 0.15865765511989594, Validation Loss: 0.018124807626008987\n",
      "Epoch 77/100, Training Loss: 0.1570027768611908, Validation Loss: 0.017946626991033554\n",
      "Epoch 78/100, Training Loss: 0.15569128096103668, Validation Loss: 0.017810475081205368\n",
      "Epoch 79/100, Training Loss: 0.15422436594963074, Validation Loss: 0.017682593315839767\n",
      "Epoch 80/100, Training Loss: 0.15135978162288666, Validation Loss: 0.017634576186537743\n",
      "Epoch 81/100, Training Loss: 0.1501929759979248, Validation Loss: 0.017561936751008034\n",
      "Epoch 82/100, Training Loss: 0.14851295948028564, Validation Loss: 0.017497790977358818\n",
      "Epoch 83/100, Training Loss: 0.14734987914562225, Validation Loss: 0.01749502867460251\n",
      "Epoch 84/100, Training Loss: 0.14667150378227234, Validation Loss: 0.017398757860064507\n",
      "Epoch 85/100, Training Loss: 0.143203005194664, Validation Loss: 0.017341723665595055\n",
      "Epoch 86/100, Training Loss: 0.14063549041748047, Validation Loss: 0.017293518409132957\n",
      "Epoch 87/100, Training Loss: 0.14185898005962372, Validation Loss: 0.017247449606657028\n",
      "Epoch 88/100, Training Loss: 0.13906227052211761, Validation Loss: 0.017235519364476204\n",
      "Epoch 89/100, Training Loss: 0.13901259005069733, Validation Loss: 0.017133371904492378\n",
      "Epoch 90/100, Training Loss: 0.1375700980424881, Validation Loss: 0.017066366970539093\n",
      "Epoch 91/100, Training Loss: 0.13766275346279144, Validation Loss: 0.01697421818971634\n",
      "Epoch 92/100, Training Loss: 0.1352134495973587, Validation Loss: 0.0168700460344553\n",
      "Epoch 93/100, Training Loss: 0.13402098417282104, Validation Loss: 0.016765166074037552\n",
      "Epoch 94/100, Training Loss: 0.13430321216583252, Validation Loss: 0.016650035977363586\n",
      "Epoch 95/100, Training Loss: 0.1312418282032013, Validation Loss: 0.01658475212752819\n",
      "Epoch 96/100, Training Loss: 0.12964460253715515, Validation Loss: 0.016492227092385292\n",
      "Epoch 97/100, Training Loss: 0.12873528897762299, Validation Loss: 0.016402272507548332\n",
      "Epoch 98/100, Training Loss: 0.12707528471946716, Validation Loss: 0.016383184120059013\n",
      "Epoch 99/100, Training Loss: 0.1260054111480713, Validation Loss: 0.016324566677212715\n",
      "Epoch 100/100, Training Loss: 0.1255318969488144, Validation Loss: 0.016224771738052368\n",
      "Fold 5 - R² Score: 0.9838, MAE: 0.0791\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 32, 'learning_rate': 0.01}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.333221673965454, Validation Loss: 0.8465275168418884\n",
      "Epoch 2/100, Training Loss: 1.997545838356018, Validation Loss: 0.7294530868530273\n",
      "Epoch 3/100, Training Loss: 1.3477389812469482, Validation Loss: 0.6311634182929993\n",
      "Epoch 4/100, Training Loss: 1.0977482795715332, Validation Loss: 0.5577457547187805\n",
      "Epoch 5/100, Training Loss: 0.9973425269126892, Validation Loss: 0.5084230303764343\n",
      "Epoch 6/100, Training Loss: 0.9185951948165894, Validation Loss: 0.48137393593788147\n",
      "Epoch 7/100, Training Loss: 0.8445261716842651, Validation Loss: 0.4703628122806549\n",
      "Epoch 8/100, Training Loss: 0.748938798904419, Validation Loss: 0.4693855941295624\n",
      "Epoch 9/100, Training Loss: 0.666137158870697, Validation Loss: 0.4735182225704193\n",
      "Epoch 10/100, Training Loss: 0.598953366279602, Validation Loss: 0.4786120057106018\n",
      "Epoch 11/100, Training Loss: 0.5564380288124084, Validation Loss: 0.48172610998153687\n",
      "Epoch 12/100, Training Loss: 0.5103806257247925, Validation Loss: 0.4802839756011963\n",
      "Epoch 13/100, Training Loss: 0.4649622440338135, Validation Loss: 0.4722965657711029\n",
      "Epoch 14/100, Training Loss: 0.44205808639526367, Validation Loss: 0.45752832293510437\n",
      "Epoch 15/100, Training Loss: 0.41627222299575806, Validation Loss: 0.43679147958755493\n",
      "Epoch 16/100, Training Loss: 0.3913194239139557, Validation Loss: 0.41032299399375916\n",
      "Epoch 17/100, Training Loss: 0.3768281042575836, Validation Loss: 0.3795055150985718\n",
      "Epoch 18/100, Training Loss: 0.35298606753349304, Validation Loss: 0.3457910418510437\n",
      "Epoch 19/100, Training Loss: 0.33205512166023254, Validation Loss: 0.31104955077171326\n",
      "Epoch 20/100, Training Loss: 0.3092916011810303, Validation Loss: 0.2765507996082306\n",
      "Epoch 21/100, Training Loss: 0.29861873388290405, Validation Loss: 0.24369506537914276\n",
      "Epoch 22/100, Training Loss: 0.2797313332557678, Validation Loss: 0.21345804631710052\n",
      "Epoch 23/100, Training Loss: 0.269674152135849, Validation Loss: 0.18622182309627533\n",
      "Epoch 24/100, Training Loss: 0.260970801115036, Validation Loss: 0.16265438497066498\n",
      "Epoch 25/100, Training Loss: 0.24784094095230103, Validation Loss: 0.14234338700771332\n",
      "Epoch 26/100, Training Loss: 0.2394344061613083, Validation Loss: 0.12540853023529053\n",
      "Epoch 27/100, Training Loss: 0.23138564825057983, Validation Loss: 0.11130820214748383\n",
      "Epoch 28/100, Training Loss: 0.21747854351997375, Validation Loss: 0.0998569205403328\n",
      "Epoch 29/100, Training Loss: 0.2141951024532318, Validation Loss: 0.09040166437625885\n",
      "Epoch 30/100, Training Loss: 0.20257064700126648, Validation Loss: 0.08272742480039597\n",
      "Epoch 31/100, Training Loss: 0.19795113801956177, Validation Loss: 0.07626105844974518\n",
      "Epoch 32/100, Training Loss: 0.19151000678539276, Validation Loss: 0.0707048699259758\n",
      "Epoch 33/100, Training Loss: 0.18540386855602264, Validation Loss: 0.06577147543430328\n",
      "Epoch 34/100, Training Loss: 0.18309156596660614, Validation Loss: 0.06112365797162056\n",
      "Epoch 35/100, Training Loss: 0.17625659704208374, Validation Loss: 0.056690748780965805\n",
      "Epoch 36/100, Training Loss: 0.17196395993232727, Validation Loss: 0.052214376628398895\n",
      "Epoch 37/100, Training Loss: 0.16790328919887543, Validation Loss: 0.04792075976729393\n",
      "Epoch 38/100, Training Loss: 0.16347496211528778, Validation Loss: 0.04374472051858902\n",
      "Epoch 39/100, Training Loss: 0.1597919911146164, Validation Loss: 0.03983908146619797\n",
      "Epoch 40/100, Training Loss: 0.1563883125782013, Validation Loss: 0.03628852590918541\n",
      "Epoch 41/100, Training Loss: 0.15308751165866852, Validation Loss: 0.033204756677150726\n",
      "Epoch 42/100, Training Loss: 0.1503472626209259, Validation Loss: 0.030574599280953407\n",
      "Epoch 43/100, Training Loss: 0.149316668510437, Validation Loss: 0.02844170480966568\n",
      "Epoch 44/100, Training Loss: 0.14539629220962524, Validation Loss: 0.026768771931529045\n",
      "Epoch 45/100, Training Loss: 0.14351607859134674, Validation Loss: 0.0253992211073637\n",
      "Epoch 46/100, Training Loss: 0.1401175707578659, Validation Loss: 0.02434089407324791\n",
      "Epoch 47/100, Training Loss: 0.1362057328224182, Validation Loss: 0.02355494722723961\n",
      "Epoch 48/100, Training Loss: 0.1358902007341385, Validation Loss: 0.02296908013522625\n",
      "Epoch 49/100, Training Loss: 0.13428184390068054, Validation Loss: 0.022600654512643814\n",
      "Epoch 50/100, Training Loss: 0.13186155259609222, Validation Loss: 0.022250408306717873\n",
      "Epoch 51/100, Training Loss: 0.13024216890335083, Validation Loss: 0.021937547251582146\n",
      "Epoch 52/100, Training Loss: 0.12657000124454498, Validation Loss: 0.02170827053487301\n",
      "Epoch 53/100, Training Loss: 0.1259375363588333, Validation Loss: 0.021426323801279068\n",
      "Epoch 54/100, Training Loss: 0.12595653533935547, Validation Loss: 0.021087849512696266\n",
      "Epoch 55/100, Training Loss: 0.12388397753238678, Validation Loss: 0.020705299451947212\n",
      "Epoch 56/100, Training Loss: 0.12198477238416672, Validation Loss: 0.020333385095000267\n",
      "Epoch 57/100, Training Loss: 0.12001132220029831, Validation Loss: 0.0198710598051548\n",
      "Epoch 58/100, Training Loss: 0.11928402632474899, Validation Loss: 0.019402606412768364\n",
      "Epoch 59/100, Training Loss: 0.1163477748632431, Validation Loss: 0.018885480239987373\n",
      "Epoch 60/100, Training Loss: 0.11687401682138443, Validation Loss: 0.01839623600244522\n",
      "Epoch 61/100, Training Loss: 0.11765540391206741, Validation Loss: 0.017942748963832855\n",
      "Epoch 62/100, Training Loss: 0.11546975374221802, Validation Loss: 0.017512066289782524\n",
      "Epoch 63/100, Training Loss: 0.11441903561353683, Validation Loss: 0.01711347885429859\n",
      "Epoch 64/100, Training Loss: 0.11309756338596344, Validation Loss: 0.016796953976154327\n",
      "Epoch 65/100, Training Loss: 0.1122719794511795, Validation Loss: 0.016489757224917412\n",
      "Epoch 66/100, Training Loss: 0.11204731464385986, Validation Loss: 0.016259636729955673\n",
      "Epoch 67/100, Training Loss: 0.1121567115187645, Validation Loss: 0.01608215644955635\n",
      "Epoch 68/100, Training Loss: 0.10923224687576294, Validation Loss: 0.015969907864928246\n",
      "Epoch 69/100, Training Loss: 0.11010599136352539, Validation Loss: 0.015935823321342468\n",
      "Epoch 70/100, Training Loss: 0.10784010589122772, Validation Loss: 0.01595293916761875\n",
      "Epoch 71/100, Training Loss: 0.10737519711256027, Validation Loss: 0.01596582494676113\n",
      "Epoch 72/100, Training Loss: 0.10898905992507935, Validation Loss: 0.01600167155265808\n",
      "Epoch 73/100, Training Loss: 0.10709226131439209, Validation Loss: 0.016036346554756165\n",
      "Epoch 74/100, Training Loss: 0.1052018404006958, Validation Loss: 0.016055189073085785\n",
      "Epoch 75/100, Training Loss: 0.10546001046895981, Validation Loss: 0.016082772985100746\n",
      "Epoch 76/100, Training Loss: 0.10406959801912308, Validation Loss: 0.016056938096880913\n",
      "Epoch 77/100, Training Loss: 0.10406195372343063, Validation Loss: 0.016028879210352898\n",
      "Epoch 78/100, Training Loss: 0.10506779700517654, Validation Loss: 0.01594577170908451\n",
      "Epoch 79/100, Training Loss: 0.10317013412714005, Validation Loss: 0.015902113169431686\n",
      "Epoch 80/100, Training Loss: 0.10285830497741699, Validation Loss: 0.01588847115635872\n",
      "Epoch 81/100, Training Loss: 0.10302545130252838, Validation Loss: 0.015817640349268913\n",
      "Epoch 82/100, Training Loss: 0.1031966581940651, Validation Loss: 0.015656979754567146\n",
      "Epoch 83/100, Training Loss: 0.102161705493927, Validation Loss: 0.015563803724944592\n",
      "Epoch 84/100, Training Loss: 0.10065483301877975, Validation Loss: 0.015430512838065624\n",
      "Epoch 85/100, Training Loss: 0.10091620683670044, Validation Loss: 0.015265922993421555\n",
      "Epoch 86/100, Training Loss: 0.10000183433294296, Validation Loss: 0.015152526088058949\n",
      "Epoch 87/100, Training Loss: 0.10068260133266449, Validation Loss: 0.015017734840512276\n",
      "Epoch 88/100, Training Loss: 0.10151547193527222, Validation Loss: 0.014842105098068714\n",
      "Epoch 89/100, Training Loss: 0.09941332042217255, Validation Loss: 0.01475259754806757\n",
      "Epoch 90/100, Training Loss: 0.09895153343677521, Validation Loss: 0.014609389007091522\n",
      "Epoch 91/100, Training Loss: 0.098617784678936, Validation Loss: 0.014548423700034618\n",
      "Epoch 92/100, Training Loss: 0.09712449461221695, Validation Loss: 0.014496276155114174\n",
      "Epoch 93/100, Training Loss: 0.09737516939640045, Validation Loss: 0.014448891393840313\n",
      "Epoch 94/100, Training Loss: 0.09674286842346191, Validation Loss: 0.014407594688236713\n",
      "Epoch 95/100, Training Loss: 0.09724800288677216, Validation Loss: 0.014387807808816433\n",
      "Epoch 96/100, Training Loss: 0.09774278104305267, Validation Loss: 0.014321882277727127\n",
      "Epoch 97/100, Training Loss: 0.09706688672304153, Validation Loss: 0.014263571240007877\n",
      "Epoch 98/100, Training Loss: 0.0960562527179718, Validation Loss: 0.014276484958827496\n",
      "Epoch 99/100, Training Loss: 0.09696288406848907, Validation Loss: 0.014204015024006367\n",
      "Epoch 100/100, Training Loss: 0.09586010873317719, Validation Loss: 0.014177415519952774\n",
      "Fold 1 - R² Score: 0.9858, MAE: 0.0760\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 3.7893052101135254, Validation Loss: 0.9184545278549194\n",
      "Epoch 2/100, Training Loss: 2.504279375076294, Validation Loss: 0.7799928784370422\n",
      "Epoch 3/100, Training Loss: 1.8131922483444214, Validation Loss: 0.6641167402267456\n",
      "Epoch 4/100, Training Loss: 1.4473919868469238, Validation Loss: 0.5792357325553894\n",
      "Epoch 5/100, Training Loss: 1.2364884614944458, Validation Loss: 0.5244262218475342\n",
      "Epoch 6/100, Training Loss: 1.0931296348571777, Validation Loss: 0.49071311950683594\n",
      "Epoch 7/100, Training Loss: 0.971382737159729, Validation Loss: 0.46932053565979004\n",
      "Epoch 8/100, Training Loss: 0.8545647859573364, Validation Loss: 0.45471319556236267\n",
      "Epoch 9/100, Training Loss: 0.7628514766693115, Validation Loss: 0.44241324067115784\n",
      "Epoch 10/100, Training Loss: 0.6788638234138489, Validation Loss: 0.4298759400844574\n",
      "Epoch 11/100, Training Loss: 0.624885618686676, Validation Loss: 0.41497865319252014\n",
      "Epoch 12/100, Training Loss: 0.5698225498199463, Validation Loss: 0.3973107933998108\n",
      "Epoch 13/100, Training Loss: 0.53082275390625, Validation Loss: 0.37586066126823425\n",
      "Epoch 14/100, Training Loss: 0.5001319050788879, Validation Loss: 0.3515233099460602\n",
      "Epoch 15/100, Training Loss: 0.46666109561920166, Validation Loss: 0.3244631588459015\n",
      "Epoch 16/100, Training Loss: 0.4374503195285797, Validation Loss: 0.29578718543052673\n",
      "Epoch 17/100, Training Loss: 0.4032781422138214, Validation Loss: 0.2673666477203369\n",
      "Epoch 18/100, Training Loss: 0.3810306787490845, Validation Loss: 0.23981598019599915\n",
      "Epoch 19/100, Training Loss: 0.35693833231925964, Validation Loss: 0.21408775448799133\n",
      "Epoch 20/100, Training Loss: 0.33575502038002014, Validation Loss: 0.19045743346214294\n",
      "Epoch 21/100, Training Loss: 0.31816232204437256, Validation Loss: 0.1694166213274002\n",
      "Epoch 22/100, Training Loss: 0.3044199049472809, Validation Loss: 0.1507553607225418\n",
      "Epoch 23/100, Training Loss: 0.2855619490146637, Validation Loss: 0.13473324477672577\n",
      "Epoch 24/100, Training Loss: 0.27133452892303467, Validation Loss: 0.12110117822885513\n",
      "Epoch 25/100, Training Loss: 0.2612808644771576, Validation Loss: 0.10935337096452713\n",
      "Epoch 26/100, Training Loss: 0.25059208273887634, Validation Loss: 0.09934545308351517\n",
      "Epoch 27/100, Training Loss: 0.23747774958610535, Validation Loss: 0.0908801332116127\n",
      "Epoch 28/100, Training Loss: 0.22999519109725952, Validation Loss: 0.08391623198986053\n",
      "Epoch 29/100, Training Loss: 0.2210148572921753, Validation Loss: 0.07803788036108017\n",
      "Epoch 30/100, Training Loss: 0.2131236046552658, Validation Loss: 0.07283364236354828\n",
      "Epoch 31/100, Training Loss: 0.20691046118736267, Validation Loss: 0.0682942122220993\n",
      "Epoch 32/100, Training Loss: 0.20026475191116333, Validation Loss: 0.06406275928020477\n",
      "Epoch 33/100, Training Loss: 0.19445031881332397, Validation Loss: 0.0601060651242733\n",
      "Epoch 34/100, Training Loss: 0.18927671015262604, Validation Loss: 0.05623055249452591\n",
      "Epoch 35/100, Training Loss: 0.18225406110286713, Validation Loss: 0.05250634253025055\n",
      "Epoch 36/100, Training Loss: 0.17801986634731293, Validation Loss: 0.04893714189529419\n",
      "Epoch 37/100, Training Loss: 0.17316755652427673, Validation Loss: 0.04550580307841301\n",
      "Epoch 38/100, Training Loss: 0.16936291754245758, Validation Loss: 0.04229636862874031\n",
      "Epoch 39/100, Training Loss: 0.16554155945777893, Validation Loss: 0.039208587259054184\n",
      "Epoch 40/100, Training Loss: 0.16187305748462677, Validation Loss: 0.03639412298798561\n",
      "Epoch 41/100, Training Loss: 0.15698696672916412, Validation Loss: 0.033841539174318314\n",
      "Epoch 42/100, Training Loss: 0.15237069129943848, Validation Loss: 0.03161708265542984\n",
      "Epoch 43/100, Training Loss: 0.15030471980571747, Validation Loss: 0.02974602021276951\n",
      "Epoch 44/100, Training Loss: 0.14906887710094452, Validation Loss: 0.02810751087963581\n",
      "Epoch 45/100, Training Loss: 0.1430855542421341, Validation Loss: 0.026776298880577087\n",
      "Epoch 46/100, Training Loss: 0.14114560186862946, Validation Loss: 0.025580160319805145\n",
      "Epoch 47/100, Training Loss: 0.13891099393367767, Validation Loss: 0.02458997257053852\n",
      "Epoch 48/100, Training Loss: 0.13591846823692322, Validation Loss: 0.023873573169112206\n",
      "Epoch 49/100, Training Loss: 0.1341511309146881, Validation Loss: 0.023368263617157936\n",
      "Epoch 50/100, Training Loss: 0.1331421136856079, Validation Loss: 0.02291395515203476\n",
      "Epoch 51/100, Training Loss: 0.1303350031375885, Validation Loss: 0.022562360391020775\n",
      "Epoch 52/100, Training Loss: 0.12835457921028137, Validation Loss: 0.022224061191082\n",
      "Epoch 53/100, Training Loss: 0.12608493864536285, Validation Loss: 0.0219639353454113\n",
      "Epoch 54/100, Training Loss: 0.12375008314847946, Validation Loss: 0.02173980139195919\n",
      "Epoch 55/100, Training Loss: 0.12395433336496353, Validation Loss: 0.02149069868028164\n",
      "Epoch 56/100, Training Loss: 0.12160222977399826, Validation Loss: 0.021212903782725334\n",
      "Epoch 57/100, Training Loss: 0.11935338377952576, Validation Loss: 0.02091945894062519\n",
      "Epoch 58/100, Training Loss: 0.11921323835849762, Validation Loss: 0.020626774057745934\n",
      "Epoch 59/100, Training Loss: 0.11727544665336609, Validation Loss: 0.020264428108930588\n",
      "Epoch 60/100, Training Loss: 0.11691258102655411, Validation Loss: 0.019886545836925507\n",
      "Epoch 61/100, Training Loss: 0.11637616157531738, Validation Loss: 0.019469138234853745\n",
      "Epoch 62/100, Training Loss: 0.11226601898670197, Validation Loss: 0.019072536379098892\n",
      "Epoch 63/100, Training Loss: 0.11260216683149338, Validation Loss: 0.018694892525672913\n",
      "Epoch 64/100, Training Loss: 0.10907885432243347, Validation Loss: 0.018348192796111107\n",
      "Epoch 65/100, Training Loss: 0.11002105474472046, Validation Loss: 0.018069231882691383\n",
      "Epoch 66/100, Training Loss: 0.11008665710687637, Validation Loss: 0.017851943150162697\n",
      "Epoch 67/100, Training Loss: 0.10871627926826477, Validation Loss: 0.017586903646588326\n",
      "Epoch 68/100, Training Loss: 0.10693173855543137, Validation Loss: 0.017364148050546646\n",
      "Epoch 69/100, Training Loss: 0.10640042275190353, Validation Loss: 0.01722840592265129\n",
      "Epoch 70/100, Training Loss: 0.10803953558206558, Validation Loss: 0.017160072922706604\n",
      "Epoch 71/100, Training Loss: 0.10628297179937363, Validation Loss: 0.01713823899626732\n",
      "Epoch 72/100, Training Loss: 0.10362373292446136, Validation Loss: 0.017173800617456436\n",
      "Epoch 73/100, Training Loss: 0.10383819043636322, Validation Loss: 0.01722651720046997\n",
      "Epoch 74/100, Training Loss: 0.10314904153347015, Validation Loss: 0.017257388681173325\n",
      "Epoch 75/100, Training Loss: 0.10153517872095108, Validation Loss: 0.01725848950445652\n",
      "Epoch 76/100, Training Loss: 0.10234002768993378, Validation Loss: 0.01724608987569809\n",
      "Epoch 77/100, Training Loss: 0.10251086950302124, Validation Loss: 0.017138022929430008\n",
      "Epoch 78/100, Training Loss: 0.09969749301671982, Validation Loss: 0.017015010118484497\n",
      "Epoch 79/100, Training Loss: 0.10010270774364471, Validation Loss: 0.01677294261753559\n",
      "Epoch 80/100, Training Loss: 0.09938793629407883, Validation Loss: 0.016536366194486618\n",
      "Epoch 81/100, Training Loss: 0.09999070316553116, Validation Loss: 0.016344336792826653\n",
      "Epoch 82/100, Training Loss: 0.0996033176779747, Validation Loss: 0.016149593517184258\n",
      "Epoch 83/100, Training Loss: 0.09947844594717026, Validation Loss: 0.015970882028341293\n",
      "Epoch 84/100, Training Loss: 0.09819117188453674, Validation Loss: 0.01582310162484646\n",
      "Epoch 85/100, Training Loss: 0.09798554331064224, Validation Loss: 0.01571868173778057\n",
      "Epoch 86/100, Training Loss: 0.09855911880731583, Validation Loss: 0.01560179889202118\n",
      "Epoch 87/100, Training Loss: 0.09754721075296402, Validation Loss: 0.015559816733002663\n",
      "Epoch 88/100, Training Loss: 0.09720899164676666, Validation Loss: 0.015478502959012985\n",
      "Epoch 89/100, Training Loss: 0.09697561711072922, Validation Loss: 0.015432452782988548\n",
      "Epoch 90/100, Training Loss: 0.09460774809122086, Validation Loss: 0.01537110935896635\n",
      "Epoch 91/100, Training Loss: 0.09528461843729019, Validation Loss: 0.01539471372961998\n",
      "Epoch 92/100, Training Loss: 0.0953560471534729, Validation Loss: 0.015356570482254028\n",
      "Epoch 93/100, Training Loss: 0.09458166360855103, Validation Loss: 0.015330526046454906\n",
      "Epoch 94/100, Training Loss: 0.09480415284633636, Validation Loss: 0.015307690016925335\n",
      "Epoch 95/100, Training Loss: 0.09346699714660645, Validation Loss: 0.01525046955794096\n",
      "Epoch 96/100, Training Loss: 0.09436452388763428, Validation Loss: 0.015185247175395489\n",
      "Epoch 97/100, Training Loss: 0.09221883863210678, Validation Loss: 0.015120981261134148\n",
      "Epoch 98/100, Training Loss: 0.09290627390146255, Validation Loss: 0.015000256709754467\n",
      "Epoch 99/100, Training Loss: 0.09304162859916687, Validation Loss: 0.01486890483647585\n",
      "Epoch 100/100, Training Loss: 0.09145189821720123, Validation Loss: 0.01475493423640728\n",
      "Fold 2 - R² Score: 0.9853, MAE: 0.0771\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 2.886295795440674, Validation Loss: 0.7512233853340149\n",
      "Epoch 2/100, Training Loss: 1.7554664611816406, Validation Loss: 0.6409631371498108\n",
      "Epoch 3/100, Training Loss: 1.429933786392212, Validation Loss: 0.5838797092437744\n",
      "Epoch 4/100, Training Loss: 1.1955111026763916, Validation Loss: 0.560248076915741\n",
      "Epoch 5/100, Training Loss: 1.0584264993667603, Validation Loss: 0.5527189373970032\n",
      "Epoch 6/100, Training Loss: 0.9125530123710632, Validation Loss: 0.5496259331703186\n",
      "Epoch 7/100, Training Loss: 0.7931091785430908, Validation Loss: 0.5439835786819458\n",
      "Epoch 8/100, Training Loss: 0.7185465097427368, Validation Loss: 0.5325677990913391\n",
      "Epoch 9/100, Training Loss: 0.6299236416816711, Validation Loss: 0.5143652558326721\n",
      "Epoch 10/100, Training Loss: 0.572891116142273, Validation Loss: 0.48986321687698364\n",
      "Epoch 11/100, Training Loss: 0.5323477387428284, Validation Loss: 0.46094539761543274\n",
      "Epoch 12/100, Training Loss: 0.4966093897819519, Validation Loss: 0.4303932785987854\n",
      "Epoch 13/100, Training Loss: 0.45731306076049805, Validation Loss: 0.39939239621162415\n",
      "Epoch 14/100, Training Loss: 0.4282784163951874, Validation Loss: 0.3694894015789032\n",
      "Epoch 15/100, Training Loss: 0.3976295590400696, Validation Loss: 0.34099045395851135\n",
      "Epoch 16/100, Training Loss: 0.3712499439716339, Validation Loss: 0.3138827085494995\n",
      "Epoch 17/100, Training Loss: 0.34304875135421753, Validation Loss: 0.2885441780090332\n",
      "Epoch 18/100, Training Loss: 0.32407504320144653, Validation Loss: 0.26458048820495605\n",
      "Epoch 19/100, Training Loss: 0.30119064450263977, Validation Loss: 0.24164114892482758\n",
      "Epoch 20/100, Training Loss: 0.2761993706226349, Validation Loss: 0.21936005353927612\n",
      "Epoch 21/100, Training Loss: 0.26380714774131775, Validation Loss: 0.1976310759782791\n",
      "Epoch 22/100, Training Loss: 0.25508856773376465, Validation Loss: 0.17681768536567688\n",
      "Epoch 23/100, Training Loss: 0.23752757906913757, Validation Loss: 0.15676280856132507\n",
      "Epoch 24/100, Training Loss: 0.22492946684360504, Validation Loss: 0.13823436200618744\n",
      "Epoch 25/100, Training Loss: 0.21837805211544037, Validation Loss: 0.12130921334028244\n",
      "Epoch 26/100, Training Loss: 0.2057042121887207, Validation Loss: 0.10654284060001373\n",
      "Epoch 27/100, Training Loss: 0.1951034963130951, Validation Loss: 0.09376846998929977\n",
      "Epoch 28/100, Training Loss: 0.18965786695480347, Validation Loss: 0.08283932507038116\n",
      "Epoch 29/100, Training Loss: 0.1835877001285553, Validation Loss: 0.07393690943717957\n",
      "Epoch 30/100, Training Loss: 0.1764964908361435, Validation Loss: 0.06649579852819443\n",
      "Epoch 31/100, Training Loss: 0.17119885981082916, Validation Loss: 0.06033359840512276\n",
      "Epoch 32/100, Training Loss: 0.16739647090435028, Validation Loss: 0.055264752358198166\n",
      "Epoch 33/100, Training Loss: 0.15920716524124146, Validation Loss: 0.051091212779283524\n",
      "Epoch 34/100, Training Loss: 0.1565295159816742, Validation Loss: 0.04756298288702965\n",
      "Epoch 35/100, Training Loss: 0.15255889296531677, Validation Loss: 0.044577255845069885\n",
      "Epoch 36/100, Training Loss: 0.14849039912223816, Validation Loss: 0.04214012622833252\n",
      "Epoch 37/100, Training Loss: 0.14382414519786835, Validation Loss: 0.0401279479265213\n",
      "Epoch 38/100, Training Loss: 0.1401476413011551, Validation Loss: 0.03839316591620445\n",
      "Epoch 39/100, Training Loss: 0.13745392858982086, Validation Loss: 0.03675369173288345\n",
      "Epoch 40/100, Training Loss: 0.13571864366531372, Validation Loss: 0.03510792925953865\n",
      "Epoch 41/100, Training Loss: 0.13269123435020447, Validation Loss: 0.033354006707668304\n",
      "Epoch 42/100, Training Loss: 0.12995927035808563, Validation Loss: 0.03153708949685097\n",
      "Epoch 43/100, Training Loss: 0.12835006415843964, Validation Loss: 0.029561230912804604\n",
      "Epoch 44/100, Training Loss: 0.12675832211971283, Validation Loss: 0.02752825990319252\n",
      "Epoch 45/100, Training Loss: 0.1225353553891182, Validation Loss: 0.025589987635612488\n",
      "Epoch 46/100, Training Loss: 0.12151188403367996, Validation Loss: 0.02388179302215576\n",
      "Epoch 47/100, Training Loss: 0.11930139362812042, Validation Loss: 0.022319721058011055\n",
      "Epoch 48/100, Training Loss: 0.11831586062908173, Validation Loss: 0.020950082689523697\n",
      "Epoch 49/100, Training Loss: 0.11927618086338043, Validation Loss: 0.01981203444302082\n",
      "Epoch 50/100, Training Loss: 0.11685594916343689, Validation Loss: 0.01885542832314968\n",
      "Epoch 51/100, Training Loss: 0.11438188701868057, Validation Loss: 0.01808946393430233\n",
      "Epoch 52/100, Training Loss: 0.11409544944763184, Validation Loss: 0.017427310347557068\n",
      "Epoch 53/100, Training Loss: 0.11271712183952332, Validation Loss: 0.016873540356755257\n",
      "Epoch 54/100, Training Loss: 0.11144082993268967, Validation Loss: 0.016428295522928238\n",
      "Epoch 55/100, Training Loss: 0.11018523573875427, Validation Loss: 0.01604655012488365\n",
      "Epoch 56/100, Training Loss: 0.10985072702169418, Validation Loss: 0.015737364068627357\n",
      "Epoch 57/100, Training Loss: 0.10837053507566452, Validation Loss: 0.015433130785822868\n",
      "Epoch 58/100, Training Loss: 0.10647547990083694, Validation Loss: 0.01512444019317627\n",
      "Epoch 59/100, Training Loss: 0.10573204606771469, Validation Loss: 0.014845795929431915\n",
      "Epoch 60/100, Training Loss: 0.10542367398738861, Validation Loss: 0.014561879448592663\n",
      "Epoch 61/100, Training Loss: 0.10436989367008209, Validation Loss: 0.014253909699618816\n",
      "Epoch 62/100, Training Loss: 0.10390233248472214, Validation Loss: 0.013962159864604473\n",
      "Epoch 63/100, Training Loss: 0.10317631810903549, Validation Loss: 0.013740523718297482\n",
      "Epoch 64/100, Training Loss: 0.10341135412454605, Validation Loss: 0.013539532199501991\n",
      "Epoch 65/100, Training Loss: 0.1033882349729538, Validation Loss: 0.013398686423897743\n",
      "Epoch 66/100, Training Loss: 0.10065017640590668, Validation Loss: 0.01326509565114975\n",
      "Epoch 67/100, Training Loss: 0.10162483900785446, Validation Loss: 0.013162026181817055\n",
      "Epoch 68/100, Training Loss: 0.10028064996004105, Validation Loss: 0.013129139319062233\n",
      "Epoch 69/100, Training Loss: 0.1002122312784195, Validation Loss: 0.01312213484197855\n",
      "Epoch 70/100, Training Loss: 0.09807039052248001, Validation Loss: 0.013136022724211216\n",
      "Epoch 71/100, Training Loss: 0.09863372892141342, Validation Loss: 0.013172646053135395\n",
      "Epoch 72/100, Training Loss: 0.09825507551431656, Validation Loss: 0.013166569173336029\n",
      "Epoch 73/100, Training Loss: 0.09833933413028717, Validation Loss: 0.01312160026282072\n",
      "Epoch 74/100, Training Loss: 0.09687100350856781, Validation Loss: 0.013079188764095306\n",
      "Epoch 75/100, Training Loss: 0.09767277538776398, Validation Loss: 0.013009562157094479\n",
      "Epoch 76/100, Training Loss: 0.09685657173395157, Validation Loss: 0.012902610003948212\n",
      "Epoch 77/100, Training Loss: 0.09582406282424927, Validation Loss: 0.012739273719489574\n",
      "Epoch 78/100, Training Loss: 0.0972953587770462, Validation Loss: 0.012562339194118977\n",
      "Epoch 79/100, Training Loss: 0.09597039967775345, Validation Loss: 0.012389312498271465\n",
      "Epoch 80/100, Training Loss: 0.09706863760948181, Validation Loss: 0.012226244434714317\n",
      "Epoch 81/100, Training Loss: 0.09534613788127899, Validation Loss: 0.012097674421966076\n",
      "Epoch 82/100, Training Loss: 0.09603825211524963, Validation Loss: 0.012007903307676315\n",
      "Epoch 83/100, Training Loss: 0.0949220135807991, Validation Loss: 0.012023430317640305\n",
      "Epoch 84/100, Training Loss: 0.09471137821674347, Validation Loss: 0.012033157981932163\n",
      "Epoch 85/100, Training Loss: 0.09339386969804764, Validation Loss: 0.012052726000547409\n",
      "Epoch 86/100, Training Loss: 0.09302791208028793, Validation Loss: 0.012092437595129013\n",
      "Epoch 87/100, Training Loss: 0.09392952919006348, Validation Loss: 0.012079856358468533\n",
      "Epoch 88/100, Training Loss: 0.09421717375516891, Validation Loss: 0.012051724828779697\n",
      "Epoch 89/100, Training Loss: 0.09384842216968536, Validation Loss: 0.01206858828663826\n",
      "Epoch 90/100, Training Loss: 0.0924985408782959, Validation Loss: 0.012053715996444225\n",
      "Epoch 91/100, Training Loss: 0.0931287631392479, Validation Loss: 0.012001022696495056\n",
      "Epoch 92/100, Training Loss: 0.09139588475227356, Validation Loss: 0.012029788456857204\n",
      "Epoch 93/100, Training Loss: 0.09224167466163635, Validation Loss: 0.012066412717103958\n",
      "Epoch 94/100, Training Loss: 0.09165657311677933, Validation Loss: 0.012107985094189644\n",
      "Epoch 95/100, Training Loss: 0.09147725254297256, Validation Loss: 0.012136696837842464\n",
      "Epoch 96/100, Training Loss: 0.09165894240140915, Validation Loss: 0.012179714627563953\n",
      "Epoch 97/100, Training Loss: 0.09096529334783554, Validation Loss: 0.012234902009367943\n",
      "Epoch 98/100, Training Loss: 0.09185735881328583, Validation Loss: 0.01225360482931137\n",
      "Epoch 99/100, Training Loss: 0.09061527997255325, Validation Loss: 0.012284512631595135\n",
      "Epoch 100/100, Training Loss: 0.09132373332977295, Validation Loss: 0.012236591428518295\n",
      "Fold 3 - R² Score: 0.9877, MAE: 0.0689\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 2.5431647300720215, Validation Loss: 0.7891209721565247\n",
      "Epoch 2/100, Training Loss: 1.7438527345657349, Validation Loss: 0.6717169880867004\n",
      "Epoch 3/100, Training Loss: 1.3037313222885132, Validation Loss: 0.5797933340072632\n",
      "Epoch 4/100, Training Loss: 1.1069200038909912, Validation Loss: 0.5151938796043396\n",
      "Epoch 5/100, Training Loss: 0.9750848412513733, Validation Loss: 0.4704086184501648\n",
      "Epoch 6/100, Training Loss: 0.8770959377288818, Validation Loss: 0.4396477937698364\n",
      "Epoch 7/100, Training Loss: 0.7885942459106445, Validation Loss: 0.4194658100605011\n",
      "Epoch 8/100, Training Loss: 0.6897608041763306, Validation Loss: 0.4057752192020416\n",
      "Epoch 9/100, Training Loss: 0.6268151998519897, Validation Loss: 0.3953586518764496\n",
      "Epoch 10/100, Training Loss: 0.5771459341049194, Validation Loss: 0.3851259648799896\n",
      "Epoch 11/100, Training Loss: 0.5285550951957703, Validation Loss: 0.3728620111942291\n",
      "Epoch 12/100, Training Loss: 0.49383920431137085, Validation Loss: 0.358092337846756\n",
      "Epoch 13/100, Training Loss: 0.4568116068840027, Validation Loss: 0.34034284949302673\n",
      "Epoch 14/100, Training Loss: 0.4225030243396759, Validation Loss: 0.32048824429512024\n",
      "Epoch 15/100, Training Loss: 0.39403054118156433, Validation Loss: 0.29902660846710205\n",
      "Epoch 16/100, Training Loss: 0.37223947048187256, Validation Loss: 0.2768033444881439\n",
      "Epoch 17/100, Training Loss: 0.3444213569164276, Validation Loss: 0.2542525827884674\n",
      "Epoch 18/100, Training Loss: 0.3209235966205597, Validation Loss: 0.2322097271680832\n",
      "Epoch 19/100, Training Loss: 0.3012729585170746, Validation Loss: 0.2111670821905136\n",
      "Epoch 20/100, Training Loss: 0.2845165431499481, Validation Loss: 0.19104818999767303\n",
      "Epoch 21/100, Training Loss: 0.2707107961177826, Validation Loss: 0.17219847440719604\n",
      "Epoch 22/100, Training Loss: 0.25224044919013977, Validation Loss: 0.15477734804153442\n",
      "Epoch 23/100, Training Loss: 0.23839645087718964, Validation Loss: 0.1389358937740326\n",
      "Epoch 24/100, Training Loss: 0.22810959815979004, Validation Loss: 0.12469503283500671\n",
      "Epoch 25/100, Training Loss: 0.2180454581975937, Validation Loss: 0.11191824078559875\n",
      "Epoch 26/100, Training Loss: 0.2079574167728424, Validation Loss: 0.10057087242603302\n",
      "Epoch 27/100, Training Loss: 0.1987159103155136, Validation Loss: 0.09059026092290878\n",
      "Epoch 28/100, Training Loss: 0.19305944442749023, Validation Loss: 0.0818154588341713\n",
      "Epoch 29/100, Training Loss: 0.18473666906356812, Validation Loss: 0.07411042600870132\n",
      "Epoch 30/100, Training Loss: 0.17913620173931122, Validation Loss: 0.06732143461704254\n",
      "Epoch 31/100, Training Loss: 0.16961060464382172, Validation Loss: 0.06129360571503639\n",
      "Epoch 32/100, Training Loss: 0.16554969549179077, Validation Loss: 0.05604483187198639\n",
      "Epoch 33/100, Training Loss: 0.1593647599220276, Validation Loss: 0.051201820373535156\n",
      "Epoch 34/100, Training Loss: 0.1554199904203415, Validation Loss: 0.0469370074570179\n",
      "Epoch 35/100, Training Loss: 0.15116019546985626, Validation Loss: 0.043095726519823074\n",
      "Epoch 36/100, Training Loss: 0.14620545506477356, Validation Loss: 0.03974313661456108\n",
      "Epoch 37/100, Training Loss: 0.1422630101442337, Validation Loss: 0.03673006594181061\n",
      "Epoch 38/100, Training Loss: 0.13930633664131165, Validation Loss: 0.034078199416399\n",
      "Epoch 39/100, Training Loss: 0.13515223562717438, Validation Loss: 0.03177522122859955\n",
      "Epoch 40/100, Training Loss: 0.13394135236740112, Validation Loss: 0.029665159061551094\n",
      "Epoch 41/100, Training Loss: 0.13177621364593506, Validation Loss: 0.027866484597325325\n",
      "Epoch 42/100, Training Loss: 0.12739808857440948, Validation Loss: 0.026360606774687767\n",
      "Epoch 43/100, Training Loss: 0.12505808472633362, Validation Loss: 0.025102583691477776\n",
      "Epoch 44/100, Training Loss: 0.12286262214183807, Validation Loss: 0.02400779165327549\n",
      "Epoch 45/100, Training Loss: 0.11982839554548264, Validation Loss: 0.023036297410726547\n",
      "Epoch 46/100, Training Loss: 0.11865883320569992, Validation Loss: 0.02218112163245678\n",
      "Epoch 47/100, Training Loss: 0.11560223996639252, Validation Loss: 0.021482808515429497\n",
      "Epoch 48/100, Training Loss: 0.11512383073568344, Validation Loss: 0.020778149366378784\n",
      "Epoch 49/100, Training Loss: 0.11496368050575256, Validation Loss: 0.020020924508571625\n",
      "Epoch 50/100, Training Loss: 0.11313306540250778, Validation Loss: 0.01933412253856659\n",
      "Epoch 51/100, Training Loss: 0.11155635118484497, Validation Loss: 0.01868354342877865\n",
      "Epoch 52/100, Training Loss: 0.11064143478870392, Validation Loss: 0.018034707754850388\n",
      "Epoch 53/100, Training Loss: 0.10923735797405243, Validation Loss: 0.017431344836950302\n",
      "Epoch 54/100, Training Loss: 0.10813809186220169, Validation Loss: 0.016926780343055725\n",
      "Epoch 55/100, Training Loss: 0.10772614181041718, Validation Loss: 0.016437988728284836\n",
      "Epoch 56/100, Training Loss: 0.1049560159444809, Validation Loss: 0.016030294820666313\n",
      "Epoch 57/100, Training Loss: 0.10573636740446091, Validation Loss: 0.015656564384698868\n",
      "Epoch 58/100, Training Loss: 0.10370565205812454, Validation Loss: 0.015283321030437946\n",
      "Epoch 59/100, Training Loss: 0.10427108407020569, Validation Loss: 0.014980762265622616\n",
      "Epoch 60/100, Training Loss: 0.1028643250465393, Validation Loss: 0.014695225283503532\n",
      "Epoch 61/100, Training Loss: 0.1009722650051117, Validation Loss: 0.014477617107331753\n",
      "Epoch 62/100, Training Loss: 0.10048939287662506, Validation Loss: 0.014270351268351078\n",
      "Epoch 63/100, Training Loss: 0.09967873245477676, Validation Loss: 0.014146488159894943\n",
      "Epoch 64/100, Training Loss: 0.10011991113424301, Validation Loss: 0.014052209444344044\n",
      "Epoch 65/100, Training Loss: 0.09958094358444214, Validation Loss: 0.01395492535084486\n",
      "Epoch 66/100, Training Loss: 0.09824482351541519, Validation Loss: 0.013908643275499344\n",
      "Epoch 67/100, Training Loss: 0.09781365841627121, Validation Loss: 0.013787896372377872\n",
      "Epoch 68/100, Training Loss: 0.09557871520519257, Validation Loss: 0.013682285323739052\n",
      "Epoch 69/100, Training Loss: 0.09654086828231812, Validation Loss: 0.013567859306931496\n",
      "Epoch 70/100, Training Loss: 0.0959092453122139, Validation Loss: 0.01346088107675314\n",
      "Epoch 71/100, Training Loss: 0.09524207562208176, Validation Loss: 0.013365604914724827\n",
      "Epoch 72/100, Training Loss: 0.0957164317369461, Validation Loss: 0.013281344436109066\n",
      "Epoch 73/100, Training Loss: 0.0950751006603241, Validation Loss: 0.01321586687117815\n",
      "Epoch 74/100, Training Loss: 0.09339313954114914, Validation Loss: 0.013182595372200012\n",
      "Epoch 75/100, Training Loss: 0.09517868608236313, Validation Loss: 0.013144810684025288\n",
      "Epoch 76/100, Training Loss: 0.09362532943487167, Validation Loss: 0.013147651217877865\n",
      "Epoch 77/100, Training Loss: 0.09344065189361572, Validation Loss: 0.0131547711789608\n",
      "Epoch 78/100, Training Loss: 0.09230238199234009, Validation Loss: 0.01319863274693489\n",
      "Epoch 79/100, Training Loss: 0.09259653091430664, Validation Loss: 0.013273807242512703\n",
      "Epoch 80/100, Training Loss: 0.09234252572059631, Validation Loss: 0.01334213837981224\n",
      "Epoch 81/100, Training Loss: 0.09251120686531067, Validation Loss: 0.013379283249378204\n",
      "Epoch 82/100, Training Loss: 0.09209732711315155, Validation Loss: 0.01333942636847496\n",
      "Epoch 83/100, Training Loss: 0.09075765311717987, Validation Loss: 0.013307549059391022\n",
      "Epoch 84/100, Training Loss: 0.09040527790784836, Validation Loss: 0.013232731260359287\n",
      "Epoch 85/100, Training Loss: 0.09113562107086182, Validation Loss: 0.013182372786104679\n",
      "Early stopping triggered\n",
      "Fold 4 - R² Score: 0.9869, MAE: 0.0699\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 2.177741765975952, Validation Loss: 0.7391347289085388\n",
      "Epoch 2/100, Training Loss: 1.501546025276184, Validation Loss: 0.6668492555618286\n",
      "Epoch 3/100, Training Loss: 1.2307486534118652, Validation Loss: 0.6043429374694824\n",
      "Epoch 4/100, Training Loss: 1.0590624809265137, Validation Loss: 0.5521238446235657\n",
      "Epoch 5/100, Training Loss: 0.9192602634429932, Validation Loss: 0.5120611786842346\n",
      "Epoch 6/100, Training Loss: 0.783065676689148, Validation Loss: 0.4812427759170532\n",
      "Epoch 7/100, Training Loss: 0.6799563765525818, Validation Loss: 0.4552518129348755\n",
      "Epoch 8/100, Training Loss: 0.6051048040390015, Validation Loss: 0.43232524394989014\n",
      "Epoch 9/100, Training Loss: 0.5437797904014587, Validation Loss: 0.410117506980896\n",
      "Epoch 10/100, Training Loss: 0.49936193227767944, Validation Loss: 0.3875565528869629\n",
      "Epoch 11/100, Training Loss: 0.4574265480041504, Validation Loss: 0.36388638615608215\n",
      "Epoch 12/100, Training Loss: 0.4202299416065216, Validation Loss: 0.3390273451805115\n",
      "Epoch 13/100, Training Loss: 0.3905242681503296, Validation Loss: 0.3134916424751282\n",
      "Epoch 14/100, Training Loss: 0.36341094970703125, Validation Loss: 0.28762251138687134\n",
      "Epoch 15/100, Training Loss: 0.3344760239124298, Validation Loss: 0.2619776427745819\n",
      "Epoch 16/100, Training Loss: 0.3101511299610138, Validation Loss: 0.23799824714660645\n",
      "Epoch 17/100, Training Loss: 0.2912185788154602, Validation Loss: 0.21612346172332764\n",
      "Epoch 18/100, Training Loss: 0.27199602127075195, Validation Loss: 0.19667895138263702\n",
      "Epoch 19/100, Training Loss: 0.25443515181541443, Validation Loss: 0.17955471575260162\n",
      "Epoch 20/100, Training Loss: 0.23749510943889618, Validation Loss: 0.16479302942752838\n",
      "Epoch 21/100, Training Loss: 0.2239857316017151, Validation Loss: 0.15188077092170715\n",
      "Epoch 22/100, Training Loss: 0.21266844868659973, Validation Loss: 0.14046557247638702\n",
      "Epoch 23/100, Training Loss: 0.20003996789455414, Validation Loss: 0.130337193608284\n",
      "Epoch 24/100, Training Loss: 0.18921081721782684, Validation Loss: 0.1212763637304306\n",
      "Epoch 25/100, Training Loss: 0.1836467683315277, Validation Loss: 0.11278282105922699\n",
      "Epoch 26/100, Training Loss: 0.17420168220996857, Validation Loss: 0.10506609827280045\n",
      "Epoch 27/100, Training Loss: 0.16944579780101776, Validation Loss: 0.09789150953292847\n",
      "Epoch 28/100, Training Loss: 0.16140146553516388, Validation Loss: 0.0912141278386116\n",
      "Epoch 29/100, Training Loss: 0.1565970927476883, Validation Loss: 0.0849384069442749\n",
      "Epoch 30/100, Training Loss: 0.14984387159347534, Validation Loss: 0.07906802743673325\n",
      "Epoch 31/100, Training Loss: 0.1464664787054062, Validation Loss: 0.07355616986751556\n",
      "Epoch 32/100, Training Loss: 0.14282101392745972, Validation Loss: 0.06844182312488556\n",
      "Epoch 33/100, Training Loss: 0.13650129735469818, Validation Loss: 0.06352561712265015\n",
      "Epoch 34/100, Training Loss: 0.1341756135225296, Validation Loss: 0.05900286138057709\n",
      "Epoch 35/100, Training Loss: 0.13059507310390472, Validation Loss: 0.05492354556918144\n",
      "Epoch 36/100, Training Loss: 0.1277560442686081, Validation Loss: 0.05127117410302162\n",
      "Epoch 37/100, Training Loss: 0.12435024231672287, Validation Loss: 0.048004940152168274\n",
      "Epoch 38/100, Training Loss: 0.12249100208282471, Validation Loss: 0.045113254338502884\n",
      "Epoch 39/100, Training Loss: 0.11951623111963272, Validation Loss: 0.042425815016031265\n",
      "Epoch 40/100, Training Loss: 0.11931190639734268, Validation Loss: 0.04007744416594505\n",
      "Epoch 41/100, Training Loss: 0.11606988310813904, Validation Loss: 0.0379381999373436\n",
      "Epoch 42/100, Training Loss: 0.11407848447561264, Validation Loss: 0.036000583320856094\n",
      "Epoch 43/100, Training Loss: 0.1127239242196083, Validation Loss: 0.03419690579175949\n",
      "Epoch 44/100, Training Loss: 0.11076764017343521, Validation Loss: 0.032584477216005325\n",
      "Epoch 45/100, Training Loss: 0.10977523028850555, Validation Loss: 0.031108757480978966\n",
      "Epoch 46/100, Training Loss: 0.10907246172428131, Validation Loss: 0.029823046177625656\n",
      "Epoch 47/100, Training Loss: 0.10698909312486649, Validation Loss: 0.028756896033883095\n",
      "Epoch 48/100, Training Loss: 0.10499785840511322, Validation Loss: 0.02768937684595585\n",
      "Epoch 49/100, Training Loss: 0.10454172641038895, Validation Loss: 0.02673039585351944\n",
      "Epoch 50/100, Training Loss: 0.10456166416406631, Validation Loss: 0.025874929502606392\n",
      "Epoch 51/100, Training Loss: 0.10385959595441818, Validation Loss: 0.02503681369125843\n",
      "Epoch 52/100, Training Loss: 0.10188417136669159, Validation Loss: 0.024177001789212227\n",
      "Epoch 53/100, Training Loss: 0.10017354041337967, Validation Loss: 0.02338666282594204\n",
      "Epoch 54/100, Training Loss: 0.10033264756202698, Validation Loss: 0.022555578500032425\n",
      "Epoch 55/100, Training Loss: 0.09960195422172546, Validation Loss: 0.021733712404966354\n",
      "Epoch 56/100, Training Loss: 0.09991282224655151, Validation Loss: 0.020843293517827988\n",
      "Epoch 57/100, Training Loss: 0.09818139672279358, Validation Loss: 0.01995830051600933\n",
      "Epoch 58/100, Training Loss: 0.09704528003931046, Validation Loss: 0.019119318574666977\n",
      "Epoch 59/100, Training Loss: 0.09771090000867844, Validation Loss: 0.018343251198530197\n",
      "Epoch 60/100, Training Loss: 0.09764818847179413, Validation Loss: 0.017638597637414932\n",
      "Epoch 61/100, Training Loss: 0.0973062589764595, Validation Loss: 0.017095619812607765\n",
      "Epoch 62/100, Training Loss: 0.09596545994281769, Validation Loss: 0.016623299568891525\n",
      "Epoch 63/100, Training Loss: 0.09496081620454788, Validation Loss: 0.01620076410472393\n",
      "Epoch 64/100, Training Loss: 0.09565860033035278, Validation Loss: 0.01578545942902565\n",
      "Epoch 65/100, Training Loss: 0.09382203966379166, Validation Loss: 0.015441563911736012\n",
      "Epoch 66/100, Training Loss: 0.09503089636564255, Validation Loss: 0.015052885748445988\n",
      "Epoch 67/100, Training Loss: 0.09238019585609436, Validation Loss: 0.014676162041723728\n",
      "Epoch 68/100, Training Loss: 0.09456425905227661, Validation Loss: 0.014313110150396824\n",
      "Epoch 69/100, Training Loss: 0.09279234707355499, Validation Loss: 0.013918641954660416\n",
      "Epoch 70/100, Training Loss: 0.09263812005519867, Validation Loss: 0.013550310395658016\n",
      "Epoch 71/100, Training Loss: 0.0923362746834755, Validation Loss: 0.013243942521512508\n",
      "Epoch 72/100, Training Loss: 0.09262445569038391, Validation Loss: 0.012964244931936264\n",
      "Epoch 73/100, Training Loss: 0.09242022037506104, Validation Loss: 0.01282927393913269\n",
      "Epoch 74/100, Training Loss: 0.09234967082738876, Validation Loss: 0.012766947038471699\n",
      "Epoch 75/100, Training Loss: 0.09052973985671997, Validation Loss: 0.01277343649417162\n",
      "Epoch 76/100, Training Loss: 0.09097151458263397, Validation Loss: 0.012804384343326092\n",
      "Epoch 77/100, Training Loss: 0.09182398021221161, Validation Loss: 0.01286198478192091\n",
      "Epoch 78/100, Training Loss: 0.09164079278707504, Validation Loss: 0.012838056311011314\n",
      "Epoch 79/100, Training Loss: 0.08971790224313736, Validation Loss: 0.012754881754517555\n",
      "Epoch 80/100, Training Loss: 0.08971524983644485, Validation Loss: 0.01265619695186615\n",
      "Epoch 81/100, Training Loss: 0.09045366942882538, Validation Loss: 0.012494988739490509\n",
      "Epoch 82/100, Training Loss: 0.08988939970731735, Validation Loss: 0.012346716597676277\n",
      "Epoch 83/100, Training Loss: 0.08922406286001205, Validation Loss: 0.012250039726495743\n",
      "Epoch 84/100, Training Loss: 0.08921001851558685, Validation Loss: 0.012185642495751381\n",
      "Epoch 85/100, Training Loss: 0.0895482525229454, Validation Loss: 0.012269232422113419\n",
      "Epoch 86/100, Training Loss: 0.08810796588659286, Validation Loss: 0.012331396341323853\n",
      "Epoch 87/100, Training Loss: 0.08721955865621567, Validation Loss: 0.012416993267834187\n",
      "Epoch 88/100, Training Loss: 0.08814137428998947, Validation Loss: 0.012523063458502293\n",
      "Epoch 89/100, Training Loss: 0.08714452385902405, Validation Loss: 0.012596486136317253\n",
      "Epoch 90/100, Training Loss: 0.08853064477443695, Validation Loss: 0.012554186396300793\n",
      "Epoch 91/100, Training Loss: 0.08750586956739426, Validation Loss: 0.012495826929807663\n",
      "Epoch 92/100, Training Loss: 0.08612959086894989, Validation Loss: 0.012415410950779915\n",
      "Epoch 93/100, Training Loss: 0.08726859092712402, Validation Loss: 0.012346708215773106\n",
      "Epoch 94/100, Training Loss: 0.08780156075954437, Validation Loss: 0.012280908413231373\n",
      "Early stopping triggered\n",
      "Fold 5 - R² Score: 0.9877, MAE: 0.0679\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 64, 'learning_rate': 0.0001}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.546219825744629, Validation Loss: 1.0225822925567627\n",
      "Epoch 2/100, Training Loss: 3.4869582653045654, Validation Loss: 1.0307507514953613\n",
      "Epoch 3/100, Training Loss: 3.421250581741333, Validation Loss: 1.04398775100708\n",
      "Epoch 4/100, Training Loss: 3.4203646183013916, Validation Loss: 1.061236023902893\n",
      "Epoch 5/100, Training Loss: 3.3841843605041504, Validation Loss: 1.08144211769104\n",
      "Epoch 6/100, Training Loss: 3.355212926864624, Validation Loss: 1.1036856174468994\n",
      "Epoch 7/100, Training Loss: 3.2822213172912598, Validation Loss: 1.127014398574829\n",
      "Epoch 8/100, Training Loss: 3.281797170639038, Validation Loss: 1.1507805585861206\n",
      "Epoch 9/100, Training Loss: 3.2019331455230713, Validation Loss: 1.1737107038497925\n",
      "Epoch 10/100, Training Loss: 3.1559298038482666, Validation Loss: 1.1954704523086548\n",
      "Epoch 11/100, Training Loss: 3.139620304107666, Validation Loss: 1.2151862382888794\n",
      "Early stopping triggered\n",
      "Fold 1 - R² Score: -0.2165, MAE: 0.8078\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 4.251187801361084, Validation Loss: 1.2419863939285278\n",
      "Epoch 2/100, Training Loss: 4.20058536529541, Validation Loss: 1.2393977642059326\n",
      "Epoch 3/100, Training Loss: 4.12767219543457, Validation Loss: 1.240808367729187\n",
      "Epoch 4/100, Training Loss: 4.075772762298584, Validation Loss: 1.2440903186798096\n",
      "Epoch 5/100, Training Loss: 4.02230167388916, Validation Loss: 1.24857497215271\n",
      "Epoch 6/100, Training Loss: 4.007356643676758, Validation Loss: 1.2533485889434814\n",
      "Epoch 7/100, Training Loss: 3.92824125289917, Validation Loss: 1.2577697038650513\n",
      "Epoch 8/100, Training Loss: 3.9036943912506104, Validation Loss: 1.2617462873458862\n",
      "Epoch 9/100, Training Loss: 3.8339152336120605, Validation Loss: 1.265366792678833\n",
      "Epoch 10/100, Training Loss: 3.7990922927856445, Validation Loss: 1.2679823637008667\n",
      "Epoch 11/100, Training Loss: 3.7495064735412598, Validation Loss: 1.27008056640625\n",
      "Epoch 12/100, Training Loss: 3.7291674613952637, Validation Loss: 1.2714838981628418\n",
      "Early stopping triggered\n",
      "Fold 2 - R² Score: -0.2662, MAE: 0.8959\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 3.6808550357818604, Validation Loss: 1.0048705339431763\n",
      "Epoch 2/100, Training Loss: 3.6614973545074463, Validation Loss: 0.9971147775650024\n",
      "Epoch 3/100, Training Loss: 3.586031436920166, Validation Loss: 0.9919395446777344\n",
      "Epoch 4/100, Training Loss: 3.5305163860321045, Validation Loss: 0.9887006282806396\n",
      "Epoch 5/100, Training Loss: 3.4907736778259277, Validation Loss: 0.9866584539413452\n",
      "Epoch 6/100, Training Loss: 3.428898811340332, Validation Loss: 0.985341489315033\n",
      "Epoch 7/100, Training Loss: 3.389430046081543, Validation Loss: 0.9843658804893494\n",
      "Epoch 8/100, Training Loss: 3.330587863922119, Validation Loss: 0.9831408858299255\n",
      "Epoch 9/100, Training Loss: 3.3256657123565674, Validation Loss: 0.9817405343055725\n",
      "Epoch 10/100, Training Loss: 3.2792694568634033, Validation Loss: 0.979670524597168\n",
      "Epoch 11/100, Training Loss: 3.2196104526519775, Validation Loss: 0.9768496155738831\n",
      "Epoch 12/100, Training Loss: 3.1769192218780518, Validation Loss: 0.973436713218689\n",
      "Epoch 13/100, Training Loss: 3.142087936401367, Validation Loss: 0.9689593315124512\n",
      "Epoch 14/100, Training Loss: 3.1169166564941406, Validation Loss: 0.9637941122055054\n",
      "Epoch 15/100, Training Loss: 3.0540146827697754, Validation Loss: 0.95759117603302\n",
      "Epoch 16/100, Training Loss: 3.0162241458892822, Validation Loss: 0.9505969285964966\n",
      "Epoch 17/100, Training Loss: 2.9936912059783936, Validation Loss: 0.9427555203437805\n",
      "Epoch 18/100, Training Loss: 2.9478981494903564, Validation Loss: 0.9344372749328613\n",
      "Epoch 19/100, Training Loss: 2.9091575145721436, Validation Loss: 0.9248661994934082\n",
      "Epoch 20/100, Training Loss: 2.883220911026001, Validation Loss: 0.9146512746810913\n",
      "Epoch 21/100, Training Loss: 2.8419320583343506, Validation Loss: 0.9036957025527954\n",
      "Epoch 22/100, Training Loss: 2.7938010692596436, Validation Loss: 0.892358124256134\n",
      "Epoch 23/100, Training Loss: 2.781618595123291, Validation Loss: 0.8807773590087891\n",
      "Epoch 24/100, Training Loss: 2.735968828201294, Validation Loss: 0.8687983155250549\n",
      "Epoch 25/100, Training Loss: 2.6970534324645996, Validation Loss: 0.8563173413276672\n",
      "Epoch 26/100, Training Loss: 2.688854217529297, Validation Loss: 0.843197226524353\n",
      "Epoch 27/100, Training Loss: 2.6397225856781006, Validation Loss: 0.8298248648643494\n",
      "Epoch 28/100, Training Loss: 2.634678602218628, Validation Loss: 0.8165419101715088\n",
      "Epoch 29/100, Training Loss: 2.591095209121704, Validation Loss: 0.8033085465431213\n",
      "Epoch 30/100, Training Loss: 2.5728774070739746, Validation Loss: 0.789995551109314\n",
      "Epoch 31/100, Training Loss: 2.5140621662139893, Validation Loss: 0.776955783367157\n",
      "Epoch 32/100, Training Loss: 2.5162765979766846, Validation Loss: 0.7638265490531921\n",
      "Epoch 33/100, Training Loss: 2.4778635501861572, Validation Loss: 0.7508442401885986\n",
      "Epoch 34/100, Training Loss: 2.454085111618042, Validation Loss: 0.7378455996513367\n",
      "Epoch 35/100, Training Loss: 2.4251420497894287, Validation Loss: 0.7255933284759521\n",
      "Epoch 36/100, Training Loss: 2.4215521812438965, Validation Loss: 0.7130798101425171\n",
      "Epoch 37/100, Training Loss: 2.3913159370422363, Validation Loss: 0.7011259198188782\n",
      "Epoch 38/100, Training Loss: 2.3640153408050537, Validation Loss: 0.6893647313117981\n",
      "Epoch 39/100, Training Loss: 2.3363356590270996, Validation Loss: 0.6778064966201782\n",
      "Epoch 40/100, Training Loss: 2.323469400405884, Validation Loss: 0.6667370200157166\n",
      "Epoch 41/100, Training Loss: 2.3015356063842773, Validation Loss: 0.6556912064552307\n",
      "Epoch 42/100, Training Loss: 2.278247356414795, Validation Loss: 0.6454017758369446\n",
      "Epoch 43/100, Training Loss: 2.264638662338257, Validation Loss: 0.6352907419204712\n",
      "Epoch 44/100, Training Loss: 2.2217912673950195, Validation Loss: 0.6254107356071472\n",
      "Epoch 45/100, Training Loss: 2.209861993789673, Validation Loss: 0.6155928373336792\n",
      "Epoch 46/100, Training Loss: 2.187995672225952, Validation Loss: 0.6063764691352844\n",
      "Epoch 47/100, Training Loss: 2.1721506118774414, Validation Loss: 0.5970522165298462\n",
      "Epoch 48/100, Training Loss: 2.154086112976074, Validation Loss: 0.5879265069961548\n",
      "Epoch 49/100, Training Loss: 2.1587369441986084, Validation Loss: 0.5792627930641174\n",
      "Epoch 50/100, Training Loss: 2.123244524002075, Validation Loss: 0.5706298351287842\n",
      "Epoch 51/100, Training Loss: 2.112534761428833, Validation Loss: 0.5623586773872375\n",
      "Epoch 52/100, Training Loss: 2.100196361541748, Validation Loss: 0.5542812943458557\n",
      "Epoch 53/100, Training Loss: 2.078047037124634, Validation Loss: 0.5463686585426331\n",
      "Epoch 54/100, Training Loss: 2.03950834274292, Validation Loss: 0.5385079979896545\n",
      "Epoch 55/100, Training Loss: 2.025693893432617, Validation Loss: 0.5307959914207458\n",
      "Epoch 56/100, Training Loss: 2.0302207469940186, Validation Loss: 0.5233221054077148\n",
      "Epoch 57/100, Training Loss: 2.0174763202667236, Validation Loss: 0.5158807635307312\n",
      "Epoch 58/100, Training Loss: 2.009718418121338, Validation Loss: 0.5085875391960144\n",
      "Epoch 59/100, Training Loss: 1.962225079536438, Validation Loss: 0.501183807849884\n",
      "Epoch 60/100, Training Loss: 1.972902774810791, Validation Loss: 0.4941801130771637\n",
      "Epoch 61/100, Training Loss: 1.9550604820251465, Validation Loss: 0.4873650074005127\n",
      "Epoch 62/100, Training Loss: 1.9603798389434814, Validation Loss: 0.4806917607784271\n",
      "Epoch 63/100, Training Loss: 1.924878716468811, Validation Loss: 0.4740118086338043\n",
      "Epoch 64/100, Training Loss: 1.9165675640106201, Validation Loss: 0.46711045503616333\n",
      "Epoch 65/100, Training Loss: 1.9146698713302612, Validation Loss: 0.4603114128112793\n",
      "Epoch 66/100, Training Loss: 1.8913938999176025, Validation Loss: 0.4536936283111572\n",
      "Epoch 67/100, Training Loss: 1.8781638145446777, Validation Loss: 0.4471227526664734\n",
      "Epoch 68/100, Training Loss: 1.8785244226455688, Validation Loss: 0.4406605362892151\n",
      "Epoch 69/100, Training Loss: 1.8742291927337646, Validation Loss: 0.4343430697917938\n",
      "Epoch 70/100, Training Loss: 1.8457252979278564, Validation Loss: 0.4282548725605011\n",
      "Epoch 71/100, Training Loss: 1.8440883159637451, Validation Loss: 0.4223529100418091\n",
      "Epoch 72/100, Training Loss: 1.8386260271072388, Validation Loss: 0.41627755761146545\n",
      "Epoch 73/100, Training Loss: 1.843450665473938, Validation Loss: 0.4105451703071594\n",
      "Epoch 74/100, Training Loss: 1.8029652833938599, Validation Loss: 0.4045700132846832\n",
      "Epoch 75/100, Training Loss: 1.7895623445510864, Validation Loss: 0.3989541828632355\n",
      "Epoch 76/100, Training Loss: 1.7927087545394897, Validation Loss: 0.3929632604122162\n",
      "Epoch 77/100, Training Loss: 1.7944186925888062, Validation Loss: 0.38700947165489197\n",
      "Epoch 78/100, Training Loss: 1.7784379720687866, Validation Loss: 0.38164660334587097\n",
      "Epoch 79/100, Training Loss: 1.7677795886993408, Validation Loss: 0.37614157795906067\n",
      "Epoch 80/100, Training Loss: 1.759202241897583, Validation Loss: 0.37071236968040466\n",
      "Epoch 81/100, Training Loss: 1.7564910650253296, Validation Loss: 0.3654218018054962\n",
      "Epoch 82/100, Training Loss: 1.725078821182251, Validation Loss: 0.36018842458724976\n",
      "Epoch 83/100, Training Loss: 1.7220946550369263, Validation Loss: 0.3550359010696411\n",
      "Epoch 84/100, Training Loss: 1.735693097114563, Validation Loss: 0.3500480353832245\n",
      "Epoch 85/100, Training Loss: 1.739344596862793, Validation Loss: 0.34530502557754517\n",
      "Epoch 86/100, Training Loss: 1.6890591382980347, Validation Loss: 0.34027135372161865\n",
      "Epoch 87/100, Training Loss: 1.6965843439102173, Validation Loss: 0.3354625403881073\n",
      "Epoch 88/100, Training Loss: 1.6845245361328125, Validation Loss: 0.33071932196617126\n",
      "Epoch 89/100, Training Loss: 1.6737040281295776, Validation Loss: 0.3260393440723419\n",
      "Epoch 90/100, Training Loss: 1.6848957538604736, Validation Loss: 0.3214723467826843\n",
      "Epoch 91/100, Training Loss: 1.663067102432251, Validation Loss: 0.31698495149612427\n",
      "Epoch 92/100, Training Loss: 1.6597232818603516, Validation Loss: 0.3125520348548889\n",
      "Epoch 93/100, Training Loss: 1.669869303703308, Validation Loss: 0.30827611684799194\n",
      "Epoch 94/100, Training Loss: 1.6374682188034058, Validation Loss: 0.30396872758865356\n",
      "Epoch 95/100, Training Loss: 1.631289005279541, Validation Loss: 0.2998773157596588\n",
      "Epoch 96/100, Training Loss: 1.625133752822876, Validation Loss: 0.2956436276435852\n",
      "Epoch 97/100, Training Loss: 1.6512194871902466, Validation Loss: 0.29172903299331665\n",
      "Epoch 98/100, Training Loss: 1.6381328105926514, Validation Loss: 0.28796452283859253\n",
      "Epoch 99/100, Training Loss: 1.6173900365829468, Validation Loss: 0.2840390205383301\n",
      "Epoch 100/100, Training Loss: 1.6100443601608276, Validation Loss: 0.2802574038505554\n",
      "Fold 3 - R² Score: 0.7173, MAE: 0.3566\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 2.638207197189331, Validation Loss: 1.0756909847259521\n",
      "Epoch 2/100, Training Loss: 2.629117727279663, Validation Loss: 1.0752100944519043\n",
      "Epoch 3/100, Training Loss: 2.5910134315490723, Validation Loss: 1.0753920078277588\n",
      "Epoch 4/100, Training Loss: 2.5693459510803223, Validation Loss: 1.075748324394226\n",
      "Epoch 5/100, Training Loss: 2.5304465293884277, Validation Loss: 1.0759327411651611\n",
      "Epoch 6/100, Training Loss: 2.5102641582489014, Validation Loss: 1.0759464502334595\n",
      "Epoch 7/100, Training Loss: 2.477163076400757, Validation Loss: 1.0755727291107178\n",
      "Epoch 8/100, Training Loss: 2.4158315658569336, Validation Loss: 1.0746484994888306\n",
      "Epoch 9/100, Training Loss: 2.419372081756592, Validation Loss: 1.0728002786636353\n",
      "Epoch 10/100, Training Loss: 2.395165205001831, Validation Loss: 1.0701104402542114\n",
      "Epoch 11/100, Training Loss: 2.3588905334472656, Validation Loss: 1.0660507678985596\n",
      "Epoch 12/100, Training Loss: 2.2967264652252197, Validation Loss: 1.0605854988098145\n",
      "Epoch 13/100, Training Loss: 2.269641876220703, Validation Loss: 1.0537033081054688\n",
      "Epoch 14/100, Training Loss: 2.2652580738067627, Validation Loss: 1.045774221420288\n",
      "Epoch 15/100, Training Loss: 2.253551721572876, Validation Loss: 1.036231517791748\n",
      "Epoch 16/100, Training Loss: 2.2243752479553223, Validation Loss: 1.0248870849609375\n",
      "Epoch 17/100, Training Loss: 2.198331832885742, Validation Loss: 1.0122864246368408\n",
      "Epoch 18/100, Training Loss: 2.156359910964966, Validation Loss: 0.9982501268386841\n",
      "Epoch 19/100, Training Loss: 2.147329092025757, Validation Loss: 0.9828318357467651\n",
      "Epoch 20/100, Training Loss: 2.1301000118255615, Validation Loss: 0.9656676054000854\n",
      "Epoch 21/100, Training Loss: 2.0778424739837646, Validation Loss: 0.9470352530479431\n",
      "Epoch 22/100, Training Loss: 2.0719590187072754, Validation Loss: 0.9274321794509888\n",
      "Epoch 23/100, Training Loss: 2.0407416820526123, Validation Loss: 0.9063562750816345\n",
      "Epoch 24/100, Training Loss: 2.0108041763305664, Validation Loss: 0.8846276998519897\n",
      "Epoch 25/100, Training Loss: 2.008122682571411, Validation Loss: 0.8618069887161255\n",
      "Epoch 26/100, Training Loss: 1.9588840007781982, Validation Loss: 0.8381308913230896\n",
      "Epoch 27/100, Training Loss: 1.968250036239624, Validation Loss: 0.8138375282287598\n",
      "Epoch 28/100, Training Loss: 1.9510136842727661, Validation Loss: 0.7890348434448242\n",
      "Epoch 29/100, Training Loss: 1.9185985326766968, Validation Loss: 0.7641514539718628\n",
      "Epoch 30/100, Training Loss: 1.9004288911819458, Validation Loss: 0.7389740347862244\n",
      "Epoch 31/100, Training Loss: 1.8869225978851318, Validation Loss: 0.7136816382408142\n",
      "Epoch 32/100, Training Loss: 1.8905837535858154, Validation Loss: 0.6883237957954407\n",
      "Epoch 33/100, Training Loss: 1.8515316247940063, Validation Loss: 0.6630665063858032\n",
      "Epoch 34/100, Training Loss: 1.8401572704315186, Validation Loss: 0.6379903554916382\n",
      "Epoch 35/100, Training Loss: 1.844870686531067, Validation Loss: 0.6134514212608337\n",
      "Epoch 36/100, Training Loss: 1.8121885061264038, Validation Loss: 0.5894912481307983\n",
      "Epoch 37/100, Training Loss: 1.8080228567123413, Validation Loss: 0.5661745667457581\n",
      "Epoch 38/100, Training Loss: 1.7771756649017334, Validation Loss: 0.5431541800498962\n",
      "Epoch 39/100, Training Loss: 1.7411259412765503, Validation Loss: 0.5208298563957214\n",
      "Epoch 40/100, Training Loss: 1.751526117324829, Validation Loss: 0.49919071793556213\n",
      "Epoch 41/100, Training Loss: 1.7345138788223267, Validation Loss: 0.4782571792602539\n",
      "Epoch 42/100, Training Loss: 1.7147150039672852, Validation Loss: 0.45793628692626953\n",
      "Epoch 43/100, Training Loss: 1.7297186851501465, Validation Loss: 0.43848496675491333\n",
      "Epoch 44/100, Training Loss: 1.689266562461853, Validation Loss: 0.41968834400177\n",
      "Epoch 45/100, Training Loss: 1.705296516418457, Validation Loss: 0.4016134738922119\n",
      "Epoch 46/100, Training Loss: 1.672820806503296, Validation Loss: 0.3845389187335968\n",
      "Epoch 47/100, Training Loss: 1.6485928297042847, Validation Loss: 0.3685280978679657\n",
      "Epoch 48/100, Training Loss: 1.6570210456848145, Validation Loss: 0.35303056240081787\n",
      "Epoch 49/100, Training Loss: 1.629280924797058, Validation Loss: 0.33856385946273804\n",
      "Epoch 50/100, Training Loss: 1.6275750398635864, Validation Loss: 0.32466769218444824\n",
      "Epoch 51/100, Training Loss: 1.618430495262146, Validation Loss: 0.3120174705982208\n",
      "Epoch 52/100, Training Loss: 1.5909494161605835, Validation Loss: 0.29995232820510864\n",
      "Epoch 53/100, Training Loss: 1.5915210247039795, Validation Loss: 0.2885349988937378\n",
      "Epoch 54/100, Training Loss: 1.5737351179122925, Validation Loss: 0.2779466509819031\n",
      "Epoch 55/100, Training Loss: 1.5691862106323242, Validation Loss: 0.2680288553237915\n",
      "Epoch 56/100, Training Loss: 1.5475469827651978, Validation Loss: 0.2586992084980011\n",
      "Epoch 57/100, Training Loss: 1.5421409606933594, Validation Loss: 0.2498331516981125\n",
      "Epoch 58/100, Training Loss: 1.5280756950378418, Validation Loss: 0.24141232669353485\n",
      "Epoch 59/100, Training Loss: 1.5496374368667603, Validation Loss: 0.23363836109638214\n",
      "Epoch 60/100, Training Loss: 1.5263099670410156, Validation Loss: 0.2263648957014084\n",
      "Epoch 61/100, Training Loss: 1.5177862644195557, Validation Loss: 0.21944361925125122\n",
      "Epoch 62/100, Training Loss: 1.5179935693740845, Validation Loss: 0.21285858750343323\n",
      "Epoch 63/100, Training Loss: 1.504907488822937, Validation Loss: 0.20674733817577362\n",
      "Epoch 64/100, Training Loss: 1.4940252304077148, Validation Loss: 0.20117808878421783\n",
      "Epoch 65/100, Training Loss: 1.4669690132141113, Validation Loss: 0.19578373432159424\n",
      "Epoch 66/100, Training Loss: 1.4722092151641846, Validation Loss: 0.1905289590358734\n",
      "Epoch 67/100, Training Loss: 1.4608732461929321, Validation Loss: 0.185635507106781\n",
      "Epoch 68/100, Training Loss: 1.4686976671218872, Validation Loss: 0.1810787171125412\n",
      "Epoch 69/100, Training Loss: 1.462450385093689, Validation Loss: 0.1766471117734909\n",
      "Epoch 70/100, Training Loss: 1.4608973264694214, Validation Loss: 0.1725389063358307\n",
      "Epoch 71/100, Training Loss: 1.453345537185669, Validation Loss: 0.16854991018772125\n",
      "Epoch 72/100, Training Loss: 1.426347017288208, Validation Loss: 0.16485220193862915\n",
      "Epoch 73/100, Training Loss: 1.4271235466003418, Validation Loss: 0.16112415492534637\n",
      "Epoch 74/100, Training Loss: 1.429308295249939, Validation Loss: 0.15769784152507782\n",
      "Epoch 75/100, Training Loss: 1.419356346130371, Validation Loss: 0.15424609184265137\n",
      "Epoch 76/100, Training Loss: 1.3926295042037964, Validation Loss: 0.1510930359363556\n",
      "Epoch 77/100, Training Loss: 1.4095507860183716, Validation Loss: 0.14814446866512299\n",
      "Epoch 78/100, Training Loss: 1.3982394933700562, Validation Loss: 0.14517347514629364\n",
      "Epoch 79/100, Training Loss: 1.396252989768982, Validation Loss: 0.14235946536064148\n",
      "Epoch 80/100, Training Loss: 1.3690613508224487, Validation Loss: 0.13961853086948395\n",
      "Epoch 81/100, Training Loss: 1.3902326822280884, Validation Loss: 0.1370694786310196\n",
      "Epoch 82/100, Training Loss: 1.3978137969970703, Validation Loss: 0.13450804352760315\n",
      "Epoch 83/100, Training Loss: 1.37619948387146, Validation Loss: 0.13204382359981537\n",
      "Epoch 84/100, Training Loss: 1.362810492515564, Validation Loss: 0.12972010672092438\n",
      "Epoch 85/100, Training Loss: 1.351709008216858, Validation Loss: 0.12748000025749207\n",
      "Epoch 86/100, Training Loss: 1.3659416437149048, Validation Loss: 0.1253804713487625\n",
      "Epoch 87/100, Training Loss: 1.3669579029083252, Validation Loss: 0.12324704974889755\n",
      "Epoch 88/100, Training Loss: 1.3420225381851196, Validation Loss: 0.12120505422353745\n",
      "Epoch 89/100, Training Loss: 1.334930658340454, Validation Loss: 0.11927212029695511\n",
      "Epoch 90/100, Training Loss: 1.3381993770599365, Validation Loss: 0.11740656197071075\n",
      "Epoch 91/100, Training Loss: 1.3281033039093018, Validation Loss: 0.11569656431674957\n",
      "Epoch 92/100, Training Loss: 1.3161667585372925, Validation Loss: 0.1139148622751236\n",
      "Epoch 93/100, Training Loss: 1.3263734579086304, Validation Loss: 0.11227049678564072\n",
      "Epoch 94/100, Training Loss: 1.319568157196045, Validation Loss: 0.11060536652803421\n",
      "Epoch 95/100, Training Loss: 1.3057464361190796, Validation Loss: 0.10901836305856705\n",
      "Epoch 96/100, Training Loss: 1.3078328371047974, Validation Loss: 0.10750362277030945\n",
      "Epoch 97/100, Training Loss: 1.3117741346359253, Validation Loss: 0.10597839206457138\n",
      "Epoch 98/100, Training Loss: 1.3083744049072266, Validation Loss: 0.10455594211816788\n",
      "Epoch 99/100, Training Loss: 1.3036006689071655, Validation Loss: 0.10322204977273941\n",
      "Epoch 100/100, Training Loss: 1.3046246767044067, Validation Loss: 0.10186559706926346\n",
      "Fold 4 - R² Score: 0.8986, MAE: 0.2139\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 4.372838497161865, Validation Loss: 1.1981301307678223\n",
      "Epoch 2/100, Training Loss: 4.324790000915527, Validation Loss: 1.2066564559936523\n",
      "Epoch 3/100, Training Loss: 4.224643707275391, Validation Loss: 1.227678894996643\n",
      "Epoch 4/100, Training Loss: 4.226648807525635, Validation Loss: 1.2584573030471802\n",
      "Epoch 5/100, Training Loss: 4.212835788726807, Validation Loss: 1.296432375907898\n",
      "Epoch 6/100, Training Loss: 4.13459587097168, Validation Loss: 1.3393378257751465\n",
      "Epoch 7/100, Training Loss: 4.034801483154297, Validation Loss: 1.3849059343338013\n",
      "Epoch 8/100, Training Loss: 4.017581939697266, Validation Loss: 1.431653380393982\n",
      "Epoch 9/100, Training Loss: 3.9462826251983643, Validation Loss: 1.4782987833023071\n",
      "Epoch 10/100, Training Loss: 3.9018077850341797, Validation Loss: 1.523163914680481\n",
      "Epoch 11/100, Training Loss: 3.834102153778076, Validation Loss: 1.565334677696228\n",
      "Early stopping triggered\n",
      "Fold 5 - R² Score: -0.5648, MAE: 0.9668\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 64, 'learning_rate': 0.001}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 3.5991945266723633, Validation Loss: 1.0629777908325195\n",
      "Epoch 2/100, Training Loss: 3.206616163253784, Validation Loss: 1.0194976329803467\n",
      "Epoch 3/100, Training Loss: 2.847461462020874, Validation Loss: 0.9800497889518738\n",
      "Epoch 4/100, Training Loss: 2.5344958305358887, Validation Loss: 0.9425647258758545\n",
      "Epoch 5/100, Training Loss: 2.2827632427215576, Validation Loss: 0.9058887362480164\n",
      "Epoch 6/100, Training Loss: 2.0639665126800537, Validation Loss: 0.869856059551239\n",
      "Epoch 7/100, Training Loss: 1.904025673866272, Validation Loss: 0.8341522216796875\n",
      "Epoch 8/100, Training Loss: 1.7842406034469604, Validation Loss: 0.798595130443573\n",
      "Epoch 9/100, Training Loss: 1.6565816402435303, Validation Loss: 0.7629833221435547\n",
      "Epoch 10/100, Training Loss: 1.5897454023361206, Validation Loss: 0.7275553941726685\n",
      "Epoch 11/100, Training Loss: 1.5178931951522827, Validation Loss: 0.6925419569015503\n",
      "Epoch 12/100, Training Loss: 1.4976341724395752, Validation Loss: 0.6577380299568176\n",
      "Epoch 13/100, Training Loss: 1.420986294746399, Validation Loss: 0.6234716176986694\n",
      "Epoch 14/100, Training Loss: 1.3926584720611572, Validation Loss: 0.5896145701408386\n",
      "Epoch 15/100, Training Loss: 1.377631664276123, Validation Loss: 0.5570011138916016\n",
      "Epoch 16/100, Training Loss: 1.3330864906311035, Validation Loss: 0.5251384377479553\n",
      "Epoch 17/100, Training Loss: 1.304726004600525, Validation Loss: 0.49397894740104675\n",
      "Epoch 18/100, Training Loss: 1.2829639911651611, Validation Loss: 0.4639839828014374\n",
      "Epoch 19/100, Training Loss: 1.2565083503723145, Validation Loss: 0.43537357449531555\n",
      "Epoch 20/100, Training Loss: 1.2253419160842896, Validation Loss: 0.4085732698440552\n",
      "Epoch 21/100, Training Loss: 1.1867610216140747, Validation Loss: 0.38387802243232727\n",
      "Epoch 22/100, Training Loss: 1.1702502965927124, Validation Loss: 0.36069315671920776\n",
      "Epoch 23/100, Training Loss: 1.1242190599441528, Validation Loss: 0.33958274126052856\n",
      "Epoch 24/100, Training Loss: 1.1036797761917114, Validation Loss: 0.3201420307159424\n",
      "Epoch 25/100, Training Loss: 1.0694113969802856, Validation Loss: 0.301954984664917\n",
      "Epoch 26/100, Training Loss: 1.0320707559585571, Validation Loss: 0.2853703200817108\n",
      "Epoch 27/100, Training Loss: 1.0263209342956543, Validation Loss: 0.27019214630126953\n",
      "Epoch 28/100, Training Loss: 0.998644232749939, Validation Loss: 0.25602811574935913\n",
      "Epoch 29/100, Training Loss: 0.9861578941345215, Validation Loss: 0.24284608662128448\n",
      "Epoch 30/100, Training Loss: 0.9678158164024353, Validation Loss: 0.23045635223388672\n",
      "Epoch 31/100, Training Loss: 0.937705934047699, Validation Loss: 0.21875403821468353\n",
      "Epoch 32/100, Training Loss: 0.9363150596618652, Validation Loss: 0.20753037929534912\n",
      "Epoch 33/100, Training Loss: 0.9231372475624084, Validation Loss: 0.19654378294944763\n",
      "Epoch 34/100, Training Loss: 0.9021162986755371, Validation Loss: 0.18598294258117676\n",
      "Epoch 35/100, Training Loss: 0.8842175006866455, Validation Loss: 0.1754724383354187\n",
      "Epoch 36/100, Training Loss: 0.87290358543396, Validation Loss: 0.1649535894393921\n",
      "Epoch 37/100, Training Loss: 0.8608542680740356, Validation Loss: 0.15466642379760742\n",
      "Epoch 38/100, Training Loss: 0.845911979675293, Validation Loss: 0.1444845199584961\n",
      "Epoch 39/100, Training Loss: 0.8279639482498169, Validation Loss: 0.1342950165271759\n",
      "Epoch 40/100, Training Loss: 0.8322663903236389, Validation Loss: 0.12417671829462051\n",
      "Epoch 41/100, Training Loss: 0.8072054386138916, Validation Loss: 0.1139640137553215\n",
      "Epoch 42/100, Training Loss: 0.8064351677894592, Validation Loss: 0.10431809723377228\n",
      "Epoch 43/100, Training Loss: 0.7913113832473755, Validation Loss: 0.09521444886922836\n",
      "Epoch 44/100, Training Loss: 0.7784861922264099, Validation Loss: 0.08640854060649872\n",
      "Epoch 45/100, Training Loss: 0.7856695652008057, Validation Loss: 0.07813496142625809\n",
      "Epoch 46/100, Training Loss: 0.7624552249908447, Validation Loss: 0.07049210369586945\n",
      "Epoch 47/100, Training Loss: 0.748744010925293, Validation Loss: 0.06365132331848145\n",
      "Epoch 48/100, Training Loss: 0.7475247383117676, Validation Loss: 0.05759621039032936\n",
      "Epoch 49/100, Training Loss: 0.7365362048149109, Validation Loss: 0.05219068005681038\n",
      "Epoch 50/100, Training Loss: 0.7273449301719666, Validation Loss: 0.047331925481557846\n",
      "Epoch 51/100, Training Loss: 0.70963054895401, Validation Loss: 0.04306282475590706\n",
      "Epoch 52/100, Training Loss: 0.7037670612335205, Validation Loss: 0.03937210515141487\n",
      "Epoch 53/100, Training Loss: 0.70017009973526, Validation Loss: 0.03626001253724098\n",
      "Epoch 54/100, Training Loss: 0.6871549487113953, Validation Loss: 0.033749137073755264\n",
      "Epoch 55/100, Training Loss: 0.679144024848938, Validation Loss: 0.031757108867168427\n",
      "Epoch 56/100, Training Loss: 0.6732540726661682, Validation Loss: 0.03012610785663128\n",
      "Epoch 57/100, Training Loss: 0.6632674336433411, Validation Loss: 0.02887687087059021\n",
      "Epoch 58/100, Training Loss: 0.6580466032028198, Validation Loss: 0.027835901826620102\n",
      "Epoch 59/100, Training Loss: 0.6514744162559509, Validation Loss: 0.026921141892671585\n",
      "Epoch 60/100, Training Loss: 0.6390347480773926, Validation Loss: 0.026055539026856422\n",
      "Epoch 61/100, Training Loss: 0.6423781514167786, Validation Loss: 0.02521584928035736\n",
      "Epoch 62/100, Training Loss: 0.6325371861457825, Validation Loss: 0.02445734106004238\n",
      "Epoch 63/100, Training Loss: 0.6232085824012756, Validation Loss: 0.023671196773648262\n",
      "Epoch 64/100, Training Loss: 0.6273565292358398, Validation Loss: 0.02287643402814865\n",
      "Epoch 65/100, Training Loss: 0.6208882927894592, Validation Loss: 0.022113319486379623\n",
      "Epoch 66/100, Training Loss: 0.6084105968475342, Validation Loss: 0.02134150266647339\n",
      "Epoch 67/100, Training Loss: 0.5978966951370239, Validation Loss: 0.02066580392420292\n",
      "Epoch 68/100, Training Loss: 0.6067420840263367, Validation Loss: 0.020089806988835335\n",
      "Epoch 69/100, Training Loss: 0.590815007686615, Validation Loss: 0.019518021494150162\n",
      "Epoch 70/100, Training Loss: 0.5933451056480408, Validation Loss: 0.019005537033081055\n",
      "Epoch 71/100, Training Loss: 0.5754607319831848, Validation Loss: 0.018606161698698997\n",
      "Epoch 72/100, Training Loss: 0.5759414434432983, Validation Loss: 0.018355518579483032\n",
      "Epoch 73/100, Training Loss: 0.5717255473136902, Validation Loss: 0.018050970509648323\n",
      "Epoch 74/100, Training Loss: 0.5624352097511292, Validation Loss: 0.017882367596030235\n",
      "Epoch 75/100, Training Loss: 0.5602076649665833, Validation Loss: 0.017709562554955482\n",
      "Epoch 76/100, Training Loss: 0.550805389881134, Validation Loss: 0.01747722737491131\n",
      "Epoch 77/100, Training Loss: 0.5532279014587402, Validation Loss: 0.01729009859263897\n",
      "Epoch 78/100, Training Loss: 0.5460934638977051, Validation Loss: 0.017073430120944977\n",
      "Epoch 79/100, Training Loss: 0.5458576083183289, Validation Loss: 0.016859855502843857\n",
      "Epoch 80/100, Training Loss: 0.5336535573005676, Validation Loss: 0.016653012484312057\n",
      "Epoch 81/100, Training Loss: 0.5267077088356018, Validation Loss: 0.01641210727393627\n",
      "Epoch 82/100, Training Loss: 0.5217499732971191, Validation Loss: 0.01626741886138916\n",
      "Epoch 83/100, Training Loss: 0.5261600017547607, Validation Loss: 0.016133008524775505\n",
      "Epoch 84/100, Training Loss: 0.5139333009719849, Validation Loss: 0.01597350835800171\n",
      "Epoch 85/100, Training Loss: 0.5183305144309998, Validation Loss: 0.015808869153261185\n",
      "Epoch 86/100, Training Loss: 0.5085001587867737, Validation Loss: 0.015666939318180084\n",
      "Epoch 87/100, Training Loss: 0.5024584531784058, Validation Loss: 0.015491831116378307\n",
      "Epoch 88/100, Training Loss: 0.5035849809646606, Validation Loss: 0.015229801647365093\n",
      "Epoch 89/100, Training Loss: 0.49430790543556213, Validation Loss: 0.014919017441570759\n",
      "Epoch 90/100, Training Loss: 0.49150341749191284, Validation Loss: 0.01464419811964035\n",
      "Epoch 91/100, Training Loss: 0.49206817150115967, Validation Loss: 0.01440506149083376\n",
      "Epoch 92/100, Training Loss: 0.47767528891563416, Validation Loss: 0.014244824647903442\n",
      "Epoch 93/100, Training Loss: 0.47992974519729614, Validation Loss: 0.014099599793553352\n",
      "Epoch 94/100, Training Loss: 0.47093459963798523, Validation Loss: 0.014054980129003525\n",
      "Epoch 95/100, Training Loss: 0.4635786712169647, Validation Loss: 0.013969890773296356\n",
      "Epoch 96/100, Training Loss: 0.46677979826927185, Validation Loss: 0.01396693754941225\n",
      "Epoch 97/100, Training Loss: 0.4623848497867584, Validation Loss: 0.013933368027210236\n",
      "Epoch 98/100, Training Loss: 0.45940202474594116, Validation Loss: 0.013803317211568356\n",
      "Epoch 99/100, Training Loss: 0.4542998969554901, Validation Loss: 0.013639594428241253\n",
      "Epoch 100/100, Training Loss: 0.45271366834640503, Validation Loss: 0.013399399816989899\n",
      "Fold 1 - R² Score: 0.9866, MAE: 0.0784\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 3.5766687393188477, Validation Loss: 0.8860397934913635\n",
      "Epoch 2/100, Training Loss: 3.0828566551208496, Validation Loss: 0.8438673615455627\n",
      "Epoch 3/100, Training Loss: 2.7187418937683105, Validation Loss: 0.8073803782463074\n",
      "Epoch 4/100, Training Loss: 2.392545223236084, Validation Loss: 0.7749532461166382\n",
      "Epoch 5/100, Training Loss: 2.157410144805908, Validation Loss: 0.7453219294548035\n",
      "Epoch 6/100, Training Loss: 1.979461908340454, Validation Loss: 0.7171322107315063\n",
      "Epoch 7/100, Training Loss: 1.8358803987503052, Validation Loss: 0.6890602111816406\n",
      "Epoch 8/100, Training Loss: 1.7326542139053345, Validation Loss: 0.6610212326049805\n",
      "Epoch 9/100, Training Loss: 1.6913366317749023, Validation Loss: 0.6331288814544678\n",
      "Epoch 10/100, Training Loss: 1.6269466876983643, Validation Loss: 0.6059564352035522\n",
      "Epoch 11/100, Training Loss: 1.5879034996032715, Validation Loss: 0.5802482962608337\n",
      "Epoch 12/100, Training Loss: 1.5654946565628052, Validation Loss: 0.5562792420387268\n",
      "Epoch 13/100, Training Loss: 1.5258773565292358, Validation Loss: 0.5341143012046814\n",
      "Epoch 14/100, Training Loss: 1.4734891653060913, Validation Loss: 0.5137428045272827\n",
      "Epoch 15/100, Training Loss: 1.4497400522232056, Validation Loss: 0.4948362112045288\n",
      "Epoch 16/100, Training Loss: 1.410368800163269, Validation Loss: 0.47785693407058716\n",
      "Epoch 17/100, Training Loss: 1.3595298528671265, Validation Loss: 0.462758868932724\n",
      "Epoch 18/100, Training Loss: 1.320989727973938, Validation Loss: 0.4491299092769623\n",
      "Epoch 19/100, Training Loss: 1.2720831632614136, Validation Loss: 0.4361228346824646\n",
      "Epoch 20/100, Training Loss: 1.2385737895965576, Validation Loss: 0.42386144399642944\n",
      "Epoch 21/100, Training Loss: 1.2260724306106567, Validation Loss: 0.4118252396583557\n",
      "Epoch 22/100, Training Loss: 1.1943899393081665, Validation Loss: 0.39946267008781433\n",
      "Epoch 23/100, Training Loss: 1.1771272420883179, Validation Loss: 0.3865099847316742\n",
      "Epoch 24/100, Training Loss: 1.1709654331207275, Validation Loss: 0.3727666139602661\n",
      "Epoch 25/100, Training Loss: 1.1380051374435425, Validation Loss: 0.35765549540519714\n",
      "Epoch 26/100, Training Loss: 1.1117165088653564, Validation Loss: 0.34119993448257446\n",
      "Epoch 27/100, Training Loss: 1.0936301946640015, Validation Loss: 0.323384553194046\n",
      "Epoch 28/100, Training Loss: 1.0876877307891846, Validation Loss: 0.30403435230255127\n",
      "Epoch 29/100, Training Loss: 1.0611752271652222, Validation Loss: 0.2835574448108673\n",
      "Epoch 30/100, Training Loss: 1.048422932624817, Validation Loss: 0.2623582184314728\n",
      "Epoch 31/100, Training Loss: 1.025493860244751, Validation Loss: 0.24077096581459045\n",
      "Epoch 32/100, Training Loss: 1.0131553411483765, Validation Loss: 0.21952345967292786\n",
      "Epoch 33/100, Training Loss: 0.9916309118270874, Validation Loss: 0.19905918836593628\n",
      "Epoch 34/100, Training Loss: 0.9815908670425415, Validation Loss: 0.1796080321073532\n",
      "Epoch 35/100, Training Loss: 0.9617204666137695, Validation Loss: 0.16123832762241364\n",
      "Epoch 36/100, Training Loss: 0.9505598545074463, Validation Loss: 0.14434599876403809\n",
      "Epoch 37/100, Training Loss: 0.9390314221382141, Validation Loss: 0.1294678896665573\n",
      "Epoch 38/100, Training Loss: 0.9268268942832947, Validation Loss: 0.11641465127468109\n",
      "Epoch 39/100, Training Loss: 0.9032685160636902, Validation Loss: 0.10500524938106537\n",
      "Epoch 40/100, Training Loss: 0.891503632068634, Validation Loss: 0.09526591002941132\n",
      "Epoch 41/100, Training Loss: 0.8825149536132812, Validation Loss: 0.08686473220586777\n",
      "Epoch 42/100, Training Loss: 0.8678641319274902, Validation Loss: 0.07970884442329407\n",
      "Epoch 43/100, Training Loss: 0.8656917214393616, Validation Loss: 0.07361156493425369\n",
      "Epoch 44/100, Training Loss: 0.8447291851043701, Validation Loss: 0.06840381026268005\n",
      "Epoch 45/100, Training Loss: 0.8397758603096008, Validation Loss: 0.06391167640686035\n",
      "Epoch 46/100, Training Loss: 0.8216760754585266, Validation Loss: 0.06005721539258957\n",
      "Epoch 47/100, Training Loss: 0.8141272068023682, Validation Loss: 0.05663660168647766\n",
      "Epoch 48/100, Training Loss: 0.8055298328399658, Validation Loss: 0.05355888605117798\n",
      "Epoch 49/100, Training Loss: 0.797309398651123, Validation Loss: 0.05085832253098488\n",
      "Epoch 50/100, Training Loss: 0.7836462259292603, Validation Loss: 0.04842422157526016\n",
      "Epoch 51/100, Training Loss: 0.7822684645652771, Validation Loss: 0.046196646988391876\n",
      "Epoch 52/100, Training Loss: 0.7599279284477234, Validation Loss: 0.04419192671775818\n",
      "Epoch 53/100, Training Loss: 0.7627259492874146, Validation Loss: 0.04234660416841507\n",
      "Epoch 54/100, Training Loss: 0.748775839805603, Validation Loss: 0.040618788450956345\n",
      "Epoch 55/100, Training Loss: 0.7476226091384888, Validation Loss: 0.03905945643782616\n",
      "Epoch 56/100, Training Loss: 0.7332634329795837, Validation Loss: 0.0376417450606823\n",
      "Epoch 57/100, Training Loss: 0.7245815396308899, Validation Loss: 0.036330804228782654\n",
      "Epoch 58/100, Training Loss: 0.723022997379303, Validation Loss: 0.03513583540916443\n",
      "Epoch 59/100, Training Loss: 0.7137617468833923, Validation Loss: 0.03396938368678093\n",
      "Epoch 60/100, Training Loss: 0.7052660584449768, Validation Loss: 0.03286070376634598\n",
      "Epoch 61/100, Training Loss: 0.6928700804710388, Validation Loss: 0.03178195282816887\n",
      "Epoch 62/100, Training Loss: 0.6836929321289062, Validation Loss: 0.030713185667991638\n",
      "Epoch 63/100, Training Loss: 0.6821275949478149, Validation Loss: 0.029665758833289146\n",
      "Epoch 64/100, Training Loss: 0.6806282997131348, Validation Loss: 0.02873002178966999\n",
      "Epoch 65/100, Training Loss: 0.6755516529083252, Validation Loss: 0.027854016050696373\n",
      "Epoch 66/100, Training Loss: 0.6618301868438721, Validation Loss: 0.027035532519221306\n",
      "Epoch 67/100, Training Loss: 0.6581047773361206, Validation Loss: 0.026283198967576027\n",
      "Epoch 68/100, Training Loss: 0.6503661870956421, Validation Loss: 0.02561725676059723\n",
      "Epoch 69/100, Training Loss: 0.6397264003753662, Validation Loss: 0.02500508725643158\n",
      "Epoch 70/100, Training Loss: 0.6388116478919983, Validation Loss: 0.024454372003674507\n",
      "Epoch 71/100, Training Loss: 0.6324822902679443, Validation Loss: 0.02393992990255356\n",
      "Epoch 72/100, Training Loss: 0.6264322400093079, Validation Loss: 0.02347644604742527\n",
      "Epoch 73/100, Training Loss: 0.6229856610298157, Validation Loss: 0.023058509454131126\n",
      "Epoch 74/100, Training Loss: 0.6123450398445129, Validation Loss: 0.02264365740120411\n",
      "Epoch 75/100, Training Loss: 0.6100170612335205, Validation Loss: 0.0222613625228405\n",
      "Epoch 76/100, Training Loss: 0.6007064580917358, Validation Loss: 0.021868404000997543\n",
      "Epoch 77/100, Training Loss: 0.5939232707023621, Validation Loss: 0.02152930572628975\n",
      "Epoch 78/100, Training Loss: 0.5882014632225037, Validation Loss: 0.02119411528110504\n",
      "Epoch 79/100, Training Loss: 0.5846509337425232, Validation Loss: 0.020847680047154427\n",
      "Epoch 80/100, Training Loss: 0.5908764004707336, Validation Loss: 0.02050846628844738\n",
      "Epoch 81/100, Training Loss: 0.5805040001869202, Validation Loss: 0.0202233474701643\n",
      "Epoch 82/100, Training Loss: 0.5751517415046692, Validation Loss: 0.019932199269533157\n",
      "Epoch 83/100, Training Loss: 0.5597031712532043, Validation Loss: 0.019654637202620506\n",
      "Epoch 84/100, Training Loss: 0.5622158050537109, Validation Loss: 0.019375791773200035\n",
      "Epoch 85/100, Training Loss: 0.5588945150375366, Validation Loss: 0.019083483144640923\n",
      "Epoch 86/100, Training Loss: 0.5532474517822266, Validation Loss: 0.01878521963953972\n",
      "Epoch 87/100, Training Loss: 0.5441023707389832, Validation Loss: 0.018521780148148537\n",
      "Epoch 88/100, Training Loss: 0.54360032081604, Validation Loss: 0.018256090581417084\n",
      "Epoch 89/100, Training Loss: 0.536617636680603, Validation Loss: 0.018008699640631676\n",
      "Epoch 90/100, Training Loss: 0.5305043458938599, Validation Loss: 0.017730243504047394\n",
      "Epoch 91/100, Training Loss: 0.526599109172821, Validation Loss: 0.017450684681534767\n",
      "Epoch 92/100, Training Loss: 0.5217853784561157, Validation Loss: 0.017167508602142334\n",
      "Epoch 93/100, Training Loss: 0.516936182975769, Validation Loss: 0.016912411898374557\n",
      "Epoch 94/100, Training Loss: 0.5173283815383911, Validation Loss: 0.016637006774544716\n",
      "Epoch 95/100, Training Loss: 0.5080732107162476, Validation Loss: 0.01639205776154995\n",
      "Epoch 96/100, Training Loss: 0.5042048096656799, Validation Loss: 0.01617732271552086\n",
      "Epoch 97/100, Training Loss: 0.503326952457428, Validation Loss: 0.015977194532752037\n",
      "Epoch 98/100, Training Loss: 0.501255452632904, Validation Loss: 0.01578211598098278\n",
      "Epoch 99/100, Training Loss: 0.4922815263271332, Validation Loss: 0.015605660155415535\n",
      "Epoch 100/100, Training Loss: 0.49146994948387146, Validation Loss: 0.01542037446051836\n",
      "Fold 2 - R² Score: 0.9847, MAE: 0.0884\n",
      "Fold 3/5\n",
      "Epoch 1/100, Training Loss: 3.5606679916381836, Validation Loss: 0.9449779987335205\n",
      "Epoch 2/100, Training Loss: 3.1300132274627686, Validation Loss: 0.9081911444664001\n",
      "Epoch 3/100, Training Loss: 2.772516965866089, Validation Loss: 0.8744493126869202\n",
      "Epoch 4/100, Training Loss: 2.4971978664398193, Validation Loss: 0.8431522250175476\n",
      "Epoch 5/100, Training Loss: 2.2085111141204834, Validation Loss: 0.8129839897155762\n",
      "Epoch 6/100, Training Loss: 1.9998425245285034, Validation Loss: 0.7844783663749695\n",
      "Epoch 7/100, Training Loss: 1.8430218696594238, Validation Loss: 0.7573598623275757\n",
      "Epoch 8/100, Training Loss: 1.7021756172180176, Validation Loss: 0.731329083442688\n",
      "Epoch 9/100, Training Loss: 1.5980051755905151, Validation Loss: 0.7060973644256592\n",
      "Epoch 10/100, Training Loss: 1.5372282266616821, Validation Loss: 0.6829056739807129\n",
      "Epoch 11/100, Training Loss: 1.4970736503601074, Validation Loss: 0.6600320935249329\n",
      "Epoch 12/100, Training Loss: 1.4491591453552246, Validation Loss: 0.6384984850883484\n",
      "Epoch 13/100, Training Loss: 1.4267926216125488, Validation Loss: 0.618740439414978\n",
      "Epoch 14/100, Training Loss: 1.3757848739624023, Validation Loss: 0.600157618522644\n",
      "Epoch 15/100, Training Loss: 1.3547767400741577, Validation Loss: 0.5823952555656433\n",
      "Epoch 16/100, Training Loss: 1.3194564580917358, Validation Loss: 0.5650390386581421\n",
      "Epoch 17/100, Training Loss: 1.290738582611084, Validation Loss: 0.5480228662490845\n",
      "Epoch 18/100, Training Loss: 1.264951467514038, Validation Loss: 0.5303018689155579\n",
      "Epoch 19/100, Training Loss: 1.2120860815048218, Validation Loss: 0.5124101042747498\n",
      "Epoch 20/100, Training Loss: 1.1960856914520264, Validation Loss: 0.49382564425468445\n",
      "Epoch 21/100, Training Loss: 1.1594703197479248, Validation Loss: 0.4750611186027527\n",
      "Epoch 22/100, Training Loss: 1.130081057548523, Validation Loss: 0.45554158091545105\n",
      "Epoch 23/100, Training Loss: 1.0962427854537964, Validation Loss: 0.43582576513290405\n",
      "Epoch 24/100, Training Loss: 1.0728214979171753, Validation Loss: 0.4159909188747406\n",
      "Epoch 25/100, Training Loss: 1.0363620519638062, Validation Loss: 0.39628833532333374\n",
      "Epoch 26/100, Training Loss: 1.0046120882034302, Validation Loss: 0.3773903250694275\n",
      "Epoch 27/100, Training Loss: 0.9977326393127441, Validation Loss: 0.3589671552181244\n",
      "Epoch 28/100, Training Loss: 0.9735249280929565, Validation Loss: 0.3408365547657013\n",
      "Epoch 29/100, Training Loss: 0.9488121271133423, Validation Loss: 0.3232947289943695\n",
      "Epoch 30/100, Training Loss: 0.9395713210105896, Validation Loss: 0.30608442425727844\n",
      "Epoch 31/100, Training Loss: 0.9243746995925903, Validation Loss: 0.28862661123275757\n",
      "Epoch 32/100, Training Loss: 0.9130825400352478, Validation Loss: 0.2714296877384186\n",
      "Epoch 33/100, Training Loss: 0.8922078609466553, Validation Loss: 0.2540713846683502\n",
      "Epoch 34/100, Training Loss: 0.8965006470680237, Validation Loss: 0.2366892546415329\n",
      "Epoch 35/100, Training Loss: 0.8723214864730835, Validation Loss: 0.2195747345685959\n",
      "Epoch 36/100, Training Loss: 0.8683865666389465, Validation Loss: 0.20299217104911804\n",
      "Epoch 37/100, Training Loss: 0.849898099899292, Validation Loss: 0.18716846406459808\n",
      "Epoch 38/100, Training Loss: 0.8435990810394287, Validation Loss: 0.17203845083713531\n",
      "Epoch 39/100, Training Loss: 0.8256027102470398, Validation Loss: 0.1572573482990265\n",
      "Epoch 40/100, Training Loss: 0.8170676231384277, Validation Loss: 0.1433005928993225\n",
      "Epoch 41/100, Training Loss: 0.812391459941864, Validation Loss: 0.13018330931663513\n",
      "Epoch 42/100, Training Loss: 0.7972288727760315, Validation Loss: 0.11825712770223618\n",
      "Epoch 43/100, Training Loss: 0.7879276275634766, Validation Loss: 0.10746420919895172\n",
      "Epoch 44/100, Training Loss: 0.7724860906600952, Validation Loss: 0.09785276651382446\n",
      "Epoch 45/100, Training Loss: 0.7529773116111755, Validation Loss: 0.08921775221824646\n",
      "Epoch 46/100, Training Loss: 0.7584640383720398, Validation Loss: 0.08161931484937668\n",
      "Epoch 47/100, Training Loss: 0.7471830248832703, Validation Loss: 0.0750446692109108\n",
      "Epoch 48/100, Training Loss: 0.7326423525810242, Validation Loss: 0.06912144273519516\n",
      "Epoch 49/100, Training Loss: 0.7333803176879883, Validation Loss: 0.06400369107723236\n",
      "Epoch 50/100, Training Loss: 0.7261998057365417, Validation Loss: 0.05939852446317673\n",
      "Epoch 51/100, Training Loss: 0.7047066688537598, Validation Loss: 0.05535067617893219\n",
      "Epoch 52/100, Training Loss: 0.6972475647926331, Validation Loss: 0.05166485905647278\n",
      "Epoch 53/100, Training Loss: 0.7006813287734985, Validation Loss: 0.04830621927976608\n",
      "Epoch 54/100, Training Loss: 0.6863598227500916, Validation Loss: 0.04542024806141853\n",
      "Epoch 55/100, Training Loss: 0.6759461760520935, Validation Loss: 0.04270966723561287\n",
      "Epoch 56/100, Training Loss: 0.6717723608016968, Validation Loss: 0.040290553122758865\n",
      "Epoch 57/100, Training Loss: 0.6633250117301941, Validation Loss: 0.03805002570152283\n",
      "Epoch 58/100, Training Loss: 0.6646538972854614, Validation Loss: 0.03611020743846893\n",
      "Epoch 59/100, Training Loss: 0.6515696048736572, Validation Loss: 0.034311238676309586\n",
      "Epoch 60/100, Training Loss: 0.6487329006195068, Validation Loss: 0.03273436799645424\n",
      "Epoch 61/100, Training Loss: 0.6395371556282043, Validation Loss: 0.03118397295475006\n",
      "Epoch 62/100, Training Loss: 0.6394935250282288, Validation Loss: 0.029860837385058403\n",
      "Epoch 63/100, Training Loss: 0.6293254494667053, Validation Loss: 0.02865704335272312\n",
      "Epoch 64/100, Training Loss: 0.6171345710754395, Validation Loss: 0.02747289463877678\n",
      "Epoch 65/100, Training Loss: 0.6209277510643005, Validation Loss: 0.026331827044487\n",
      "Epoch 66/100, Training Loss: 0.6104790568351746, Validation Loss: 0.02526695281267166\n",
      "Epoch 67/100, Training Loss: 0.5975050330162048, Validation Loss: 0.024200042709708214\n",
      "Epoch 68/100, Training Loss: 0.5902124643325806, Validation Loss: 0.023350810632109642\n",
      "Epoch 69/100, Training Loss: 0.5919433236122131, Validation Loss: 0.02265360951423645\n",
      "Epoch 70/100, Training Loss: 0.5775259733200073, Validation Loss: 0.022048376500606537\n",
      "Epoch 71/100, Training Loss: 0.5799711346626282, Validation Loss: 0.021557144820690155\n",
      "Epoch 72/100, Training Loss: 0.580036997795105, Validation Loss: 0.021187083795666695\n",
      "Epoch 73/100, Training Loss: 0.5672246813774109, Validation Loss: 0.020794544368982315\n",
      "Epoch 74/100, Training Loss: 0.5696356296539307, Validation Loss: 0.020434772595763206\n",
      "Epoch 75/100, Training Loss: 0.5633929967880249, Validation Loss: 0.020096980035305023\n",
      "Epoch 76/100, Training Loss: 0.5531827807426453, Validation Loss: 0.019782284274697304\n",
      "Epoch 77/100, Training Loss: 0.5445595383644104, Validation Loss: 0.01938670128583908\n",
      "Epoch 78/100, Training Loss: 0.5485935211181641, Validation Loss: 0.019044548273086548\n",
      "Epoch 79/100, Training Loss: 0.550570547580719, Validation Loss: 0.018693028017878532\n",
      "Epoch 80/100, Training Loss: 0.5337030291557312, Validation Loss: 0.018324436619877815\n",
      "Epoch 81/100, Training Loss: 0.5294132828712463, Validation Loss: 0.017941201105713844\n",
      "Epoch 82/100, Training Loss: 0.5242788195610046, Validation Loss: 0.017573239281773567\n",
      "Epoch 83/100, Training Loss: 0.5224682092666626, Validation Loss: 0.017207851633429527\n",
      "Epoch 84/100, Training Loss: 0.5200938582420349, Validation Loss: 0.016830433160066605\n",
      "Epoch 85/100, Training Loss: 0.5180433988571167, Validation Loss: 0.016495192423462868\n",
      "Epoch 86/100, Training Loss: 0.5147256851196289, Validation Loss: 0.016101015731692314\n",
      "Epoch 87/100, Training Loss: 0.5066068768501282, Validation Loss: 0.015781451016664505\n",
      "Epoch 88/100, Training Loss: 0.5074138045310974, Validation Loss: 0.01547932531684637\n",
      "Epoch 89/100, Training Loss: 0.4957064688205719, Validation Loss: 0.015155416913330555\n",
      "Epoch 90/100, Training Loss: 0.49849092960357666, Validation Loss: 0.014897163957357407\n",
      "Epoch 91/100, Training Loss: 0.48590388894081116, Validation Loss: 0.014718106016516685\n",
      "Epoch 92/100, Training Loss: 0.49124661087989807, Validation Loss: 0.014535081572830677\n",
      "Epoch 93/100, Training Loss: 0.47929665446281433, Validation Loss: 0.014286564663052559\n",
      "Epoch 94/100, Training Loss: 0.47818616032600403, Validation Loss: 0.014113133773207664\n",
      "Epoch 95/100, Training Loss: 0.4703747630119324, Validation Loss: 0.013878208585083485\n",
      "Epoch 96/100, Training Loss: 0.47149208188056946, Validation Loss: 0.013648015446960926\n",
      "Epoch 97/100, Training Loss: 0.46156784892082214, Validation Loss: 0.013456929475069046\n",
      "Epoch 98/100, Training Loss: 0.4602539539337158, Validation Loss: 0.013265687972307205\n",
      "Epoch 99/100, Training Loss: 0.45466598868370056, Validation Loss: 0.013081453740596771\n",
      "Epoch 100/100, Training Loss: 0.4528680741786957, Validation Loss: 0.01291931513696909\n",
      "Fold 3 - R² Score: 0.9870, MAE: 0.0783\n",
      "Fold 4/5\n",
      "Epoch 1/100, Training Loss: 2.4807517528533936, Validation Loss: 0.8201889395713806\n",
      "Epoch 2/100, Training Loss: 2.2233974933624268, Validation Loss: 0.801345944404602\n",
      "Epoch 3/100, Training Loss: 2.0403404235839844, Validation Loss: 0.7828871607780457\n",
      "Epoch 4/100, Training Loss: 1.9121294021606445, Validation Loss: 0.7639403343200684\n",
      "Epoch 5/100, Training Loss: 1.8077707290649414, Validation Loss: 0.74483722448349\n",
      "Epoch 6/100, Training Loss: 1.7413663864135742, Validation Loss: 0.7256699800491333\n",
      "Epoch 7/100, Training Loss: 1.6551553010940552, Validation Loss: 0.7063698172569275\n",
      "Epoch 8/100, Training Loss: 1.584886908531189, Validation Loss: 0.6877115964889526\n",
      "Epoch 9/100, Training Loss: 1.547956109046936, Validation Loss: 0.6697670817375183\n",
      "Epoch 10/100, Training Loss: 1.4844653606414795, Validation Loss: 0.6531049609184265\n",
      "Epoch 11/100, Training Loss: 1.4372797012329102, Validation Loss: 0.6364349126815796\n",
      "Epoch 12/100, Training Loss: 1.395674467086792, Validation Loss: 0.6201981902122498\n",
      "Epoch 13/100, Training Loss: 1.3502495288848877, Validation Loss: 0.6040051579475403\n",
      "Epoch 14/100, Training Loss: 1.3029385805130005, Validation Loss: 0.5877454876899719\n",
      "Epoch 15/100, Training Loss: 1.2909266948699951, Validation Loss: 0.5712491869926453\n",
      "Epoch 16/100, Training Loss: 1.248280644416809, Validation Loss: 0.5547230243682861\n",
      "Epoch 17/100, Training Loss: 1.2236100435256958, Validation Loss: 0.5379424095153809\n",
      "Epoch 18/100, Training Loss: 1.166478157043457, Validation Loss: 0.5206753015518188\n",
      "Epoch 19/100, Training Loss: 1.158050298690796, Validation Loss: 0.5023208260536194\n",
      "Epoch 20/100, Training Loss: 1.1373118162155151, Validation Loss: 0.48319754004478455\n",
      "Epoch 21/100, Training Loss: 1.1009243726730347, Validation Loss: 0.4628392159938812\n",
      "Epoch 22/100, Training Loss: 1.0840697288513184, Validation Loss: 0.44155260920524597\n",
      "Epoch 23/100, Training Loss: 1.0748008489608765, Validation Loss: 0.41960078477859497\n",
      "Epoch 24/100, Training Loss: 1.0400291681289673, Validation Loss: 0.39650580286979675\n",
      "Epoch 25/100, Training Loss: 1.0181705951690674, Validation Loss: 0.3725566864013672\n",
      "Epoch 26/100, Training Loss: 0.9967423677444458, Validation Loss: 0.34827151894569397\n",
      "Epoch 27/100, Training Loss: 0.9902945160865784, Validation Loss: 0.3238760232925415\n",
      "Epoch 28/100, Training Loss: 0.9735917448997498, Validation Loss: 0.2995716333389282\n",
      "Epoch 29/100, Training Loss: 0.949053943157196, Validation Loss: 0.27603113651275635\n",
      "Epoch 30/100, Training Loss: 0.932400107383728, Validation Loss: 0.25399675965309143\n",
      "Epoch 31/100, Training Loss: 0.9051897525787354, Validation Loss: 0.2329316884279251\n",
      "Epoch 32/100, Training Loss: 0.9056023359298706, Validation Loss: 0.21301566064357758\n",
      "Epoch 33/100, Training Loss: 0.8795968890190125, Validation Loss: 0.1942944973707199\n",
      "Epoch 34/100, Training Loss: 0.8704527020454407, Validation Loss: 0.17729684710502625\n",
      "Epoch 35/100, Training Loss: 0.8505368232727051, Validation Loss: 0.16193224489688873\n",
      "Epoch 36/100, Training Loss: 0.8509346842765808, Validation Loss: 0.1483234316110611\n",
      "Epoch 37/100, Training Loss: 0.8275277018547058, Validation Loss: 0.13574077188968658\n",
      "Epoch 38/100, Training Loss: 0.8049470782279968, Validation Loss: 0.12429939210414886\n",
      "Epoch 39/100, Training Loss: 0.8041713237762451, Validation Loss: 0.11380807310342789\n",
      "Epoch 40/100, Training Loss: 0.7855721116065979, Validation Loss: 0.1044103279709816\n",
      "Epoch 41/100, Training Loss: 0.7783429026603699, Validation Loss: 0.09554711729288101\n",
      "Epoch 42/100, Training Loss: 0.7677351832389832, Validation Loss: 0.08751053363084793\n",
      "Epoch 43/100, Training Loss: 0.7554650902748108, Validation Loss: 0.08038502931594849\n",
      "Epoch 44/100, Training Loss: 0.7364517450332642, Validation Loss: 0.0739336907863617\n",
      "Epoch 45/100, Training Loss: 0.7372598648071289, Validation Loss: 0.06793579459190369\n",
      "Epoch 46/100, Training Loss: 0.7283160090446472, Validation Loss: 0.06253696978092194\n",
      "Epoch 47/100, Training Loss: 0.725560188293457, Validation Loss: 0.057694148272275925\n",
      "Epoch 48/100, Training Loss: 0.7046350240707397, Validation Loss: 0.05329388380050659\n",
      "Epoch 49/100, Training Loss: 0.705636203289032, Validation Loss: 0.04912152141332626\n",
      "Epoch 50/100, Training Loss: 0.6826837062835693, Validation Loss: 0.04517919197678566\n",
      "Epoch 51/100, Training Loss: 0.6890195608139038, Validation Loss: 0.0415823757648468\n",
      "Epoch 52/100, Training Loss: 0.682680070400238, Validation Loss: 0.0384896844625473\n",
      "Epoch 53/100, Training Loss: 0.6615688800811768, Validation Loss: 0.03585588559508324\n",
      "Epoch 54/100, Training Loss: 0.6716235876083374, Validation Loss: 0.033411070704460144\n",
      "Epoch 55/100, Training Loss: 0.6601129174232483, Validation Loss: 0.03134078159928322\n",
      "Epoch 56/100, Training Loss: 0.6479136943817139, Validation Loss: 0.029511956498026848\n",
      "Epoch 57/100, Training Loss: 0.6387453079223633, Validation Loss: 0.027912776917219162\n",
      "Epoch 58/100, Training Loss: 0.624229371547699, Validation Loss: 0.026506874710321426\n",
      "Epoch 59/100, Training Loss: 0.617611289024353, Validation Loss: 0.02531835436820984\n",
      "Epoch 60/100, Training Loss: 0.6143295764923096, Validation Loss: 0.02427998185157776\n",
      "Epoch 61/100, Training Loss: 0.6211154460906982, Validation Loss: 0.023327359929680824\n",
      "Epoch 62/100, Training Loss: 0.6042639017105103, Validation Loss: 0.022500881925225258\n",
      "Epoch 63/100, Training Loss: 0.6038722395896912, Validation Loss: 0.021720048040151596\n",
      "Epoch 64/100, Training Loss: 0.5835901498794556, Validation Loss: 0.020901374518871307\n",
      "Epoch 65/100, Training Loss: 0.5906767845153809, Validation Loss: 0.02006489969789982\n",
      "Epoch 66/100, Training Loss: 0.5851851105690002, Validation Loss: 0.01940103992819786\n",
      "Epoch 67/100, Training Loss: 0.5781513452529907, Validation Loss: 0.018739797174930573\n",
      "Epoch 68/100, Training Loss: 0.5696493983268738, Validation Loss: 0.018152303993701935\n",
      "Epoch 69/100, Training Loss: 0.56442791223526, Validation Loss: 0.01763596385717392\n",
      "Epoch 70/100, Training Loss: 0.5532039999961853, Validation Loss: 0.017239434644579887\n",
      "Epoch 71/100, Training Loss: 0.5438935160636902, Validation Loss: 0.016833771020174026\n",
      "Epoch 72/100, Training Loss: 0.5385288596153259, Validation Loss: 0.016408585011959076\n",
      "Epoch 73/100, Training Loss: 0.5348454117774963, Validation Loss: 0.01602170616388321\n",
      "Epoch 74/100, Training Loss: 0.5317198634147644, Validation Loss: 0.015655774623155594\n",
      "Epoch 75/100, Training Loss: 0.5265356302261353, Validation Loss: 0.015219158492982388\n",
      "Epoch 76/100, Training Loss: 0.5279386639595032, Validation Loss: 0.014845822937786579\n",
      "Epoch 77/100, Training Loss: 0.5186845064163208, Validation Loss: 0.014488469809293747\n",
      "Epoch 78/100, Training Loss: 0.5143888592720032, Validation Loss: 0.014116109348833561\n",
      "Epoch 79/100, Training Loss: 0.5095295906066895, Validation Loss: 0.013766002841293812\n",
      "Epoch 80/100, Training Loss: 0.5053690075874329, Validation Loss: 0.013554065488278866\n",
      "Epoch 81/100, Training Loss: 0.5040786862373352, Validation Loss: 0.013421409763395786\n",
      "Epoch 82/100, Training Loss: 0.5005609393119812, Validation Loss: 0.013266733847558498\n",
      "Epoch 83/100, Training Loss: 0.4972792863845825, Validation Loss: 0.013084601610898972\n",
      "Epoch 84/100, Training Loss: 0.48592203855514526, Validation Loss: 0.012910915538668633\n",
      "Epoch 85/100, Training Loss: 0.48681315779685974, Validation Loss: 0.01273885928094387\n",
      "Epoch 86/100, Training Loss: 0.4685543477535248, Validation Loss: 0.01259684283286333\n",
      "Epoch 87/100, Training Loss: 0.47913989424705505, Validation Loss: 0.012406937777996063\n",
      "Epoch 88/100, Training Loss: 0.47473281621932983, Validation Loss: 0.01221836730837822\n",
      "Epoch 89/100, Training Loss: 0.4584379494190216, Validation Loss: 0.012031196616590023\n",
      "Epoch 90/100, Training Loss: 0.45342278480529785, Validation Loss: 0.011898955330252647\n",
      "Epoch 91/100, Training Loss: 0.44707703590393066, Validation Loss: 0.011763506568968296\n",
      "Epoch 92/100, Training Loss: 0.4519837498664856, Validation Loss: 0.011613610200583935\n",
      "Epoch 93/100, Training Loss: 0.44477379322052, Validation Loss: 0.011446166783571243\n",
      "Epoch 94/100, Training Loss: 0.4457765519618988, Validation Loss: 0.011275231838226318\n",
      "Epoch 95/100, Training Loss: 0.4377197325229645, Validation Loss: 0.011171896010637283\n",
      "Epoch 96/100, Training Loss: 0.43601319193840027, Validation Loss: 0.01107966247946024\n",
      "Epoch 97/100, Training Loss: 0.4388377070426941, Validation Loss: 0.011030260473489761\n",
      "Epoch 98/100, Training Loss: 0.42770329117774963, Validation Loss: 0.010967674665153027\n",
      "Epoch 99/100, Training Loss: 0.4189797341823578, Validation Loss: 0.010906933806836605\n",
      "Epoch 100/100, Training Loss: 0.4185517132282257, Validation Loss: 0.010837635956704617\n",
      "Fold 4 - R² Score: 0.9892, MAE: 0.0764\n",
      "Fold 5/5\n",
      "Epoch 1/100, Training Loss: 3.2367286682128906, Validation Loss: 0.9502944946289062\n",
      "Epoch 2/100, Training Loss: 2.853590488433838, Validation Loss: 0.9041475057601929\n",
      "Epoch 3/100, Training Loss: 2.60371732711792, Validation Loss: 0.8665094375610352\n",
      "Epoch 4/100, Training Loss: 2.3483617305755615, Validation Loss: 0.8350863456726074\n",
      "Epoch 5/100, Training Loss: 2.1865687370300293, Validation Loss: 0.8080577254295349\n",
      "Epoch 6/100, Training Loss: 2.0177574157714844, Validation Loss: 0.7841963171958923\n",
      "Epoch 7/100, Training Loss: 1.8837032318115234, Validation Loss: 0.7622089982032776\n",
      "Epoch 8/100, Training Loss: 1.7803133726119995, Validation Loss: 0.7417349219322205\n",
      "Epoch 9/100, Training Loss: 1.7047667503356934, Validation Loss: 0.7225506901741028\n",
      "Epoch 10/100, Training Loss: 1.6275913715362549, Validation Loss: 0.7042861580848694\n",
      "Epoch 11/100, Training Loss: 1.5943156480789185, Validation Loss: 0.6870893836021423\n",
      "Epoch 12/100, Training Loss: 1.540250539779663, Validation Loss: 0.6707122921943665\n",
      "Epoch 13/100, Training Loss: 1.49092435836792, Validation Loss: 0.654981255531311\n",
      "Epoch 14/100, Training Loss: 1.439358115196228, Validation Loss: 0.6401697993278503\n",
      "Epoch 15/100, Training Loss: 1.433252215385437, Validation Loss: 0.62552809715271\n",
      "Epoch 16/100, Training Loss: 1.3795182704925537, Validation Loss: 0.6117666363716125\n",
      "Epoch 17/100, Training Loss: 1.3737770318984985, Validation Loss: 0.5982986092567444\n",
      "Epoch 18/100, Training Loss: 1.3122367858886719, Validation Loss: 0.5842471718788147\n",
      "Epoch 19/100, Training Loss: 1.3005425930023193, Validation Loss: 0.5693771839141846\n",
      "Epoch 20/100, Training Loss: 1.2678533792495728, Validation Loss: 0.5543883442878723\n",
      "Epoch 21/100, Training Loss: 1.236495018005371, Validation Loss: 0.5388249754905701\n",
      "Epoch 22/100, Training Loss: 1.208456039428711, Validation Loss: 0.5217781066894531\n",
      "Epoch 23/100, Training Loss: 1.2009185552597046, Validation Loss: 0.5029693245887756\n",
      "Epoch 24/100, Training Loss: 1.166541337966919, Validation Loss: 0.48231324553489685\n",
      "Epoch 25/100, Training Loss: 1.138369083404541, Validation Loss: 0.46010321378707886\n",
      "Epoch 26/100, Training Loss: 1.1193383932113647, Validation Loss: 0.4366087317466736\n",
      "Epoch 27/100, Training Loss: 1.0874826908111572, Validation Loss: 0.41195011138916016\n",
      "Epoch 28/100, Training Loss: 1.0732239484786987, Validation Loss: 0.3861822187900543\n",
      "Epoch 29/100, Training Loss: 1.0492202043533325, Validation Loss: 0.35968658328056335\n",
      "Epoch 30/100, Training Loss: 1.0273067951202393, Validation Loss: 0.3328627347946167\n",
      "Epoch 31/100, Training Loss: 1.0102200508117676, Validation Loss: 0.30625152587890625\n",
      "Epoch 32/100, Training Loss: 1.0052368640899658, Validation Loss: 0.280135840177536\n",
      "Epoch 33/100, Training Loss: 0.9690815806388855, Validation Loss: 0.25522172451019287\n",
      "Epoch 34/100, Training Loss: 0.9594622254371643, Validation Loss: 0.23175226151943207\n",
      "Epoch 35/100, Training Loss: 0.9522244334220886, Validation Loss: 0.20990467071533203\n",
      "Epoch 36/100, Training Loss: 0.9290661811828613, Validation Loss: 0.19001339375972748\n",
      "Epoch 37/100, Training Loss: 0.908397912979126, Validation Loss: 0.17168129980564117\n",
      "Epoch 38/100, Training Loss: 0.900421679019928, Validation Loss: 0.15502290427684784\n",
      "Epoch 39/100, Training Loss: 0.8919154405593872, Validation Loss: 0.14023374021053314\n",
      "Epoch 40/100, Training Loss: 0.8746256828308105, Validation Loss: 0.12675996124744415\n",
      "Epoch 41/100, Training Loss: 0.8748695850372314, Validation Loss: 0.11471143364906311\n",
      "Epoch 42/100, Training Loss: 0.8503780364990234, Validation Loss: 0.10376381129026413\n",
      "Epoch 43/100, Training Loss: 0.8444951176643372, Validation Loss: 0.09392877668142319\n",
      "Epoch 44/100, Training Loss: 0.8301871418952942, Validation Loss: 0.08514930307865143\n",
      "Epoch 45/100, Training Loss: 0.8181772232055664, Validation Loss: 0.07728876918554306\n",
      "Epoch 46/100, Training Loss: 0.8105453848838806, Validation Loss: 0.07036937028169632\n",
      "Epoch 47/100, Training Loss: 0.8034242987632751, Validation Loss: 0.06425076723098755\n",
      "Epoch 48/100, Training Loss: 0.7940570712089539, Validation Loss: 0.05894068256020546\n",
      "Epoch 49/100, Training Loss: 0.7815330028533936, Validation Loss: 0.05433269590139389\n",
      "Epoch 50/100, Training Loss: 0.7682205438613892, Validation Loss: 0.050356097519397736\n",
      "Epoch 51/100, Training Loss: 0.765623927116394, Validation Loss: 0.04694878309965134\n",
      "Epoch 52/100, Training Loss: 0.7585113644599915, Validation Loss: 0.043886274099349976\n",
      "Epoch 53/100, Training Loss: 0.7464171051979065, Validation Loss: 0.04110942780971527\n",
      "Epoch 54/100, Training Loss: 0.7356275320053101, Validation Loss: 0.038583073765039444\n",
      "Epoch 55/100, Training Loss: 0.7384030222892761, Validation Loss: 0.036243196576833725\n",
      "Epoch 56/100, Training Loss: 0.7219377756118774, Validation Loss: 0.03410246968269348\n",
      "Epoch 57/100, Training Loss: 0.7170406579971313, Validation Loss: 0.03214443847537041\n",
      "Epoch 58/100, Training Loss: 0.7172185182571411, Validation Loss: 0.0303374994546175\n",
      "Epoch 59/100, Training Loss: 0.7000332474708557, Validation Loss: 0.028752515092492104\n",
      "Epoch 60/100, Training Loss: 0.6912857890129089, Validation Loss: 0.027420584112405777\n",
      "Epoch 61/100, Training Loss: 0.6787335276603699, Validation Loss: 0.026321154087781906\n",
      "Epoch 62/100, Training Loss: 0.6734788417816162, Validation Loss: 0.025313999503850937\n",
      "Epoch 63/100, Training Loss: 0.6706029772758484, Validation Loss: 0.024456029757857323\n",
      "Epoch 64/100, Training Loss: 0.6704314947128296, Validation Loss: 0.02358940988779068\n",
      "Epoch 65/100, Training Loss: 0.660287082195282, Validation Loss: 0.02277764119207859\n",
      "Epoch 66/100, Training Loss: 0.6513398885726929, Validation Loss: 0.022022699937224388\n",
      "Epoch 67/100, Training Loss: 0.6321715712547302, Validation Loss: 0.02120637148618698\n",
      "Epoch 68/100, Training Loss: 0.639029860496521, Validation Loss: 0.020339567214250565\n",
      "Epoch 69/100, Training Loss: 0.6370559930801392, Validation Loss: 0.019549673423171043\n",
      "Epoch 70/100, Training Loss: 0.625795304775238, Validation Loss: 0.018922464922070503\n",
      "Epoch 71/100, Training Loss: 0.6166591644287109, Validation Loss: 0.018327152356505394\n",
      "Epoch 72/100, Training Loss: 0.6142028570175171, Validation Loss: 0.01786494068801403\n",
      "Epoch 73/100, Training Loss: 0.6141493916511536, Validation Loss: 0.01744728349149227\n",
      "Epoch 74/100, Training Loss: 0.600792407989502, Validation Loss: 0.01715211756527424\n",
      "Epoch 75/100, Training Loss: 0.6079009771347046, Validation Loss: 0.01687367632985115\n",
      "Epoch 76/100, Training Loss: 0.596002995967865, Validation Loss: 0.016660524532198906\n",
      "Epoch 77/100, Training Loss: 0.5827708840370178, Validation Loss: 0.01639832742512226\n",
      "Epoch 78/100, Training Loss: 0.5858014822006226, Validation Loss: 0.01618328131735325\n",
      "Epoch 79/100, Training Loss: 0.5835457444190979, Validation Loss: 0.015987418591976166\n",
      "Epoch 80/100, Training Loss: 0.5743356943130493, Validation Loss: 0.015741238370537758\n",
      "Epoch 81/100, Training Loss: 0.5626298785209656, Validation Loss: 0.015458296984434128\n",
      "Epoch 82/100, Training Loss: 0.5607483386993408, Validation Loss: 0.015163480304181576\n",
      "Epoch 83/100, Training Loss: 0.5547057390213013, Validation Loss: 0.014891520142555237\n",
      "Epoch 84/100, Training Loss: 0.5511103868484497, Validation Loss: 0.014650030992925167\n",
      "Epoch 85/100, Training Loss: 0.5500609874725342, Validation Loss: 0.014422784559428692\n",
      "Epoch 86/100, Training Loss: 0.5459672808647156, Validation Loss: 0.014259261079132557\n",
      "Epoch 87/100, Training Loss: 0.5415241122245789, Validation Loss: 0.014152014628052711\n",
      "Epoch 88/100, Training Loss: 0.5292993783950806, Validation Loss: 0.014049903489649296\n",
      "Epoch 89/100, Training Loss: 0.5277865529060364, Validation Loss: 0.013942615129053593\n",
      "Epoch 90/100, Training Loss: 0.5246026515960693, Validation Loss: 0.013784140348434448\n",
      "Epoch 91/100, Training Loss: 0.5244895815849304, Validation Loss: 0.013636600226163864\n",
      "Epoch 92/100, Training Loss: 0.5220093131065369, Validation Loss: 0.013469157740473747\n",
      "Epoch 93/100, Training Loss: 0.5122179388999939, Validation Loss: 0.013301780447363853\n",
      "Epoch 94/100, Training Loss: 0.510398805141449, Validation Loss: 0.013158591464161873\n",
      "Epoch 95/100, Training Loss: 0.5044049024581909, Validation Loss: 0.013000070117413998\n",
      "Epoch 96/100, Training Loss: 0.4938698709011078, Validation Loss: 0.012903685681521893\n",
      "Epoch 97/100, Training Loss: 0.48916810750961304, Validation Loss: 0.012813339941203594\n",
      "Epoch 98/100, Training Loss: 0.4890509843826294, Validation Loss: 0.012734627351164818\n",
      "Epoch 99/100, Training Loss: 0.4913496971130371, Validation Loss: 0.012676602229475975\n",
      "Epoch 100/100, Training Loss: 0.4849717319011688, Validation Loss: 0.012626350857317448\n",
      "Fold 5 - R² Score: 0.9874, MAE: 0.0859\n",
      "Testing parameters: {'dropout_rate': 0.3, 'hidden_dim': 64, 'learning_rate': 0.005}\n",
      "Fold 1/5\n",
      "Epoch 1/100, Training Loss: 2.6734845638275146, Validation Loss: 0.704402506351471\n",
      "Epoch 2/100, Training Loss: 1.7276641130447388, Validation Loss: 0.6077166795730591\n",
      "Epoch 3/100, Training Loss: 1.5389256477355957, Validation Loss: 0.5559687614440918\n",
      "Epoch 4/100, Training Loss: 1.3996857404708862, Validation Loss: 0.5348600149154663\n",
      "Epoch 5/100, Training Loss: 1.255412220954895, Validation Loss: 0.5321913361549377\n",
      "Epoch 6/100, Training Loss: 1.1362661123275757, Validation Loss: 0.5392508506774902\n",
      "Epoch 7/100, Training Loss: 1.0421116352081299, Validation Loss: 0.5488556623458862\n",
      "Epoch 8/100, Training Loss: 0.9463439583778381, Validation Loss: 0.5548092126846313\n",
      "Epoch 9/100, Training Loss: 0.8895264863967896, Validation Loss: 0.5526710748672485\n",
      "Epoch 10/100, Training Loss: 0.8195124268531799, Validation Loss: 0.5419440269470215\n",
      "Epoch 11/100, Training Loss: 0.7500319480895996, Validation Loss: 0.5244085788726807\n",
      "Epoch 12/100, Training Loss: 0.7242376208305359, Validation Loss: 0.5011004209518433\n",
      "Epoch 13/100, Training Loss: 0.6778445839881897, Validation Loss: 0.474270224571228\n",
      "Epoch 14/100, Training Loss: 0.6478003859519958, Validation Loss: 0.446869820356369\n",
      "Epoch 15/100, Training Loss: 0.6157167553901672, Validation Loss: 0.4198324382305145\n",
      "Epoch 16/100, Training Loss: 0.5843965411186218, Validation Loss: 0.39414483308792114\n",
      "Epoch 17/100, Training Loss: 0.5484830141067505, Validation Loss: 0.3704477846622467\n",
      "Epoch 18/100, Training Loss: 0.5288893580436707, Validation Loss: 0.3485852777957916\n",
      "Epoch 19/100, Training Loss: 0.5027090907096863, Validation Loss: 0.3284219801425934\n",
      "Epoch 20/100, Training Loss: 0.48625868558883667, Validation Loss: 0.31016579270362854\n",
      "Epoch 21/100, Training Loss: 0.4551183581352234, Validation Loss: 0.29298555850982666\n",
      "Epoch 22/100, Training Loss: 0.43664905428886414, Validation Loss: 0.2768425941467285\n",
      "Epoch 23/100, Training Loss: 0.4134269058704376, Validation Loss: 0.2613897919654846\n",
      "Epoch 24/100, Training Loss: 0.39639145135879517, Validation Loss: 0.246185302734375\n",
      "Epoch 25/100, Training Loss: 0.3839229941368103, Validation Loss: 0.2315671145915985\n",
      "Epoch 26/100, Training Loss: 0.36869072914123535, Validation Loss: 0.21700774133205414\n",
      "Epoch 27/100, Training Loss: 0.3507533371448517, Validation Loss: 0.20229610800743103\n",
      "Epoch 28/100, Training Loss: 0.34204360842704773, Validation Loss: 0.18770140409469604\n",
      "Epoch 29/100, Training Loss: 0.33126258850097656, Validation Loss: 0.17278063297271729\n",
      "Epoch 30/100, Training Loss: 0.31271031498908997, Validation Loss: 0.15792740881443024\n",
      "Epoch 31/100, Training Loss: 0.30480122566223145, Validation Loss: 0.14357556402683258\n",
      "Epoch 32/100, Training Loss: 0.29004967212677, Validation Loss: 0.12965673208236694\n",
      "Epoch 33/100, Training Loss: 0.27980121970176697, Validation Loss: 0.11643179506063461\n",
      "Epoch 34/100, Training Loss: 0.27293041348457336, Validation Loss: 0.10422439873218536\n",
      "Epoch 35/100, Training Loss: 0.2647152245044708, Validation Loss: 0.09291297942399979\n",
      "Epoch 36/100, Training Loss: 0.2555650770664215, Validation Loss: 0.08278525620698929\n",
      "Epoch 37/100, Training Loss: 0.24180179834365845, Validation Loss: 0.07383088022470474\n",
      "Epoch 38/100, Training Loss: 0.23882828652858734, Validation Loss: 0.06609279662370682\n",
      "Epoch 39/100, Training Loss: 0.2299147993326187, Validation Loss: 0.05952339246869087\n",
      "Epoch 40/100, Training Loss: 0.22308027744293213, Validation Loss: 0.05406944453716278\n",
      "Epoch 41/100, Training Loss: 0.21426734328269958, Validation Loss: 0.04937659949064255\n",
      "Epoch 42/100, Training Loss: 0.20991197228431702, Validation Loss: 0.04527720808982849\n",
      "Epoch 43/100, Training Loss: 0.2005205750465393, Validation Loss: 0.04163350164890289\n",
      "Epoch 44/100, Training Loss: 0.19604913890361786, Validation Loss: 0.03827955201268196\n",
      "Epoch 45/100, Training Loss: 0.18629665672779083, Validation Loss: 0.03521318361163139\n",
      "Epoch 46/100, Training Loss: 0.18444518744945526, Validation Loss: 0.03216520696878433\n",
      "Epoch 47/100, Training Loss: 0.17959648370742798, Validation Loss: 0.029075996950268745\n",
      "Epoch 48/100, Training Loss: 0.17483364045619965, Validation Loss: 0.026058105751872063\n",
      "Epoch 49/100, Training Loss: 0.1693548560142517, Validation Loss: 0.023170867934823036\n",
      "Epoch 50/100, Training Loss: 0.16278347373008728, Validation Loss: 0.020522627979516983\n",
      "Epoch 51/100, Training Loss: 0.15947122871875763, Validation Loss: 0.018200168386101723\n",
      "Epoch 52/100, Training Loss: 0.1558038890361786, Validation Loss: 0.01619727909564972\n",
      "Epoch 53/100, Training Loss: 0.1511683464050293, Validation Loss: 0.014512731693685055\n",
      "Epoch 54/100, Training Loss: 0.14624035358428955, Validation Loss: 0.013057042844593525\n",
      "Epoch 55/100, Training Loss: 0.14070101082324982, Validation Loss: 0.011820167303085327\n",
      "Epoch 56/100, Training Loss: 0.13983683288097382, Validation Loss: 0.010726580396294594\n",
      "Epoch 57/100, Training Loss: 0.13515643775463104, Validation Loss: 0.009814639575779438\n",
      "Epoch 58/100, Training Loss: 0.1330636888742447, Validation Loss: 0.009069149382412434\n",
      "Epoch 59/100, Training Loss: 0.13035187125205994, Validation Loss: 0.008418534882366657\n",
      "Epoch 60/100, Training Loss: 0.1266060173511505, Validation Loss: 0.00788881629705429\n",
      "Epoch 61/100, Training Loss: 0.12264396250247955, Validation Loss: 0.007443448528647423\n",
      "Epoch 62/100, Training Loss: 0.12046750634908676, Validation Loss: 0.007081577554345131\n",
      "Epoch 63/100, Training Loss: 0.1173098087310791, Validation Loss: 0.006768922321498394\n",
      "Epoch 64/100, Training Loss: 0.11560249328613281, Validation Loss: 0.006465371698141098\n",
      "Epoch 65/100, Training Loss: 0.11129555106163025, Validation Loss: 0.0061735049821436405\n",
      "Epoch 66/100, Training Loss: 0.11075828969478607, Validation Loss: 0.00588596984744072\n",
      "Epoch 67/100, Training Loss: 0.10910233110189438, Validation Loss: 0.005583262071013451\n",
      "Epoch 68/100, Training Loss: 0.10594724118709564, Validation Loss: 0.005292666144669056\n",
      "Epoch 69/100, Training Loss: 0.10418026149272919, Validation Loss: 0.005040302406996489\n",
      "Epoch 70/100, Training Loss: 0.10020195692777634, Validation Loss: 0.004836108069866896\n",
      "Epoch 71/100, Training Loss: 0.09979334473609924, Validation Loss: 0.004673399031162262\n",
      "Epoch 72/100, Training Loss: 0.0973251461982727, Validation Loss: 0.004544114228338003\n",
      "Epoch 73/100, Training Loss: 0.09540385007858276, Validation Loss: 0.004442468751221895\n",
      "Epoch 74/100, Training Loss: 0.09421607106924057, Validation Loss: 0.0043472289107739925\n",
      "Epoch 75/100, Training Loss: 0.09200294315814972, Validation Loss: 0.004249916411936283\n",
      "Epoch 76/100, Training Loss: 0.09076298028230667, Validation Loss: 0.004149566404521465\n",
      "Epoch 77/100, Training Loss: 0.08806741237640381, Validation Loss: 0.004076667129993439\n",
      "Epoch 78/100, Training Loss: 0.08873800933361053, Validation Loss: 0.004015459679067135\n",
      "Epoch 79/100, Training Loss: 0.08627833425998688, Validation Loss: 0.003951488062739372\n",
      "Epoch 80/100, Training Loss: 0.08480063825845718, Validation Loss: 0.003895442234352231\n",
      "Epoch 81/100, Training Loss: 0.08318328112363815, Validation Loss: 0.0038680590223520994\n",
      "Epoch 82/100, Training Loss: 0.08258222788572311, Validation Loss: 0.0038428418338298798\n",
      "Epoch 83/100, Training Loss: 0.08075122535228729, Validation Loss: 0.003823329694569111\n",
      "Epoch 84/100, Training Loss: 0.08060663193464279, Validation Loss: 0.003808580106124282\n",
      "Epoch 85/100, Training Loss: 0.0787932425737381, Validation Loss: 0.0037918253801763058\n",
      "Epoch 86/100, Training Loss: 0.0763065367937088, Validation Loss: 0.003777930047363043\n",
      "Epoch 87/100, Training Loss: 0.07689988613128662, Validation Loss: 0.0037846623454242945\n",
      "Epoch 88/100, Training Loss: 0.07511451840400696, Validation Loss: 0.003804621286690235\n",
      "Epoch 89/100, Training Loss: 0.07417832314968109, Validation Loss: 0.0038198938127607107\n",
      "Epoch 90/100, Training Loss: 0.07356027513742447, Validation Loss: 0.003818602068349719\n",
      "Epoch 91/100, Training Loss: 0.07186944037675858, Validation Loss: 0.003816707758232951\n",
      "Epoch 92/100, Training Loss: 0.0721374899148941, Validation Loss: 0.0038046897388994694\n",
      "Epoch 93/100, Training Loss: 0.07096211612224579, Validation Loss: 0.003762310603633523\n",
      "Epoch 94/100, Training Loss: 0.07057293504476547, Validation Loss: 0.0037180588115006685\n",
      "Epoch 95/100, Training Loss: 0.06909969449043274, Validation Loss: 0.003678269451484084\n",
      "Epoch 96/100, Training Loss: 0.06846776604652405, Validation Loss: 0.003649576101452112\n",
      "Epoch 97/100, Training Loss: 0.06834141165018082, Validation Loss: 0.0036599976010620594\n",
      "Epoch 98/100, Training Loss: 0.06758125126361847, Validation Loss: 0.003651656676083803\n",
      "Epoch 99/100, Training Loss: 0.06689995527267456, Validation Loss: 0.003637793008238077\n",
      "Epoch 100/100, Training Loss: 0.06569567322731018, Validation Loss: 0.003626297926530242\n",
      "Fold 1 - R² Score: 0.9964, MAE: 0.0404\n",
      "Fold 2/5\n",
      "Epoch 1/100, Training Loss: 3.77951717376709, Validation Loss: 0.9481145739555359\n",
      "Epoch 2/100, Training Loss: 2.2274656295776367, Validation Loss: 0.8039475083351135\n",
      "Epoch 3/100, Training Loss: 1.7555855512619019, Validation Loss: 0.7099281549453735\n",
      "Epoch 4/100, Training Loss: 1.5891904830932617, Validation Loss: 0.6554456353187561\n",
      "Epoch 5/100, Training Loss: 1.4517920017242432, Validation Loss: 0.6318281888961792\n",
      "Epoch 6/100, Training Loss: 1.3189834356307983, Validation Loss: 0.6306679248809814\n",
      "Epoch 7/100, Training Loss: 1.2248975038528442, Validation Loss: 0.6440169215202332\n",
      "Epoch 8/100, Training Loss: 1.125234603881836, Validation Loss: 0.6628212332725525\n",
      "Epoch 9/100, Training Loss: 1.0317150354385376, Validation Loss: 0.6793100833892822\n",
      "Epoch 10/100, Training Loss: 0.9444506764411926, Validation Loss: 0.6875630021095276\n",
      "Epoch 11/100, Training Loss: 0.8718497157096863, Validation Loss: 0.6844847202301025\n",
      "Epoch 12/100, Training Loss: 0.7920593023300171, Validation Loss: 0.6710071563720703\n",
      "Epoch 13/100, Training Loss: 0.7359133362770081, Validation Loss: 0.6477013230323792\n",
      "Epoch 14/100, Training Loss: 0.6970301270484924, Validation Loss: 0.615753710269928\n",
      "Epoch 15/100, Training Loss: 0.6673117280006409, Validation Loss: 0.5773971676826477\n"
     ]
    }
   ],
   "source": [
    "# Define K-Fold cross-validation\n",
    "num_folds = 5  # You can adjust this number\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['learning_rate', 'hidden_dim', 'dropout_rate', 'fold', 'mae', 'r2'])\n",
    "\n",
    "print(\"Starting hyperparameter tuning with cross-validation...\")\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        train_data = Data(x=torch.tensor(X_train, dtype=torch.float), edge_index=data.edge_index, y=torch.tensor(y_train, dtype=torch.float))\n",
    "        val_data = Data(x=torch.tensor(X_val, dtype=torch.float), edge_index=data.edge_index, y=torch.tensor(y_val, dtype=torch.float))\n",
    "        \n",
    "        # Initialize model, optimizer, and loss function\n",
    "        model = EnhancedGNN(input_dim=3, hidden_dim=params['hidden_dim'], output_dim=3, dropout_rate=params['dropout_rate'])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        num_epochs = 100\n",
    "        patience = 10  # Early stopping patience\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(train_data)\n",
    "            loss = criterion(out, train_data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_out = model(val_data)\n",
    "                val_loss = criterion(val_out, val_data.y)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "        \n",
    "        # Calculate metrics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            final_out = model(val_data)\n",
    "            mae = mean_absolute_error(val_data.y.detach().numpy(), final_out.detach().numpy())\n",
    "            r2 = r2_score(val_data.y.detach().numpy(), final_out.detach().numpy())\n",
    "            print(f\"Fold {fold + 1} - R² Score: {r2:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "            # Record results for this fold\n",
    "            fold_results.append({\n",
    "                'learning_rate': params['learning_rate'],\n",
    "                'hidden_dim': params['hidden_dim'],\n",
    "                'dropout_rate': params['dropout_rate'],\n",
    "                'fold': fold + 1,\n",
    "                'mae': mae,\n",
    "                'r2': r2\n",
    "            })\n",
    "    \n",
    "    # Append fold results to the main results DataFrame\n",
    "    results_df = pd.concat([results_df, pd.DataFrame(fold_results)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9c80392-2756-4962-9a72-3c2b208aa732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dummy data for GNN model (use your actual model data)\n",
    "import numpy as np\n",
    "val_predictions = np.random.rand(len(y))  # Replace with actual model predictions\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y - val_predictions\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residual Analysis')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed45e988-1774-40fe-8a63-0c1aa0bcff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curves for Enhanced GNN Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e94609-48cb-4a44-89f2-a67b3051b830",
   "metadata": {},
   "source": [
    "# different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff007983-40af-47b7-be02-595ce964e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00022640528914052993\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming you have already split your data into X_train, X_test, y_train, y_test\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = XGBRegressor()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "#If You Are Performing Classification\n",
    "#If your target variable is categorical and you want to classify it, ensure that y_train and y_test contain discrete class labels. Here’s how to do it with XGBClassifier:\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef32f0-39e4-4a4b-acd2-947e2fecba53",
   "metadata": {},
   "source": [
    "We are not going to use XGBOOST Model because the R2 is 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48134e4b-ca19-4aa3-9ec1-2359b90315ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
